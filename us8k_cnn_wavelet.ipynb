{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7x6wKsIGKLK"
   },
   "source": [
    "**Reproduction of:**\n",
    "\n",
    "**Deep Convolutional Neural Networks and Data Augmentation for Environmental  Sound Classification** \n",
    "\n",
    "Justin Salamon and Juan Pablo Bello\n",
    "\n",
    "Some code taken from https://github.com/jaron/deep-listening/blob/master/4-us8k-cnn-salamon.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNGuDtV8G3v9"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#for dir in [load_dir, augmented_load_dir]:\n",
    "#    for k in range(1,10+1):\n",
    "#        filename = \"fold\"+str(k)+\"_x.npy\"\n",
    "#        file_path = os.path.join(dir,filename)\n",
    "#        file= np.load(file_path, allow_pickle = True)\n",
    "#        file = file.astype('float32') \n",
    "#        np.save(file_path, file, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/grudloff/Salomon2017Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kj7xR5hfzYAW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monic\\miniconda3\\envs\\deepsound\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\monic\\miniconda3\\envs\\deepsound\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "#gc.set_debug(gc.DEBUG_STATS)\n",
    "\n",
    "from preprocessing_augmented import load_folds\n",
    "from model import build_model\n",
    "from evaluation import evaluate\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pywt import dwt2\n",
    "\n",
    "load_dir = \"CNN-Sound/data/us8k\"\n",
    "augmented_load_dir = \"CNN-Sound/data/us8k-augmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet = 'bior1.5'\n",
    "frames = 68\n",
    "bands=68\n",
    "channels = 4\n",
    "\n",
    "def wavedec(batch_x):\n",
    "    new_batch_x = np.empty(shape = (batch_x.shape[0], frames, bands, channels),dtype = 'float32')\n",
    "    for i, img in enumerate(batch_x):\n",
    "        img = np.squeeze(img)\n",
    "        img = (img - np.mean(img))/np.std(img)\n",
    "    \n",
    "        # 2D Discrete Wavelet Transform\n",
    "        LL, (LH, HL, HH) = dwt2(img, wavelet)\n",
    "        new_batch_x[i] = np.stack([LL,LH,HL,HH],axis=-1)# shape: [frames, bands, 4]\n",
    "    \n",
    "    return new_batch_x\n",
    "\n",
    "class waveletGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size, shuffle):\n",
    "        self.x, self.y = x_set, np.array(y_set)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(self.x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(self.x.shape[0] / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_x = wavedec(self.x[indexes])\n",
    "        batch_y = self.y[indexes]\n",
    "\n",
    "        return batch_x , batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLYCNfTzwWBt"
   },
   "source": [
    "10-Fold Crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(f):\n",
    "    # load data\n",
    "    train_x, test_x, val_x, train_y, test_y, val_y = load_folds(load_dir,augmented_load_dir, f)\n",
    "    #train_gen, test_x, val_x, test_y, val_y = load_folds_pescador(load_dir,augmented_load_dir, f)\n",
    "\n",
    "    train_gen = waveletGenerator(train_x, train_y, shuffle=True, batch_size=100)\n",
    "    test_gen = waveletGenerator(test_x, test_y, shuffle=False, batch_size=100)\n",
    "    val_gen = waveletGenerator(val_x, val_y, shuffle=False, batch_size=100)\n",
    "    \n",
    "    print(\"Building model...\")\n",
    "    model = build_model(f_size=3, frames=frames, bands=bands, channels=channels)\n",
    "\n",
    "    # now fit the model to the training data, evaluating loss against the validation data\n",
    "    print(\"Training model...\")\n",
    "    model.fit(train_gen, validation_data=test_gen, \n",
    "              callbacks=[EarlyStopping(restore_best_weights=True, patience=15)],\n",
    "              epochs=100, workers=0)\n",
    "    \n",
    "    # now evaluate the trained model against the unseen test data\n",
    "    print(\"Evaluating model...\")\n",
    "    return evaluate(model, val_gen, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "WQyEXvd9wWBt",
    "outputId": "78f34333-1791-4de4-9206-1d2cf9591893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Train on {2, 3, 4, 5, 6, 7, 9} Validate on 1 Test on 8 ***\n",
      "val shape:  (873, 128, 128, 1)\n",
      "test shape:  (806, 128, 128, 1)\n",
      "train shape:  (148113, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1482 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "1482/1482 [==============================] - 75s 51ms/step - loss: 2.1361 - accuracy: 0.2670 - val_loss: 1.7958 - val_accuracy: 0.5385 loss: 2.3394 - accuracy: - ETA: 51s - loss: 2.3377 - accuracy:  - ETA: 50s - loss: 2.3357 - accuracy: 0 - ETA: 50s - loss: 2.333 - ETA: 48s - loss: 2. - ETA: 45s - ETA: 37s  - ETA: 34s   - ETA: 27s - loss: 2.2\n",
      "Epoch 2/100\n",
      "1482/1482 [==============================] - 67s 46ms/step - loss: 1.7480 - accuracy: 0.4226 - val_loss: 1.6063 - val_accuracy: 0.5087\n",
      "Epoch 3/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 1.5337 - accuracy: 0.5049 - val_loss: 1.4538 - val_accuracy: 0.5906\n",
      "Epoch 4/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 1.3948 - accuracy: 0.5545 - val_loss: 1.6504 - val_accuracy: 0.5335 1.3950 - accuracy: \n",
      "Epoch 5/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 1.2938 - accuracy: 0.5905 - val_loss: 1.2625 - val_accuracy: 0.6414\n",
      "Epoch 6/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 1.2076 - accuracy: 0.6199 - val_loss: 1.3416 - val_accuracy: 0.6104TA: 25s - E\n",
      "Epoch 7/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 1.1482 - accuracy: 0.6416 - val_loss: 1.2669 - val_accuracy: 0.6390loss: 1.1688 - accuracy: 0. - ETA: 37s - loss: 1.1677 - accura - ETA: 36s - loss: 1.1737  - ETA: 34s - loss: 1.1 - ETA: 11s - loss: 1.1499 - accuracy: 0 - ETA: 10s - loss: 1.1501 - accuracy: 0. - ETA: 10s - loss: 1.1522 - accuracy:  - ETA: 9s  - E\n",
      "Epoch 8/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 1.0900 - accuracy: 0.6587 - val_loss: 1.6208 - val_accuracy: 0.5608\n",
      "Epoch 9/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 1.0352 - accuracy: 0.6777 - val_loss: 1.2937 - val_accuracy: 0.6390\n",
      "Epoch 10/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 0.9961 - accuracy: 0.6923 - val_loss: 1.3684 - val_accuracy: 0.6390 - - ETA: 59s - loss: 0.9404 - ETA: 58s - loss: 0.9564 - accuracy: - ET\n",
      "Epoch 11/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.9622 - accuracy: 0.7044 - val_loss: 1.2220 - val_accuracy: 0.6464- accura - ETA: 2s - loss: 0.9608  - ETA: 2s - loss: 0.9609 -  - ETA\n",
      "Epoch 12/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.9283 - accuracy: 0.7136 - val_loss: 1.2020 - val_accuracy: 0.6787 48s - loss: 0.9 - ETA: 43s - ETA: 3s - loss: 0.926 - ETA: 2s - los - ETA: 1s -\n",
      "Epoch 13/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.8953 - accuracy: 0.7266 - val_loss: 1.2654 - val_accuracy: 0.6613s - loss: 0.8776 - accura - ETA: 50s - loss: 0.8851 - accu - ETA: 42s - loss: 0.8944 -  - ETA: 3 - ETA: 34s - loss: 0.8862 - accuracy: 0.728 - ETA: 34s - l - ETA: 31s - loss: 0.8850 - accuracy:  - ETA: 31s - loss: 0.8825 - accuracy: 0.7 - ETA: 31s - lo - ETA: 28s -  - ETA: 26s - loss: 0.8848 - a - ETA: 13s - los\n",
      "Epoch 14/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.8658 - accuracy: 0.7349 - val_loss: 1.2982 - val_accuracy: 0.6638TA: 53s - loss: 0.8748 - ac\n",
      "Epoch 15/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 0.8497 - accuracy: 0.7395 - val_loss: 1.3228 - val_accuracy: 0.6687\n",
      "Epoch 16/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.8213 - accuracy: 0.7494 - val_loss: 1.2214 - val_accuracy: 0.6811curacy - - ETA: 51s - loss: 0.81 - ETA: 49s - loss: 0.8205  - \n",
      "Epoch 17/100\n",
      "1482/1482 [==============================] - 69s 46ms/step - loss: 0.8014 - accuracy: 0.7555 - val_loss: 1.3662 - val_accuracy: 0.6650\n",
      "Epoch 18/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.7793 - accuracy: 0.7611 - val_loss: 1.2942 - val_accuracy: 0.6774\n",
      "Epoch 19/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 0.7634 - accuracy: 0.7671 - val_loss: 1.2994 - val_accuracy: 0.6774\n",
      "Epoch 20/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.7476 - accuracy: 0.7724 - val_loss: 1.4262 - val_accuracy: 0.6712\n",
      "Epoch 21/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 0.7309 - accuracy: 0.7771 - val_loss: 1.3864 - val_accuracy: 0.6762\n",
      "Epoch 22/100\n",
      "1482/1482 [==============================] - 68s 46ms/step - loss: 0.7168 - accuracy: 0.7814 - val_loss: 1.3469 - val_accuracy: 0.6489\n",
      "Epoch 23/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.7045 - accuracy: 0.7841 - val_loss: 1.4787 - val_accuracy: 0.6476: 0.7045 - accuracy: 0.783 - ETA: 32s - los - ETA: 30s - loss: 0.7011 - acc - E - ETA: 26s - loss: 0.7019  - ETA: 24s - loss: 0.7021 - - ETA: 2s - loss: 0.7047 - accu\n",
      "Epoch 24/100\n",
      "1482/1482 [==============================] - 68s 46ms/step - loss: 0.6917 - accuracy: 0.7884 - val_loss: 1.2110 - val_accuracy: 0.6787\n",
      "Epoch 25/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 0.6790 - accuracy: 0.7929 - val_loss: 1.3107 - val_accuracy: 0.6600\n",
      "Epoch 26/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.6708 - accuracy: 0.7961 - val_loss: 1.3411 - val_accuracy: 0.6663oss: 0.6718 - accu - ETA: 0s - loss: 0.6712 - \n",
      "Epoch 27/100\n",
      "1482/1482 [==============================] - 68s 46ms/step - loss: 0.6576 - accuracy: 0.8004 - val_loss: 1.4574 - val_accuracy: 0.6787los - ETA: 20s - loss: 0.6572 - ETA: 18s - loss: 0. - ETA: 0s - loss: 0.6584 - accuracy: 0.80 - ETA: 0s - loss: 0.6582 - \n",
      "Evaluating model...\n",
      "ROC: 0.949\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.69\n",
      "F-Score: 0.69\n",
      "\n",
      "*** Train on {1, 3, 4, 5, 6, 8, 9} Validate on 2 Test on 7 ***\n",
      "val shape:  (888, 128, 128, 1)\n",
      "test shape:  (838, 128, 128, 1)\n",
      "train shape:  (147126, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1472 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "1472/1472 [==============================] - 73s 50ms/step - loss: 2.1187 - accuracy: 0.2687 - val_loss: 1.8652 - val_accuracy: 0.3699cy: 0.15 - ETA: 59s - loss: - ETA: 51s -  - ETA: 48s - loss: 2.3316 - a - ETA: 46s - loss: 2.3263 - - ETA: 45s - loss: 2.3152 - - ETA: 39s - loss: 2.2857 - accuracy: 0 - ETA: 38s - - ETA: 35s - loss: 2.2673 - ETA: 25s - loss: 2.2170 - accuracy: 0.2 - ETA: 25s - loss: 2.2160 - accura - ETA: 24s - loss: 2.2109 - accuracy: 0.227 - ETA: 24s - loss: 2.2110 - accuracy: 0.2 - ETA: 24s - loss:  - ETA: 21s - loss - ETA: 15s - loss:  - ETA: 12s - loss: 2.1698 - accura - ETA: 12s - los - ETA: 0s - loss: 2.1\n",
      "Epoch 2/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 1.7324 - accuracy: 0.4306 - val_loss: 1.5902 - val_accuracy: 0.4726\n",
      "Epoch 3/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 1.5399 - accuracy: 0.5018 - val_loss: 1.4735 - val_accuracy: 0.4845\n",
      "Epoch 4/100\n",
      "1472/1472 [==============================] - 65s 44ms/step - loss: 1.3961 - accuracy: 0.5561 - val_loss: 1.4781 - val_accuracy: 0.4821\n",
      "Epoch 5/100\n",
      "1472/1472 [==============================] - 65s 44ms/step - loss: 1.2948 - accuracy: 0.5924 - val_loss: 1.5219 - val_accuracy: 0.5263\n",
      "Epoch 6/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 1.2092 - accuracy: 0.6212 - val_loss: 1.3650 - val_accuracy: 0.5668  - ETA: 26s - loss: 1.2247 - acc \n",
      "Epoch 7/100\n",
      "1472/1472 [==============================] - 65s 44ms/step - loss: 1.1441 - accuracy: 0.6446 - val_loss: 1.3761 - val_accuracy: 0.5800\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472/1472 [==============================] - 66s 45ms/step - loss: 1.0759 - accuracy: 0.6670 - val_loss: 1.4470 - val_accuracy: 0.5621\n",
      "Epoch 9/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 1.0357 - accuracy: 0.6822 - val_loss: 1.2504 - val_accuracy: 0.6110ccuracy: 0. - ETA: 35s -  - ETA: 33s - loss - ETA: 13s - loss: 1.0348 - accuracy: 0.683 -  - ETA: 2s - los\n",
      "Epoch 10/100\n",
      "1472/1472 [==============================] - 67s 46ms/step - loss: 0.9907 - accuracy: 0.6964 - val_loss: 1.2779 - val_accuracy: 0.6074\n",
      "Epoch 11/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.9547 - accuracy: 0.7099 - val_loss: 1.1768 - val_accuracy: 0.6432 - los\n",
      "Epoch 12/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.9209 - accuracy: 0.7195 - val_loss: 1.3362 - val_accuracy: 0.6098\n",
      "Epoch 13/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.8875 - accuracy: 0.7309 - val_loss: 1.2699 - val_accuracy: 0.6337\n",
      "Epoch 14/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.8651 - accuracy: 0.7376 - val_loss: 1.2483 - val_accuracy: 0.6396\n",
      "Epoch 15/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.8409 - accuracy: 0.7443 - val_loss: 1.4387 - val_accuracy: 0.5955\n",
      "Epoch 16/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.8169 - accuracy: 0.7504 - val_loss: 1.2914 - val_accuracy: 0.6134\n",
      "Epoch 17/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.8003 - accuracy: 0.7572 - val_loss: 1.1974 - val_accuracy: 0.6313 57s - loss: 0.8043 - accuracy: 0.7 - ETA: 57s - loss: 0.\n",
      "Epoch 18/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.7820 - accuracy: 0.7623 - val_loss: 1.2359 - val_accuracy: 0.6384 - loss: - ETA: 58s - loss: 0.7849 - accu - ETA: 53s - loss: 0.7744 - - ETA: 29s - loss: 0.7699 - accuracy:  - ETA: 29s -  -  - ETA: 1s - loss: 0.7834  - ETA: 1s - loss: 0.781 - ETA: 0s - loss: 0.7804 - accuracy\n",
      "Epoch 19/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.7623 - accuracy: 0.7699 - val_loss: 1.3522 - val_accuracy: 0.6289ss: 0.7563 - accurac - ETA: 53s - loss: 0.7543 - accuracy: 0.7 - ETA: 53 - ETA: 50s - loss: 0.762 - ETA: 41s - loss: 0.7569 - ETA: 39s - loss: 0.75 - ETA: 37s - loss: 0.7\n",
      "Epoch 20/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.7488 - accuracy: 0.7737 - val_loss: 1.3042 - val_accuracy: 0.6337loss: 0.7363 - accur - ETA: 50s - loss: 0.7358 - accuracy: 0 - ETA: 50s - loss: 0. - E - ETA: 26s - loss: 0.7499 - accuracy:  \n",
      "Epoch 21/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.7338 - accuracy: 0.7762 - val_loss: 1.2453 - val_accuracy: 0.63018  - ETA: 57s - loss: 0.7800 - accuracy: 0.76 -  - ETA: 53s - loss: 0.76 - ETA: 51s - loss: 0.7659 - accura - ETA: 50s - loss: 0.7672 - accurac - ETA: 39s - loss: 0.7283 - acc - ETA: 38s - loss: 0.7261 - accurac - ETA: 37s - loss: 0.7307 - accuracy: 0. - ETA: 37s - loss: 0.7307 - ETA: 31s - loss: 0.7242 - a - ETA: 30s - l - ETA: 28s - loss: 0.7247 - accuracy: 0.777 - ETA: 28s - loss - ETA: 25s - loss: 0.7204 - accuracy: 0.77 - ETA: 25s - loss: 0.7213 - ETA: 20s - loss: 0.7267 - accur - ETA: 19s - loss: 0.7258 - accuracy:  - ETA: 19s - loss: 0.7281 - a  - ETA - ETA\n",
      "Epoch 22/100\n",
      "1472/1472 [==============================] - 67s 46ms/step - loss: 0.7187 - accuracy: 0.7826 - val_loss: 1.2158 - val_accuracy: 0.6444 ETA: 43s - loss: 0. - ETA: 41s - loss: 0.7078 - accuracy: 0. - ETA: - ETA:  - ETA: 27s - - ETA: 25s - loss: 0.7172 - accur - ETA: 20s - loss: 0.7199 - ETA: 19s - loss: 0.7203 - accuracy: 0.782 - E\n",
      "Epoch 23/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.7151 - accuracy: 0.7817 - val_loss: 1.2056 - val_accuracy: 0.6468oss: 0.7151 - accuracy:  - ETA: 2s - loss: 0.7146 - ac - ETA: 1s - l - ETA: 0s - loss: 0.7159 - \n",
      "Epoch 24/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6947 - accuracy: 0.7902 - val_loss: 1.2594 - val_accuracy: 0.6480\n",
      "Epoch 25/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6859 - accuracy: 0.7928 - val_loss: 1.1505 - val_accuracy: 0.65517s - loss: 0.6918 - accuracy - ETA: 56s - loss: 0.6912  - ET\n",
      "Epoch 26/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6728 - accuracy: 0.7955 - val_loss: 1.2276 - val_accuracy: 0.6647\n",
      "Epoch 27/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6650 - accuracy: 0.7971 - val_loss: 1.1444 - val_accuracy: 0.6504ETA: 59s - loss: 0.63 - ETA: 54s -  - ETA: 51s - loss: 0.6621 - accuracy: - ETA: 47s - loss:  - ETA: 45s - loss: 0.6591 - accuracy: 0 - ETA: 45s - loss: 0. - ETA: 39s - loss: 0.6641 - accuracy:  - ETA: 39s - loss: 0.6658 - accuracy:  - ETA: 38s - l - ETA: 29s - loss - ETA: 27s - loss: - ETA: 24s - loss: 0.6633 -  - ETA: 23s - loss: 0.6605 - accurac - ETA: 22s - loss: 0.6612 - accuracy: 0 - ETA: 22s  - ETA: 16s - loss: 0.6582 - ETA: 14s - loss: - ETA: 12s - l - ETA: 6s - loss: 0.6618 - ac - ETA: 5s - los - ETA: 4s - loss: 0.6621 - ac - ETA: 2s - loss: 0.6620 - accuracy:  - E - ETA: 0s - loss: 0.6640 - ac\n",
      "Epoch 28/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6564 - accuracy: 0.8007 - val_loss: 1.2020 - val_accuracy: 0.6563TA: 1:00 - loss: 0.6329 - ac - ETA: 1:00 - loss: 0.637 - ETA: 58s - loss: 0.6348 - a - ETA: 57s - loss: 0.6406 - - ETA: 56s - loss - ETA: 32s - l - ETA: 30s - lo - ETA: 2 - ETA: 21s - loss: 0.6512 - accurac - ETA: 20s - loss - ETA: 1\n",
      "Epoch 29/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6422 - accuracy: 0.8038 - val_loss: 1.3597 - val_accuracy: 0.6432 - accurac - ETA: 58s - loss: 0.6074 - accuracy: 0. - ETA: 57s -  - ETA: 44s - loss: - ETA: 42s -  - ETA: 39s - loss: 0.6249 - accuracy: 0 - ETA: 39s - loss: 0.6282 - a - ETA: 38s - loss: 0.63 - ETA: 36s - loss: 0.626  - ETA: 20s - ETA: 13s - loss: 0.6338 - a - ETA: 12s - loss: 0.63 - ETA: 8s - loss: 0.6363 - accura - E - ETA: 4s - loss: 0.6387 - accu - ETA: 4s - l - ETA: 3s - loss: 0.6 - ETA: 0s - loss: 0.6422 - ac\n",
      "Epoch 30/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6368 - accuracy: 0.8049 - val_loss: 1.2913 - val_accuracy: 0.6444A: 20s - loss: 0.6337 - accuracy: 0.8 - ETA: 20s - loss:  - ETA: 18s - loss: 0.6332 - accuracy - ETA: 17s - loss: 0.6355 - accuracy: 0.805 - ETA: 17s - loss: 0\n",
      "Epoch 31/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6289 - accuracy: 0.8081 - val_loss: 1.3398 - val_accuracy: 0.64080.6345 - \n",
      "Epoch 32/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6215 - accuracy: 0.8108 - val_loss: 1.4574 - val_accuracy: 0.6002A: 45s - loss: 0.6095 - accuracy: 0 - ETA: 44s - l - ETA: 42s - loss: 0.61 - ETA: 37s - loss: 0.62 -  - ETA: 1s - l\n",
      "Epoch 33/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6170 - accuracy: 0.8110 - val_loss: 1.2302 - val_accuracy: 0.6611s - ETA: 2 - ETA: 4s - loss: 0.6148 -  - ETA: 0s - loss: 0.6170 - accuracy\n",
      "Epoch 34/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6071 - accuracy: 0.8137 - val_loss: 1.3013 - val_accuracy: 0.6134ccuracy - ETA: 32s - loss: 0.60 - ETA: 31s - l - ET - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.6074 - accura\n",
      "Epoch 35/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.6013 - accuracy: 0.8150 - val_loss: 1.3695 - val_accuracy: 0.6348\n",
      "Epoch 36/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.5967 - accuracy: 0.8165 - val_loss: 1.1148 - val_accuracy: 0.6683 - l - ETA: 1:06 - ETA: 1:00 - loss: 0.6031 - accuracy: 0.81 - ETA: 1:00 - loss: 0.6038 - ac -  - ETA: 56s - loss: 0.6 - ETA: 54s - l  - ETA: 9s - loss: 0.5949  - ETA: 9s - loss: 0.5952 - accuracy: 0. - ETA: 9s - loss: 0.595 - ETA: 8s - loss: 0.5939 - accura - ETA: 7s - loss: - ETA: 3s - loss: 0.5951  - ETA: 2s - loss: 0.5946 - ac\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5865 - accuracy: 0.8202 - val_loss: 1.2528 - val_accuracy: 0.6504- los\n",
      "Epoch 38/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5812 - accuracy: 0.8209 - val_loss: 1.4601 - val_accuracy: 0.6002loss: 0.5642 - - ETA: 53s - loss: 0.5835 - accuracy: 0.818 - ETA: 53s - lo - ETA: 47s - loss: 0.5955 - a - - ETA: 2s - loss: 0.5835 - accuracy: 0. - ETA: 2s - loss: 0.5837 - ac - ETA: 1s - loss: 0.5832 - accuracy: 0. - ETA: 1s - loss: 0.5827 - accuracy: 0.82 - ETA: 1s - loss: 0.5827 - accuracy - ETA: 1s -\n",
      "Epoch 39/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5735 - accuracy: 0.8239 - val_loss: 1.2243 - val_accuracy: 0.6146\n",
      "Epoch 40/100\n",
      "1472/1472 [==============================] - 67s 45ms/step - loss: 0.5708 - accuracy: 0.8260 - val_loss: 1.3063 - val_accuracy: 0.62650.5805 - accur - ETA: 39s - loss: 0.5760 - accuracy: 0 - ETA: 38s - loss: 0.5751 - accuracy - ETA: 37s - loss: 0.5765 - a - ETA: 36s - loss:  - ETA: 34s - loss: 0.5776 - a - ETA: 33s - loss: 0.5774 -  - ETA: 32s - l - ETA: 29s - l - ETA: 27s - loss: 0.5801 - accurac - ETA: 26s - loss: 0.5795 - accuracy: 0.82 - ETA: 26s - lo -  - ETA: 16s - loss: 0.5768 - accuracy - ETA: 15s - loss: 0.5766 -  - ETA: 14s - loss: 0.5773 - ETA: 13s - loss:  - ETA: 11s - loss: 0 - ETA: 9s - loss: 0.5760 -  - ETA: 7s - ETA: 3s - loss: 0.572 - ETA: 3s - loss: 0.5732  - ETA: 0s - loss: 0.5720 - \n",
      "Epoch 41/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5629 - accuracy: 0.8267 - val_loss: 1.2181 - val_accuracy: 0.6408accuracy:  - ETA: 42s - loss: 0.5522 -  - ETA: 40s - loss: 0. - ETA: 35s - loss: 0.5 - ETA: 33s - loss: 0. - ETA: 31s - loss: 0.5530 - accuracy - ETA: 30s - loss: 0.5537 -  - ETA: 29s - loss: 0.5539 - accuracy:  - ETA: 29\n",
      "Epoch 42/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5636 - accuracy: 0.8273 - val_loss: 1.3562 - val_accuracy: 0.6169 ETA: 3s - loss: 0 - ETA: 0s - loss:\n",
      "Epoch 43/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5581 - accuracy: 0.8284 - val_loss: 1.1685 - val_accuracy: 0.65994s - loss: 0.5617 - accuracy:  - ETA: 54s - loss: 0.5580 - accuracy: 0.82 - ETA: 53s -  - ETA: 47s - l - ETA: 45s - loss: 0.5 - ETA: 43s - loss: 0.5510 - accuracy - ETA: 42s - loss: 0.5525 - accuracy: 0. - ETA: 42s - - ETA: 32s - loss: 0.5525 - accuracy: 0.829 - ETA: 32s - loss: - ETA: 26s - loss: 0.5579 -  \n",
      "Epoch 44/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5509 - accuracy: 0.8314 - val_loss: 1.1428 - val_accuracy: 0.6623 56s - loss: 0.5150 - accuracy: 0.841 - ETA: 56s - loss -  - ETA: 25s - loss: 0.5495 - a - ETA: 24s - loss: 0.5494 - accuracy: 0.83 - ETA: 24s - loss: 0.5491 - accura - ETA: 23s - l - ETA: 20s - loss: 0.5486 - acc - ETA: 4s - loss: 0.5490 -  - E\n",
      "Epoch 45/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5438 - accuracy: 0.8332 - val_loss: 1.1901 - val_accuracy: 0.6384A: 58s - loss: 0.5619 - accura - ETA: 57s - loss: 0.5615 - accuracy: 0. - ETA: 57s - loss: 0.5620 - accuracy: 0.827 - ET - ETA: 46s - loss\n",
      "Epoch 46/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5421 - accuracy: 0.8339 - val_loss: 1.1973 - val_accuracy: 0.6313s: 0.5416 - accuracy: 0.83\n",
      "Epoch 47/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5399 - accuracy: 0.8334 - val_loss: 1.2895 - val_accuracy: 0.6086TA: 50s - l - ETA: 44s - lo - ETA: 42s - loss: 0.5300 - accuracy:  - ETA: 41s - los - ETA: 39s - loss: 0.5294 - a - ETA: 38s - los - ETA: 32s - loss: 0.5286 - accurac - ETA: 31s - loss: 0.5287 - accuracy:  - E - ETA: 27s - loss: 0.5317 - accuracy:  - ETA: - ET - ETA: 17s - loss:\n",
      "Epoch 48/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5371 - accuracy: 0.8349 - val_loss: 1.2392 - val_accuracy: 0.6181\n",
      "Epoch 49/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5287 - accuracy: 0.8371 - val_loss: 1.1969 - val_accuracy: 0.6253: 23s - loss: 0.5283 - accuracy:  - ETA: 22s - loss: 0.5 - ETA: - ETA: 14s - loss: 0.5299 - a - ETA: 7s - loss: 0.5 - ETA: 1s - l - ETA: 0s - loss: 0.5279 - \n",
      "Epoch 50/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5238 - accuracy: 0.8394 - val_loss: 1.2097 - val_accuracy: 0.6337\n",
      "Epoch 51/100\n",
      "1472/1472 [==============================] - 66s 45ms/step - loss: 0.5233 - accuracy: 0.8391 - val_loss: 1.2516 - val_accuracy: 0.6599\n",
      "Evaluating model...\n",
      "ROC: 0.942\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.65\n",
      "F-Score: 0.65\n",
      "\n",
      "*** Train on {1, 2, 4, 6, 7, 8, 9} Validate on 3 Test on 5 ***\n",
      "val shape:  (925, 128, 128, 1)\n",
      "test shape:  (936, 128, 128, 1)\n",
      "train shape:  (144291, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1443 steps, validate for 10 steps\n",
      "Epoch 1/100\n",
      "1443/1443 [==============================] - 73s 51ms/step - loss: 2.1382 - accuracy: 0.2636 - val_loss: 1.8049 - val_accuracy: 0.4338 48s - loss: 2.3315 - accuracy: 0.1 - ETA: 47s - loss: 2.3287 - accuracy: 0.1 - ETA: 47s - loss: 2.3279 - accuracy: - ETA: 46s - loss: 2.3266 - accuracy: - ETA: 46s - loss: 2.3220 - accuracy: 0. - ETA: 45s - loss: 2.3210 - accuracy: 0. - ETA: 45s - loss: 2.3179 - accuracy: 0 - ETA: 44s - loss: 2.3154 - accuracy: - ETA: 44s - loss: 2.3114  - ETA: 42s - loss: 2.2987 - accuracy: 0.19 - ETA: 42s - loss: 2.2984 - accuracy: - ETA: 41s - loss: 2.2971 - accuracy: 0.19 - ETA: 41s - lo - ETA: 34s - loss: 2.2722 - accura - ETA: 33s - loss: 2.2 - ETA: 32s - loss: 2.2625 - accurac - ETA: 31s - loss: 2.2573 - accuracy: 0. - ETA: 30s -  - ETA: 28s - loss: 2.2467 - ac - ETA: 26s - loss: 2.23\n",
      "Epoch 2/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 1.7486 - accuracy: 0.4218 - val_loss: 1.6452 - val_accuracy: 0.4808- loss: 1.879 - ETA: - ETA: 54s - loss: 1.8512 - - ETA - ETA: 45s - loss: 1.8283 - a - ETA: 44s - loss: 1.8252 - accuracy: 0 - ETA: 43s - loss: 1.8286 -  - ETA: 42s - loss: 1.8243 - accura - ETA: 23s - loss:  - ETA: 21s - loss: 1. - ETA: 19s - loss: 1.7835 - accu - ETA: 18s - loss: 1.7831 - accuracy: 0.4 - ETA: 18s  - E - - ETA: 0s - loss: 1.7487 - accuracy: \n",
      "Epoch 3/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 1.5575 - accuracy: 0.4969 - val_loss: 1.4549 - val_accuracy: 0.5288cy: 0.4 - ETA: 54 - ETA: 52s - loss: 1.6295 - accuracy - ETA: 51s - loss: 1 - ETA: 49s - loss: - ETA: 43s -  - ETA: 41s - ETA: 38s - loss: - ETA: 36s - loss: 1.5840 - accurac - ETA: 35s - loss: 1\n",
      "Epoch 4/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 1.4126 - accuracy: 0.5494 - val_loss: 1.3307 - val_accuracy: 0.5577s:  - ETA: 58s - loss: 1.4942 - accuracy:  - ETA: 57s - loss: 1.4973 - accuracy: 0. - ETA: 57s - loss: 1.4899  - ETA: 56s - loss: 1.4733 - accuracy: 0.53 - ETA: 55s - loss: 1.4725 - accuracy: 0. - ETA: 55s - loss: 1.4762 - a - ETA: 54s - loss: 1.4615 - accuracy - ETA: 53s - loss: 1.4621 - accuracy: 0 - ETA: 53s - loss: 1.4599  - ETA: 51s - loss: 1.4740 - accuracy - ETA: 40s -  - ETA: 37s  - ETA: 31s - loss: 1.4360 - accur - ETA: 30s - loss: 1.4318 - - ETA: 2 - ETA: 21s - loss: 1.4244 - accuracy: 0.5 - ETA: 21s - loss: 1.4260 - ac - ETA: 20s  - ETA: 2s - loss: 1.4155  - ETA: 2s - l - ETA: 0s - loss: 1\n",
      "Epoch 5/100\n",
      "1443/1443 [==============================] - 66s 46ms/step - loss: 1.3057 - accuracy: 0.5900 - val_loss: 1.1920 - val_accuracy: 0.629325 - accur - ETA: 56s - loss: 1.3038 - accuracy: 0.593 - ETA: 56s - loss: 1.3082  - ETA: -  - ETA: 48s - loss: 1.3229  - ETA: 47s - loss: 1.3275 - accuracy - ETA: 46s - loss: 1.3296 - accuracy: 0.58 - - ETA: 43s - loss: 1.3384 - accuracy: 0 - ETA: 0s - loss: 1.3060 - accu\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443/1443 [==============================] - 65s 45ms/step - loss: 1.2229 - accuracy: 0.6169 - val_loss: 1.0935 - val_accuracy: 0.68069s - loss: 1.253 - ETA: 43s - loss: 1.2622 - ac - ETA: 42s - loss: 1 - ETA: 40s - loss: 1.2597 - accuracy: 0.602 - ETA: 40s - loss: 1.2607 - accurac - ETA: 39s - lo - ETA: 37s - loss: 1.2553 - ac - ETA: 32s - loss:  - ETA: 30s - loss: 1.2392 - accuracy - ETA: 29s - loss: 1.2384 -  - ETA: 28s - loss: 1.2379 - a - ETA: 27s - loss: 1.2325 - ac - ETA: 26s - loss: 1.23 - ETA: 24s - loss: 1.2327 - accuracy: 0.611 - ETA: - ETA: 21s - loss: 1.2303 - accu - ETA: 20 - ETA: 13s -  - ETA:  - ETA: 0s - loss: 1.2236 - accuracy: \n",
      "Epoch 7/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 1.1542 - accuracy: 0.6411 - val_loss: 1.0084 - val_accuracy: 0.7030 - ETA: 39s - loss: 1.1652 - accuracy: 0.6 - ETA: 39s - loss: 1.1663 - accuracy: 0. - ETA: 39s - loss: 1.1 - ETA: 37s - loss: 1.1603 - accuracy: 0.638 - ETA: 37s - loss: 1.1596 -  - ETA: 35 - ETA - ETA: 1s - - ETA: 0s - loss: 1.1546 - accuracy: \n",
      "Epoch 8/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 1.0965 - accuracy: 0.6626 - val_loss: 0.9756 - val_accuracy: 0.7276 29s - loss: 1.1086 - a - ETA: 28s - loss: \n",
      "Epoch 9/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 1.0494 - accuracy: 0.6765 - val_loss: 0.9151 - val_accuracy: 0.7564ETA: 4 - ETA: 42s - loss: 1.0662 - accuracy:  - ETA: 41s - loss: - ETA: 39s - loss: 1.0625 - ETA: 38s - loss: 1.0610 - accuracy: 0.67 - ETA: 38s - loss: 1.0600 - accuracy:  - E - ETA: 2s - loss: 1.0510 - ac\n",
      "Epoch 10/100\n",
      "1443/1443 [==============================] - 66s 45ms/step - loss: 1.0042 - accuracy: 0.6929 - val_loss: 1.0799 - val_accuracy: 0.6496 - ETA: 1:00 -  - ETA: 42s - loss: 1.0117 - accura - ETA: 41s - ETA: 35s - loss: 1.0166 - a - ETA: 34s - loss: 1.0177 - accu - ETA: 33s - loss:  - ETA: 27s - loss: 1.0104 - accuracy: 0 - ETA: 27s - loss: 1.0108 -  - ETA: 25s - loss: 1.0113 - accuracy: 0.68 - ETA: 25s - loss: 1.0120 -  - ETA: 24s -  - ETA: 21 - ETA: 19s - loss: 1.0124  - ETA: 17s - loss: 1.0125 - - ETA: 3s - loss: 1.0043 - accu - E\n",
      "Epoch 11/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.9655 - accuracy: 0.7041 - val_loss: 0.8904 - val_accuracy: 0.7671 - ETA: 57s - loss: 0.9671 - accur - ETA: 56s - loss: 0.9786 - accuracy:  - ETA: 56s - loss: 0.9745 - accurac - ETA: 55s - loss: 0.962 - - ETA: 50s - loss: 0.9589 - accuracy:  - ETA: 49s - loss: 0.9560 -  - ETA: 41s - loss: 0.9557 - accura - ETA: 40s - loss: 0.95 - ETA: 38s - loss: 0.9526 - accuracy: 0.7 - ETA: 38s - lo - ETA: 36s - loss: 0.9602 - ac - ETA: 34s - loss: 0.9628 -  - ETA: 33s - loss: 0.9645 - a - ETA: 32s - los - ETA: 30s - loss: 0.9671 - accuracy: 0.702 - ETA: 2 - ETA: 27s - loss: 0.9706 - a - ETA: 25s  - ETA: 23s - loss: 0.9648 - accu - ETA: 22s - loss: 0.9642 - accuracy:  - ETA: 21s - loss: 0.9636 - ac - ETA: 20s - loss: 0.9644 - accu - ETA: 19s - loss: 0.9638 - accurac - ETA: 18s - loss: 0.9660 - accuracy: 0 - ETA: 18s - ETA: 15s - - ETA: 13s - loss: 0.9 - ETA: 3s - - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.9639 - accu - ETA: 0s - loss: 0.9641 - \n",
      "Epoch 12/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.9359 - accuracy: 0.7142 - val_loss: 0.8465 - val_accuracy: 0.7500 - ETA: 34s - loss: 0.9405 - accuracy: 0.7 - ETA: 34s - loss: 0.9391 - accura - ETA: 30s - loss: 0.9448 - accurac - ETA: 29s - loss: 0.9475 - accuracy: 0 - ETA: 29s - loss: 0.9472 - accuracy - ETA: 28s - loss: - ETA: 26s - loss: - ETA: 24s - loss: 0.9428 - accur - ETA: 23s - loss: 0.9408 - accurac - ETA: 22s - loss: 0.9428 - accuracy - ETA: 21s - loss: 0.9417 - accurac - ETA: 21s - loss: 0.94 - ETA: 19s - loss: 0.9451 - - ETA: 18s - loss: 0.94 - - ETA: 4s - loss: 0.9390 - accuracy - ETA: 3s - loss: 0 - ETA: 1s - loss: 0.9362 - accuracy: 0.71 - ETA: 1s - loss: 0.9363  - ETA: 0s - loss: 0.9364 - accuracy: 0.71 - ETA: 0s - loss: 0.9363 - accuracy\n",
      "Epoch 13/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.9061 - accuracy: 0.7234 - val_loss: 1.0570 - val_accuracy: 0.70620.8782 - - ETA: 41s - loss: 0.8823 - accuracy - ETA: 33s - loss: - ETA: 31s - loss: 0.8855 - acc - ETA: 3s - - ETA: 0s - loss: 0.9054 - accu\n",
      "Epoch 14/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.8771 - accuracy: 0.7317 - val_loss: 0.8176 - val_accuracy: 0.7479s - loss: 0.8715 - accuracy: 0.734 - ETA: 50s - loss: 0.8719 - accurac - ETA: 50s - lo - ETA: 47s - loss: 0.8658 - a - E - ETA: 43s - loss: - ETA: 41s - loss: 0.8708  - ETA: - ETA: 33s - loss: 0.8680 - accu - ETA: 32s - loss: 0.87 - ETA: 30s - - ETA: 27s - loss: 0.8727  - ETA: 26s - loss - ETA: 13s - loss: 0.8654 - accura - - ETA: 7s - loss: 0.8729 - accura - ETA: 5s - loss: 0.875 - ETA: 1s - loss: 0.8748 - accura - ETA: 0s - loss: 0.8748 -  - ETA: 0s - loss: 0.8769 - accuracy: \n",
      "Epoch 15/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.8520 - accuracy: 0.7403 - val_loss: 0.8576 - val_accuracy: 0.7479s - loss: 0.8590 - - ETA: 50s - loss: 0.8707 - accuracy: 0 - ETA: 50s - loss: 0.8680 - accuracy: 0 - ETA: 49s - loss: 0.8678 - a - ETA - ETA: 41s - loss: 0  - ETA: 36s - loss: 0.8549 -  - ETA: 34s - loss: 0.856 - ETA: 33s - los - ETA: 30s - loss: 0.8514 - accur - ETA: 30s - loss: 0.8510 - accuracy: 0. - ETA: 29s -  - ETA: 23s - loss: 0.856 - ETA: 2 - ETA: 18s - loss: 0.8597 - accuracy: 0.737 - ETA: 18s - loss: 0.8594 - - ETA: 17s - loss: 0.8 - ETA: 0s - loss: 0.8521 - accuracy: 0.74\n",
      "Epoch 16/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.8306 - accuracy: 0.7472 - val_loss: 0.8703 - val_accuracy: 0.7457TA: 58s - loss: 0.8350 - accura - - ETA: 53s - los - ETA: 51s - loss: 0.8374 - accuracy:  - ETA: 50s - loss: 0.8347 - accuracy: 0. - ETA: 50s - loss: 0.8343 - accurac - ETA: 46s - loss: 0.8450 - accuracy:  - ETA: 45s - loss: 0.84 - ETA: 44s - loss: 0.8409 - accuracy:  - ETA: 43s - loss: 0.8406 - accuracy:  - ETA: 43s - loss: 0.8385 - accuracy: 0 - ETA: 42s - loss: 0. - ETA: 37s - loss: 0.8399 - - ETA: 28s - loss: 0.8428 - accuracy: 0.7 - ETA: 28s - loss: 0.84 - ETA: 26s - loss: 0.8 - ETA: 24s - loss: 0.8395 - accuracy:  - ETA: 24s - loss: 0.8393 - a - ETA: 22s - loss: 0.8384 - ac - ETA: 21 - ETA: 15s - loss: 0.8381 - accuracy:  - ETA: 3s - loss: 0.8327 - accuracy:  - ETA: 2s - loss:\n",
      "Epoch 17/100\n",
      "1443/1443 [==============================] - 66s 45ms/step - loss: 0.8124 - accuracy: 0.7528 - val_loss: 0.9170 - val_accuracy: 0.7532ss: 0.8076 - ETA: 48\n",
      "Epoch 18/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.7903 - accuracy: 0.7597 - val_loss: 1.0133 - val_accuracy: 0.7329- accuracy - ETA: 58s - loss: 0.7974 - accuracy: 0.7 - ETA: 58s - loss: 0.7869 - accurac - ETA: 50s - loss: 0.7631 - accuracy: 0 - ETA: 49s - loss: 0.7697 - accura - ETA: 49s - loss: 0.7720 - ETA: 43s - - ETA: 41s - loss: 0.7774 - accura - E - ETA: 29s - loss: 0.7871 - accura - ETA: 2 - ETA: 26s - loss: 0.7864 - accuracy: 0. - ETA: 25s - los - ETA: 1s - loss: 0.7917 - accuracy: 0.\n",
      "Epoch 19/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.7775 - accuracy: 0.7635 - val_loss: 0.9817 - val_accuracy: 0.7233ETA: 0s - loss: 0.7773 - accuracy: \n",
      "Epoch 20/100\n",
      "1443/1443 [==============================] - 66s 45ms/step - loss: 0.7550 - accuracy: 0.7701 - val_loss: 0.8678 - val_accuracy: 0.7404ss: 0.7624 - accuracy: 0.7 - ETA: 47s - loss: 0.7643 - accurac - ETA: 46s - loss: 0.76 - ETA: 44s - loss: 0.75 - ETA: 42s - loss: - ETA: 5s - - ETA: 0s - loss: 0.7550 - accuracy: \n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.7406 - accuracy: 0.7753 - val_loss: 0.8819 - val_accuracy: 0.7361098 - - ETA: 41s - loss: 0.7145  - ETA: 39s - loss: 0.7241 - accurac - ETA: 38s - loss: 0.7250 - accuracy: - ETA: 38s - loss: 0.7256 - accuracy: 0.7 - ETA: 38s - loss: 0.7245 - acc - ETA: 37s - loss: 0.732 - ETA: 35s - loss: 0.7267 - accu - ETA: 34s - loss: 0.7275 - accur - ETA: 33s - loss: 0.72 - ETA: 28s - loss: 0.7313 - accuracy:  - ETA: 27s - loss: 0.7312 - accu - ETA: 26s - - ETA: 20s - loss: 0.7360 - accura - ETA: 19s - loss: 0.7358 - - ETA: 1s\n",
      "Epoch 22/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.7313 - accuracy: 0.7772 - val_loss: 0.8569 - val_accuracy: 0.7447445 - accuracy: 0.77 - E - ETA: 53s - loss: 0.7552 - accuracy: 0 - ETA: 53s - loss: 0.7 - ETA: 47s - loss: 0.7582 - acc - ETA: 46s - loss: 0.7549 -  - ETA: 45s - loss: 0.7448 - accura - ETA: 44s - loss: 0.7416 - accur - ETA: 43s - loss: 0.7484 - accur - ETA: 42s - loss: 0.7526 - accuracy:  - ET - ETA: 13s - loss: 0.7302 - ac - ETA: 5s - l - ETA: 2s - loss: 0.7318 - ac - ETA: 2s - loss: 0.7309 - accu -\n",
      "Epoch 23/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.7160 - accuracy: 0.7808 - val_loss: 0.9150 - val_accuracy: 0.7415loss: 0.7240 - accuracy: 0.777 - ETA: 59s - loss: 0.7204 - accurac - ETA: 58s - loss: 0.7205 - accu - ETA: 57s - loss: 0.7154 - accurac - ETA: 5 - ETA: 53s - l - ETA: 5 - ETA: 48s - loss - ETA: 46s - loss: - ETA: 44s  - ETA: 41s - loss: 0.7107 - a - ETA: 40s - loss: 0.7137 - accuracy: 0.783 - ETA: 21s - loss: 0.7156 - - ETA: 20s - loss: 0.7168 - a - ETA: 19s - loss: 0.7166 - accuracy: 0 - ETA: 18s - loss: 0.7177 - ac - ETA: 17s - loss: 0 - ETA: 15s - loss: 0.7 - ETA: 10s - loss: 0. - ETA: 7s - loss: 0.7188  - ETA: 6s - loss: 0.717 - ETA: 5s - loss: 0.7177 - ac - ETA: 5s - loss: 0.7 - ETA: 0s - loss: 0.7172 - accu - ETA: 0s - loss: 0.7166 - accura\n",
      "Epoch 24/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.7003 - accuracy: 0.7868 - val_loss: 0.8430 - val_accuracy: 0.7382loss: 0.6686 - ETA: 44s - loss: 0.6871  - ETA: 38s - loss: 0.6929 - accura - ETA: 38s - loss: 0.6934 - accuracy: 0.79 - ETA: 37s - loss: 0.6934 - accur\n",
      "Epoch 25/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.6902 - accuracy: 0.7891 - val_loss: 0.8020 - val_accuracy: 0.7788s: 0.6744 - accurac - ETA: 48s - loss: 0.6738 - a - ETA: 47s - loss: 0.6865 - accuracy:  - ETA: 46s - loss: 0.6919 - accuracy: 0.7 - ETA: 46s - loss: 0. - ETA: 44s - loss: 0.6913 - accura - ETA: - ETA: 36s - loss: 0.6930 - accur - ETA: 36s - loss: 0.6946 -  - ETA: 34s - loss: 0.6 - ETA: 33s - loss: 0.69 - ETA: 31s - loss: 0.6925 - accur - ETA: 30s - loss: 0.6930 - accuracy: 0.7 - ETA: 30s - loss: 0.6929 - accuracy: 0 - ETA: 29s - - ETA: 9s - ETA: 2s - ETA: 1s - loss: 0.689 - ETA: 0s - loss: 0.6909 - accu\n",
      "Epoch 26/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.6787 - accuracy: 0.7926 - val_loss: 0.8748 - val_accuracy: 0.7564.6906 - accuracy:  - ETA: 44s - - ETA: 37s - loss: 0.68 - ETA: 36s - ETA: 29s - loss: 0.6 - ETA: 27s - loss: 0.6831 - accuracy:  - E - ETA: 16s - loss: 0.6807 -  - ETA: 15s - loss: 0.6823 - accuracy: 0 - ETA: 15s - loss: 0.6823 - ac - ETA: 13s - loss: 0.6824 - accuracy: 0 - ETA: 13s  - ETA: 6s - loss: - ETA: 5s - loss: 0.679 - ETA: 4s - los - ETA: 1s - l - ETA: 0s - loss: 0.6781 - \n",
      "Epoch 27/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.6713 - accuracy: 0.7955 - val_loss: 0.8477 - val_accuracy: 0.7489: 0.6493 - accuracy: 0 - ETA: 47s - loss: 0.6524 - accuracy: 0 - ETA: 47s - loss: 0.6520 - a - ETA: 42s - loss: 0.6573 - accu - ETA: 4 - ETA: 38s - loss: 0.6576 - accuracy: 0.79 - ETA: 38s - l - ETA: 35s - loss: 0. - ETA: 30s - loss: 0.6753 - a - ETA:  - ETA: 18s - loss: 0.6729 - - ETA: 17s - los - ETA: 14s - loss: 0.6697 - accuracy: - ETA: 10s - loss: 0.6687  - ETA: 9s - loss: 0.6679  - ETA: 8s - loss: 0.6 - ETA: 7s - loss: 0.6698 - accu - ETA: 7s - los - ETA: 6s - loss: 0.6721 - accuracy:  - ETA: 4s - loss: 0.6 - ETA: 3s - loss: 0.6718 -  - ETA - ETA: 1s - los\n",
      "Epoch 28/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.6557 - accuracy: 0.7999 - val_loss: 0.9179 - val_accuracy: 0.7404 ETA: 56s - loss: 0.6513 - accuracy: - ETA: 55s - loss: 0.6510 - accuracy: 0.802 - ETA: 55s - loss: 0.6489  - ETA: 54s - loss: 0.6434 -  - E - ETA: 49s - loss: 0.6518 - accuracy: - ETA: 48s - loss: 0.6520 - accurac - ETA: 48s - loss: 0.654 - ETA: 46s - loss: 0.6571 - accuracy: 0.801 - ETA: 46s - loss: 0.6570 - accuracy:  - ETA: 45s - loss - ETA - ETA:  - ETA: 33s - loss: 0.6597 - accuracy: 0.8 - - ETA: 26s - loss: 0.6669 - accuracy: 0.79 - ETA: 26s - loss: 0.6 - ETA: 24s - loss: 0.6666 - accuracy:  - ETA: 24s - loss: 0.6 - ETA: 22s - loss: 0.6  - ETA: 0s - loss: 0.656\n",
      "Epoch 29/100\n",
      "1443/1443 [==============================] - 66s 46ms/step - loss: 0.6486 - accuracy: 0.8008 - val_loss: 0.8045 - val_accuracy: 0.786355s - los - ETA: 48s - loss: 0.6458 - accuracy: 0. - ETA: 48s - l - ETA: 42s - loss: 0.6518 - - ETA: 40s - loss: 0.6494 - accuracy:  - ETA: 40s - loss: 0.6472 - accuracy:  - ETA: 39s - loss: 0.6457 - accurac - ETA: 39s - loss: 0.6492 - accuracy: 0.7 - ETA: 38s - loss: 0.6480 - accuracy: 0 - ETA: 38s - loss: 0.6488 - accuracy:  - E - ETA: 34s - loss: 0 - ETA: 32s - loss:  - ETA: 30s - loss: 0.6504 - ac - ETA: 29s - loss: 0.6517 - accura - ETA: 28s - loss: 0.6521 - accu - ETA: 27s - loss: 0.6514 - accu - ETA: 26s - loss: 0.65 - ETA: 17s - loss: 0.6466 - accurac - ETA: 16s - loss: 0.64 - ETA: 15s - loss: - ETA: 4s - loss: 0.6 - ETA: 3s - loss: 0.6490 - accu - ETA: 2s - loss: 0.6494 - accuracy:  - - ETA: 0s - loss: 0.647\n",
      "Epoch 30/100\n",
      "1443/1443 [==============================] - 66s 45ms/step - loss: 0.6438 - accuracy: 0.8019 - val_loss: 0.8434 - val_accuracy: 0.7564TA: 55s - loss: 0 - ETA: 49s - loss: 0.6589  - ETA: 48s - loss: 0.6572 - accuracy: 0.79 - ETA: 48s - loss: 0.6569 - accuracy: 0.798 - ETA: 47s - loss: 0.6595 - accurac - ETA: 47s - loss: 0.6579 - accuracy: 0 - ETA: 46s - loss: 0.6543 - a - ETA: 45 - ETA: 42s - loss: 0.6514 - accuracy: 0.801 - ETA: 42s - loss: 0.6516 - - ETA: 41s - loss: 0.6508 - accuracy: 0. - ETA: 40s - loss: 0.6496 - acc - ETA: - ETA: 36s - loss: 0. - ETA: 34s - loss:  - ETA: 32s - loss: 0 - ETA: 30s - loss: 0.6425 - accuracy: 0.803 - ETA: 30s - loss: 0.6424 - accuracy:   - ETA: 5s - los - ETA: 0s - loss: 0.643\n",
      "Epoch 31/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.6343 - accuracy: 0.8058 - val_loss: 0.9353 - val_accuracy: 0.75966372 - ac - ETA: 36s - loss: 0.6356 - accuracy:  - ETA: 36s - loss: 0.6369 - accuracy: - ETA: 35s - - ETA: 33s - loss: 0.63 - ETA: 31s - loss: 0 - ETA: 29s - loss: 0 - ETA: 27s - loss: 0.6380 - accuracy - ETA: 23s - lo - ETA: 13s - ETA\n",
      "Epoch 32/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.6257 - accuracy: 0.8085 - val_loss: 0.7956 - val_accuracy: 0.7778oss: 0 - ETA: 59s - loss: 0.6 - ETA: 39s - loss: 0.6292 - accuracy:   - ETA: 34s - loss: 0.6242 - accu - ETA: 22s  - ETA: 20s - loss: 0. - ETA: 18s - loss: 0.6271 - accuracy: 0. - ETA: 18s - loss: 0.6276 - accuracy: 0 - ETA: 17s - loss: 0.62 - ETA: 15s - loss: - ETA: 13s - loss: 0.6288 - accuracy:  - ETA: 13s - loss: 0. - ETA: 11s - loss: 0.6289 - accuracy:  - ETA: 10s - loss: 0.6281 - accu - ETA: 8s - loss: 0.6298 -  - ETA: 7s - loss: 0 - E - ETA: 1s -\n",
      "Epoch 33/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.6193 - accuracy: 0.8095 - val_loss: 0.8327 - val_accuracy: 0.7959TA: 1:00 - loss: 0.6007 - accuracy - ETA: 1:00 - loss: 0.6046 - accuracy: 0. - ETA: 1:00 - loss: 0.6063 - accu - ETA: 59s - loss - ETA:  - ETA: 54 - ETA: 43s - loss: 0.6222 - accuracy: 0.806 - ETA: 43s - l - ETA: 41s - loss: 0. - ETA: 39s - loss: 0.6200 - accu - ETA: 5s - l - E - ETA: 3s - loss: 0.6198 - accuracy: 0.80 - ETA:  - ETA: \n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.6093 - accuracy: 0.8127 - val_loss: 0.8738 - val_accuracy: 0.7799 50s - loss: - ETA: 48s - loss - ETA: 46s - loss: 0.5968 - accuracy: 0.8 - ETA: 45s - loss: 0.5966 - a - ETA: 44s - loss: 0.5970 - a - ETA: 43s - loss: 0.599 - ETA: 41s - loss - ETA: 24s - loss: 0.6057 - accuracy - ET - ETA: 21s - loss: 0.6067 - accu - ETA: 20s - loss: 0.6092 - accuracy: 0.8 - E - ETA: 16s - loss: 0.6104 - ac - ETA: 15s - loss: 0.6102 - accura - ETA: 14s - loss: 0.6098 - accuracy: 0 - ETA: 14s - loss: 0.6100 - accurac - ETA: 13s - loss: 0.6102 - - ETA: 3s - loss: 0.612 - ETA: 2s - loss: 0.6117 - accu - ETA: 2s - loss: 0 - ETA: 1s - los - ETA: 0s - loss: 0.6098 - accuracy: 0.81 - ETA: 0s - loss: 0.6096 - accuracy: \n",
      "Epoch 35/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.6079 - accuracy: 0.8138 - val_loss: 0.8727 - val_accuracy: 0.77560.6141 -  - ETA: 43 - ETA: 33s - loss: 0.6187 - accur - ETA: 32s - loss: 0.6156 - accuracy:  - ETA: 31s - loss: 0.6148 - accuracy:  - ETA: 31s - loss: 0.6159 - accurac - ETA - ETA: 27s - loss: 0.6125 - accuracy:  - ET - ETA: 2s - loss: 0.6089  - ETA: 1s - loss: 0.6089  - ETA: 0s - loss: 0.6090 - accura - ETA: 0s - loss: 0.6088 - accuracy\n",
      "Epoch 36/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5970 - accuracy: 0.8166 - val_loss: 0.7568 - val_accuracy: 0.8098 0. - ETA: 52s - loss: 0.567 - - ETA: 40s - loss: 0.5806 - - ETA: 39s - loss: 0.5830 - ac - ETA: 38s - loss: 0.5825 - accuracy: 0.819 - ETA: 38s - ETA: 35s - loss: 0.5932 - accura - ETA: 34s - loss: 0.59 - ETA: 32s\n",
      "Epoch 37/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5934 - accuracy: 0.8180 - val_loss: 0.9765 - val_accuracy: 0.7521 - accuracy: 0.815 - ETA: 57s - loss: 0.5946 - accuracy: 0 - ETA: 57s - loss: 0.5947 - accuracy: 0. - ETA: 53s - loss: 0.6065 - a - ETA: 47s - loss: 0.5970 - accuracy - ETA: 43s - loss: 0.5933 - ac - ETA: 42s - loss: 0.5927 - a - ETA: 12s - - ETA: 2s - loss: 0.5924 - accu - ETA: 1s - loss: 0.5922 - accuracy:  -\n",
      "Epoch 38/100\n",
      "1443/1443 [==============================] - 66s 46ms/step - loss: 0.5889 - accuracy: 0.8190 - val_loss: 0.8766 - val_accuracy: 0.7756TA: 1:00 - loss: 0.581 - ETA: 58s - loss: 0.5900 - accuracy: 0. - ETA: 58s - loss: 0.5860 -  - ETA: 56s - loss: - ETA: 51s - loss: 0.5981 - accuracy: - ETA: 50s - loss: 0.602 - ETA: 48s - loss: 0.5997  - ETA: 47s - loss - ETA: - ETA: 34s - loss: 0.5859 - accur - ETA: 33s - los - ETA: 31s - loss: 0.5863 - accuracy: 0 - ETA: 27s  - ETA: 24s - lo - E - ETA: 18s - los - ETA: 1 - ETA: 2s - loss: 0.5895 - accuracy:  - ETA: 2s - loss: 0.5898 - ac\n",
      "Epoch 39/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5811 - accuracy: 0.8207 - val_loss: 0.8619 - val_accuracy: 0.7703 - loss: 0.5975 - accu - ETA: 1:01 - loss: 0.5764 - accura - ETA: 1:01 - loss: - ETA: 1:00 -  - ETA: 50s - loss: - ETA: 48s - lo  - ETA: 42s - lo - ETA: 39s - loss: 0.5714 - accuracy:  - ETA: - ETA: 32s - loss: 0.5797 -  - ETA: 31 - ETA: 28s - loss: 0.5819 - accuracy - ETA: 27s - loss: 0.5813 - accuracy: 0.820 - ETA: 27s - loss: 0.582 - ETA: 26s - loss: 0.5 - ETA: 24s - loss: 0.5833 - accur - ETA: 23s - loss: 0.5822 - accuracy: 0 - ETA: 23s - loss: 0.5834 - accuracy: 0.819 - ETA: - ETA: 19s - loss: 0.5828 - ac - ETA: 18s - loss: 0.5825 - accuracy: - ETA: 18s - loss: 0.5815 - accuracy: 0 - ETA: 17s - loss: 0.5816 -  - ETA: 16s - loss: 0.5847 - a - ETA: 15s - loss: 0.58 - ETA: 13s - loss: 0.5844 - acc - ETA: 0s - loss: 0.5817 - accuracy\n",
      "Epoch 40/100\n",
      "1443/1443 [==============================] - 66s 45ms/step - loss: 0.5738 - accuracy: 0.8241 - val_loss: 0.8595 - val_accuracy: 0.7714s: 0.5763 - accu - ETA: 48s - loss: - ETA: 46s - l - ETA: 43s - loss: 0.5703 - accuracy: 0 - ETA: 39s - loss: 0.5703 - ac - ETA: 38s - loss: 0.56 - ETA: 36s - loss: 0.5698 - accuracy: - ETA: 35s - loss: 0.5 - - ETA: 23s - loss: 0.5726 - accu - ETA: 22s - loss: 0.57 - ETA: 20s - loss: 0.5727 - accu - ETA: 19s - loss: 0.5733 - - ETA: 18s - loss: 0.5720 - accuracy: - ETA: 17s - l - ETA: 15s - loss: 0.5695  - ETA: 13s - loss: 0.5716 - accuracy: 0.825 - ETA: 13s - loss: 0.5713 - accuracy: 0.8 - E - ETA: 10s - loss: 0.5736 - accuracy:  - ETA: 9s - loss: 0.5 - ETA: 8s - loss: 0.5728 - accuracy - ETA: 8s - loss: 0.5722 -  - ETA: 7s - loss: 0.573 - ETA: 7s - loss: 0.5729 -  - ETA: 6s - loss: 0.5725 - accuracy - ETA: 6s - loss: 0.571 - ETA - ETA: 0s - loss: 0.5736 - accuracy: 0.\n",
      "Epoch 41/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5672 - accuracy: 0.8249 - val_loss: 0.8927 - val_accuracy: 0.7831oss - ETA:  - ETA: 37s - loss: 0.5532 - acc - E - ETA: 29s - loss: 0.5579 - accu - ETA: 28s - loss: 0.5584 - accuracy: 0 - ETA: 28s - loss: 0.5608 - accuracy: 0.827 - ETA - ETA: 0s - loss: 0\n",
      "Epoch 42/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5640 - accuracy: 0.8267 - val_loss: 0.8982 - val_accuracy: 0.7703 ETA: 44s - loss: - ETA: 42s - loss: 0.5617  - ETA: 41s - loss: 0.5591 - a - ETA: 39s - loss: 0.562 - - ETA: - ETA: 20s - loss: 0.56 - ETA: 18s - loss: 0.5663 - - ETA: 17s - loss: 0.5647 - ac - ETA: 16s - loss: 0.5669 - accuracy: 0 - ETA: 16s - loss: 0.5669 - accuracy: 0.826 - ETA: 15s - loss: 0.5670 - accuracy: 0.826 - ETA: 15s - loss: 0.5666 - accur - ETA: 14s - loss - ETA: 12s - loss: 0.568 - ETA: 11s - loss: 0.5667 - accuracy: 0.8 - ETA: 10s - loss: 0.5668 -  - ETA: 9s - l - ETA: 8s - loss: 0.5675 - accu - ETA: 8s - loss: 0.5672 - accuracy - ETA: 7s - loss: 0.5673 - accuracy: 0. - ETA: 4s - loss: 0.5642 - accuracy: 0.82 - - ETA: 2s - loss: 0.5630 - ac - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.5646 - \n",
      "Epoch 43/100\n",
      "1443/1443 [==============================] - 66s 45ms/step - loss: 0.5594 - accuracy: 0.8284 - val_loss: 0.9241 - val_accuracy: 0.7618TA: 59s - loss: 0.5598 - a - ETA: 58s - loss: 0.5418 - accuracy: 0 - ETA: 58s - loss: 0.5400 - accuracy:  - ETA: 57s - loss: 0.5373 - accura - ETA: 53s - loss: 0.5573 - accuracy:  - ETA - ETA: 49s - loss: 0.5574 - accuracy: - ETA: 49s - loss: 0.5591 - accuracy: 0.8 - ETA: 48s - loss: 0.5598 - accuracy: 0 - ETA: 48s - loss: 0.5587 - accur - ETA: 47s - loss: 0.5612 - accura - ETA: 46s - loss: 0.5603  - ETA: 45s - loss: 0.5615 - accurac - ETA: 44s - loss: 0.5 - ETA: 42s - loss: 0.5643 - accuracy: 0.826 - ETA: 42s - loss - ETA: 40s - loss: 0.5651 - - ETA: 39s - loss: 0.5631 - ac - ETA: 37s - l - ETA: 31s - loss: 0.5594 - ac - ETA: 30s - loss: 0.5602 - accuracy: 0.827 - ETA: 30s - loss: 0.5599 - - ETA: 29s - loss: 0.5565 - accuracy: 0.8 - ETA: 29s - loss: 0.5573 - accuracy: - ETA: 28s - loss: 0.5572 - accura - ETA - ETA: 20s - loss: 0.5608 - accuracy: 0. - ETA: 20s - loss: 0.5606 - - ETA: 19s - loss: 0.5581 - ac - ETA: 17s - loss: 0.5606 - acc - ETA: 16s - loss - ETA: 14s - loss: 0.5598 - accur - ETA: 13s - loss: 0.5601 - accuracy: 0.828 - ETA: 13s - loss: 0.5596 - accu - ETA: 12s - loss: 0.5584 - ac - ETA: 11s - loss: 0.5583 - accura - ET\n",
      "Epoch 44/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5581 - accuracy: 0.8270 - val_loss: 0.8863 - val_accuracy: 0.7746- loss: 0.5572 - accuracy: - ETA: 37s - loss: 0.5579 - accuracy: 0.8 - ETA: 37s - loss: 0.5570 - ac - ETA: 36s - loss: 0.5585 - acc - ETA: 24s - loss - ETA: 2\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5525 - accuracy: 0.8295 - val_loss: 0.9100 - val_accuracy: 0.7639 - loss: 0.570 - ETA: 1: - ETA: 1:00 - loss: 0.53 - ETA: 59 - ETA: 52s - loss: 0.5333 - accuracy: 0 - ETA: 52s - loss: 0.5358 -  - ETA: 51s - loss: 0.5358 - a - ETA: 49s - loss: 0.5 - ETA: 48s  - ETA: 45s - loss: 0.5356 - accuracy: 0.835 - ETA: 45s - loss: 0.5363 - accuracy:  - ETA: 44s - loss: 0.5373 - accuracy: 0 - ETA: 44s - loss: 0.5411 - accuracy: 0. - ETA: 44s - loss: 0.5423 - accuracy:  - ETA: 43s - loss: 0.5418  - ETA: 42s - loss: 0.5429 - ac - ETA: 40s - loss: 0.5446 - accurac - ETA: 40s - loss: 0.5440 - accuracy: 0. - ETA: 39s - los - ETA: 37s - loss: 0.5423 - accuracy: 0.833 - ETA: 37s - loss: 0.544 - ETA: 35s - loss: 0.5416 - accu - ETA: 34s - loss: 0.5388 - accuracy: 0. - ETA: 34s - loss: 0.5395 - accur - ETA: 33s - loss: 0.5413 - accuracy: 0. - ETA: 33s - l - ETA: 30s - loss: 0.5456 - ETA: 29s - loss: 0.5502 - accur - ETA: 28s - loss: 0.5501 - accuracy:  - ETA: 27s - loss: 0.5501 -  - ETA: 26s - loss - ETA: 24s - loss: 0.5527 - accu - ETA: 23s - loss: 0.5544 - accuracy: 0.829 - ETA: 23s - loss: 0.5542 - accur - ETA: 22s - loss: 0.5541 - a - ETA: 21s - loss: 0.\n",
      "Epoch 46/100\n",
      "1443/1443 [==============================] - 66s 46ms/step - loss: 0.5462 - accuracy: 0.8327 - val_loss: 0.8124 - val_accuracy: 0.800244 - ETA: 1:03 - loss: 0.5 - ETA: 1:02 - loss: - ETA: 1:01 - ETA: 1:00 - loss: 0.5504 - - ETA: 58s - loss: 0. - ETA: 56s - loss:  - ETA: 54s - loss: 0.5499 - - ETA: 53s - loss: 0.5401 - ETA: 51s - loss: 0.5394 - accuracy: 0.8 - ETA: 51s - loss: 0.541 - ETA: 49s - loss: 0.5410 - accu - ETA: 48s - loss: 0.5378 - - ETA: 47s - loss: 0.5365 - acc - ETA: 46s - ETA: 39s - loss: - ETA: 34s - loss: 0.5338 - accuracy: 0. - ETA: 33s - loss: 0.5340 - accur - ETA: 32s -  - ETA: 30s - loss: 0.5336 - accuracy: 0. - ETA: 30s - loss: 0.5342 - accur - ETA: 29s - loss: 0.535 - ETA: 27s - loss: 0.5366 - accuracy: 0. - ETA: 27s - loss: 0.5370 - accuracy: 0 - ETA: 26s - loss: 0.5373 - - ETA: 21s - loss: 0.5434 - accuracy:  - ETA: 21s - loss: 0.5415 - accuracy:  - E - ETA: 17s - loss: 0.5373 - accur - ETA: 16s - loss: 0.5347 - - ETA: 15s - lo - ETA: 12s - loss: 0.5371 - accuracy: - ETA: 12s - loss: 0.5371 -  - ETA: 10s - loss: 0.5387 - accuracy: 0.835 - E - ETA: 3s - loss: 0.5458 - accuracy: 0.83 - ETA\n",
      "Epoch 47/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5449 - accuracy: 0.8318 - val_loss: 0.7618 - val_accuracy: 0.804559 - ETA: 56s - loss: 0.5153 -  - ETA: 55s - loss: 0.526 - ETA: 53s - loss: 0.5262 - ac - ETA: 52s - loss: 0.52 - ETA: 50s - loss: 0.52 - ETA: 48s - loss: 0.5245 - accu - ETA: 40s -  - ETA: 38s - loss: 0 - ETA - ETA: 29s - - - ETA: 19s - loss: 0 - ETA: 17s - loss: 0.5385 - accuracy: 0.83 - ETA: 17s - loss\n",
      "Epoch 48/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5392 - accuracy: 0.8343 - val_loss: 0.9227 - val_accuracy: 0.7607A: 40s - - ETA: 37s - l - ETA: 34s - loss: 0.53 - ETA: 33s - loss: 0.5281 - accuracy: 0.83 - ETA: 33s  - ETA: 23s - loss: 0.5329 - accuracy: 0.836 - ETA: 23s - los - ETA: 20s - loss: 0.5344 - accuracy:  - ETA: 20s - loss: 0.534 - ETA: 1s - loss: 0.5392  - ETA: 0s - loss: 0\n",
      "Epoch 49/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5374 - accuracy: 0.8353 - val_loss: 0.9015 - val_accuracy: 0.77245203 - acc - ETA: 57s - loss: 0.5195 - accuracy: - ETA: 56s - loss: 0.5199 - accuracy: - ETA: 56s - loss: 0.5177  - ETA: 55s - loss: 0.5239 - accuracy: 0.8 - ETA: 54s - loss: 0.5214 - accuracy: 0.841 - ETA: 54s - loss: 0.52 - ETA: 52s - loss: 0.5300 - accura - ETA: 52s - loss: 0.5252 - accuracy: 0.840 - ETA: 51s - loss - ETA: 49s - loss: 0.5310 - accuracy: - ETA: 49s - loss: 0.5295 -  - ETA: 47s - loss: 0.5314 - accuracy - ETA: 47s - loss: 0.5310  - ETA:  - ETA - ETA: 39s - loss: 0.5395 - - ETA: 38s - loss: - ETA: 35s - loss: 0.5388 - accuracy: 0. - ETA: 35s  - ETA: 29s - loss: 0.5422 - acc - ETA: 28s - loss: - ETA: 26s - loss: 0.54 - ETA: 24s  - ETA: 17s - loss: 0 - ETA: 15s - loss: 0.5421 - accuracy: 0 - ETA: 15s - loss: 0.5418 - accuracy: 0.833 - ETA: 15s - loss: 0.5417 - acc - ETA: 14s - loss: 0.5407 - accuracy: 0.833 - ETA: 14s - loss: 0.5407 - accuracy: 0 - ETA: 13s - loss: 0.5408 - accuracy: 0 - ETA: 13s - - ETA: 10s - loss: - ETA: 9s - loss: 0 - ETA: 8s - loss: 0.5 - ETA: 7s - loss: 0.5364 - accuracy: 0.83 - ETA: 7s - loss: 0.5367 - accuracy: 0.83 - ETA: 7s - loss: 0.5368  - - ETA: 3s - loss: 0.5382 - accuracy: 0.83 - ETA: 3s -\n",
      "Epoch 50/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5291 - accuracy: 0.8369 - val_loss: 0.8808 - val_accuracy: 0.7735TA: - ETA: 38s - loss: 0.5183 - ac - ETA - ETA: 30s - loss: - ETA: 25s - loss: 0.5179 - accuracy: 0 - ETA: 24s - loss:  - ETA: 22s - loss: 0.5193 - ac - ETA: 21s - l - ETA: 19s - loss: 0.5202 - accura - ETA: 18s - - - ETA: 1s - loss: 0.5262 - accuracy - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.5275 \n",
      "Epoch 51/100\n",
      "1443/1443 [==============================] - 65s 45ms/step - loss: 0.5257 - accuracy: 0.8363 - val_loss: 0.9682 - val_accuracy: 0.7564loss: 0.5496 - - ETA: 57s - l - ETA: 51s - lo - ETA: 49s - loss: 0 - ETA: 47s - loss:  - ETA: 45s - loss: 0.5248 - - ETA: 43s - loss: 0. - ETA: 41s - loss: 0.523 - ETA: 40s - loss: - ETA: 38s - loss: 0.5174 - accuracy:  - ETA:  - ETA: 34s - loss: 0.5212 - accuracy: - ETA: 30s - loss: 0.5215 - accuracy: 0. - ETA: 30s - loss: 0.5213 - accuracy: 0.83 - ETA: 29s - loss: 0.5216 - accuracy:  - ETA: 29s - loss: 0.5234 - accu - ETA: 28s - loss: 0.5249  - ETA: 2 - ET - ETA: 10s -  - ETA: 1s - ETA: 0s - loss: 0.5254 - accuracy: \n",
      "Evaluating model...\n",
      "ROC: 0.929\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.61\n",
      "F-Score: 0.61\n",
      "\n",
      "*** Train on {1, 2, 5, 6, 7, 8, 9} Validate on 4 Test on 3 ***\n",
      "val shape:  (990, 128, 128, 1)\n",
      "test shape:  (925, 128, 128, 1)\n",
      "train shape:  (143157, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1432 steps, validate for 10 steps\n",
      "Epoch 1/100\n",
      "1432/1432 [==============================] - 71s 50ms/step - loss: 2.1509 - accuracy: 0.2566 - val_loss: 1.9058 - val_accuracy: 0.3503- ETA: 47s - loss:   - ETA: 40s - loss: 2.309 - ETA: 38s - loss: 2.3016 - acc - ETA: 37s - lo - ETA: 34s - loss: 2.2822 - accuracy - ETA: 34s - loss: 2.2797 - ac - ETA: 32s - loss: 2.2748 - accuracy: 0.199 - ET - ETA: 25s - loss: 2.2464 - a - ETA: 23s -  - ETA: 8s - - ETA: 0s - loss: 2.1547 - accuracy: 0. - ETA: 0s - loss: 2.153\n",
      "Epoch 2/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 1.7905 - accuracy: 0.4134 - val_loss: 1.7155 - val_accuracy: 0.40227 - accuracy: - ETA: 55 - ETA: 49s - loss: 1.8602 - ETA: 47s - loss: 1.8550 - accu - ETA: 46s - loss: 1.8591 - accurac - ETA: 45s - - ETA: 39s - l - ETA: 37s - loss: 1.8462 - accuracy:  - ETA: 36s - loss: 1.8461 - ac - ETA: 35s - loss: 1.8430 - accuracy: 0 - ETA: 35s - loss: 1.8440 - accuracy: 0.391 - ETA: 35s - loss: 1.8422 - accuracy: - ETA: 34s - loss: 1.8353 - accuracy: 0.39 - ETA: 34s - loss: 1.8338 - accuracy: 0.394 - ETA: 34s - loss: 1.8344 - accuracy: 0.39 - ETA: 34s - loss: 1.8327 - accuracy: 0 - ETA: 33s - loss: 1.8 - ETA: 31s - loss: 1.8354 - accuracy:  - ETA: 31s - loss: 1.8344 - a - ETA: 30s - loss: 1.8358 - ac - ETA: 25s -\n",
      "Epoch 3/100\n",
      "1432/1432 [==============================] - 66s 46ms/step - loss: 1.5986 - accuracy: 0.4878 - val_loss: 2.0479 - val_accuracy: 0.4043 - ETA: 56s - loss: 1.6782 - accurac - ETA: 55s - loss: 1.6706 - accuracy: - ETA: 55s - los - ETA: 53s - loss: 1 - ETA: 43s - loss: 1.6486 - accuracy: 0.464 - ETA: 43s - loss: 1.6493 - accuracy: 0 - ETA: 43s - loss: 1 - ETA: 37s - loss: 1. - ETA: 35s - loss - ETA: 29s - loss: 1.6351 - accuracy: 0.47 - ETA: 29s  - ETA: 15s - loss: 1.6214  - ETA: 1 - E\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432/1432 [==============================] - 65s 45ms/step - loss: 1.4405 - accuracy: 0.5454 - val_loss: 1.7206 - val_accuracy: 0.460538s - loss: 1.4772 - accuracy: 0.531 - ETA: 38s - loss: 1.4785 - accuracy: 0. - ETA: 38s - loss: 1.4782 -  - ETA: - ETA: 33s - loss: 1.4750 - accur - ETA: 33s - loss: 1. - ETA: 31s - loss: 1.4697 - accura - ETA: 30s - loss: 1.4696 - ac - ETA: 29s - loss - ETA: 26s - lo - ETA: 24s - loss: 1.4616 - a - ETA: 23s - loss: 1.4577 - accuracy: - ETA: 22s - loss: 1.4583 - accuracy: 0.538 - ETA: 22s - ETA: 16s - loss: 1.4507 - ac - ETA: 15s - loss: 1.4520 - acc - ET - ETA: 5s - loss: 1.4460 - ac - ETA: 4s - loss: 1.4\n",
      "Epoch 5/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 1.3241 - accuracy: 0.5861 - val_loss: 1.5760 - val_accuracy: 0.5092 ac - ETA: 4 - ETA: 46s - loss: 1.35 - ETA: 44s - loss: 1.3590 - accuracy: 0.570 - ETA: 44s - loss: 1.3604 - accur - ETA: 35s - loss: 1.3517 -  - ETA: 34s - loss: 1.3531 - accuracy: - ETA: 34s - loss: - ETA: 32 - ETA: 25s - loss: 1.34 - ETA: 23s - loss: 1.3451 - accuracy: 0.578 - ETA: 23s - loss: 1.3444 - accuracy: 0 - ETA: 23s - los - ETA: 20s - loss: 1.3440 - accuracy: 0. - ETA: 20s - loss: 1.3 - ETA: 18s - loss: 1.33 - ETA: 17s - loss: 1.334 -  - - ETA: 0s - loss: 1.3257 - accura\n",
      "Epoch 6/100\n",
      "1432/1432 [==============================] - 64s 45ms/step - loss: 1.2282 - accuracy: 0.6175 - val_loss: 1.7844 - val_accuracy: 0.4962 47s - loss: - ETA: 45s - loss: 1.2683 - accuracy: 0.6 - ETA:  - ETA: 38s - loss: 1.2554 - accurac - ETA: 37s - loss: 1.2554 - accuracy: 0.60 - ETA: 37s - loss: 1.2528 - accu - ETA: 36s - loss: 1.2545 - accuracy:  - ETA: 36s - loss: 1. - ETA: 19s -  - ETA: 13s - loss: 1.2381 - a - ETA: 12s - loss: 1.2372 - accuracy: 0.614 - ETA: 12s - loss: 1.236 - ETA: 10s - ETA: 0s - loss: 1.2291 - accuracy: \n",
      "Epoch 7/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 1.1576 - accuracy: 0.6420 - val_loss: 1.6260 - val_accuracy: 0.5427oss:  - ETA: 36s - loss - ETA: 34s - l - ETA: 32s - - ETA: 22s - loss:  - ETA: 2s - loss: 1.1573 -  - ETA:  - ETA: 0s - loss: 1.1586 - accuracy\n",
      "Epoch 8/100\n",
      "1432/1432 [==============================] - 64s 45ms/step - loss: 1.0970 - accuracy: 0.6617 - val_loss: 1.5979 - val_accuracy: 0.5557 - ETA: 14s - loss: 1.1102 - accura - ETA: 13s - loss: 1.1085 -  - ETA: 12s - loss: 1.10 - ETA: 10s - loss: 1.1062 - ETA: 9s - loss: - ETA: 1s - loss: 1.0976 - ac - ETA: 0s - loss: 1.0962 - accuracy:  - ETA: 0s - loss: 1.0966 - ac\n",
      "Epoch 9/100\n",
      "1432/1432 [==============================] - 64s 45ms/step - loss: 1.0444 - accuracy: 0.6792 - val_loss: 1.5308 - val_accuracy: 0.5557ss: 1.0555 - a - ETA: 29s - ETA: 7s - loss: - ETA: 4s - loss: 1.0446 - accu - ETA: 4s - loss: 1.0443  -\n",
      "Epoch 10/100\n",
      "1432/1432 [==============================] - 67s 46ms/step - loss: 0.9951 - accuracy: 0.6953 - val_loss: 1.8720 - val_accuracy: 0.5286A: 51s - loss: 0.9987 - accuracy: 0 - ETA: 50s - loss: 1.0017 -   - ETA: 42s - loss: 1.0041 - accuracy:  - ETA: 42s - loss: 1.0025 - ETA: 40s - loss: 0.9962 - accu - ETA: 39s - loss: 0.9937  - ETA: 38s - loss: 0.9896 - accur - ETA - ETA: 33s -  - ETA: 31s - loss: 0.9880 -  - ETA: 26s - lo - ETA: 24s - loss: 0.9850 - accuracy:  - ETA: 19s - loss: 0.9945 - accuracy: 0.69 - ETA: 19s - loss: 0.9961 - accuracy: 0.6 - ETA: 19s - loss: 0.9961 - accuracy - ETA: 18s - loss: 0.9965 - accuracy: 0.694 - ETA: 18 - ETA: 11s - loss: 0.9971 - a - ETA: 10s - loss: 0.9989 - accuracy: 0 - ETA: - ETA: 8s - loss: 1.0009 - accuracy - ETA: 8s - loss: 1.0003 - accuracy: 0. - ETA: 8s - los - ETA: 6s - loss: 0.9987 - ac - ETA: 6s - loss: 0.999 - ETA: 3s - loss: 0.997 - ETA: 2s - loss: 0.9955 - accura - ETA: 0s - loss: 0.9952 - accura\n",
      "Epoch 11/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.9621 - accuracy: 0.7056 - val_loss: 2.1114 - val_accuracy: 0.5081 0 - ETA: 1:00 - los - ETA: 57s - loss: 0. - ETA: 55s - loss: 0.9827 - accu - ETA: 54s - loss: 1.0020 - - ETA:  - - ETA: 39s - loss: 0.9576 - accuracy: 0. - ETA: 39s - loss: 0.9549 - - ETA: 37s - lo - ETA: 31s - loss: 0.9669 - accuracy: 0.703 - ETA: 31s - loss: 0.9665 - -  - ETA: 26s - loss:  - ETA: 20s - loss: 0.9575  - ETA: 19s - loss: 0.9568 - accuracy: 0.7 - ETA: - ETA: 16s - loss: 0.9613 - accuracy:  - ETA: 15s - loss: 0.9610 - accuracy: 0. - ETA: 15s - loss: 0.9622 - accuracy: 0 - ETA: 14s - loss: 0.9627 - a - ETA: 13s - loss:  - ETA: 11s - loss: 0.9648 - accura - ETA: 10s\n",
      "Epoch 12/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.9208 - accuracy: 0.7196 - val_loss: 1.7029 - val_accuracy: 0.5459 - accuracy: 0 - ETA: 58s - loss: 0.9133 - accurac - ETA: 57s - loss: 0.9062 - accuracy: 0. - ETA: 57s - los - ETA: 55s - loss: 0.9322 - accu - - ETA: 50s - loss: 0.9392 - accuracy: - ETA: 46s - loss: 0.9338 - ETA: 37s - loss: 0.9284 - accu - ETA: 32s - loss: 0.9265 - accuracy: - ETA: 32s - loss: 0.9240 - accuracy: 0 - ETA: 31s - loss: 0 -  - ETA: 26s - loss: 0.9195 - accuracy: 0 - ETA: 25s - loss: 0.9190  - ETA: 24s - loss: 0.9192 - accu - ETA: 23s - loss: 0.9185 - accu - ETA: 22s - loss: 0.91 - ETA: 13s - loss: 0.9167 - accuracy: 0.7 - ETA: 13s  - ETA: 10s - loss: 0.9198 - accuracy: 0 - ETA: 10s - loss: 0.9195 - - ETA: 5s - loss: 0.9183 - accu\n",
      "Epoch 13/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.8940 - accuracy: 0.7281 - val_loss: 1.4709 - val_accuracy: 0.5535.9075 - accuracy - ETA: 48s - ETA: 45s - loss: 0.9137 - accurac - ETA: 45s - loss: 0.9088 - accuracy - ETA: 44s - loss: 0.9086  - ETA: 42s - loss: 0.9080  - ETA: 41s - loss: 0 - ET - ETA: 21s - loss: 0.9008 - ET - ETA: 2s - loss: 0.8962  -\n",
      "Epoch 14/100\n",
      "1432/1432 [==============================] - 64s 45ms/step - loss: 0.8681 - accuracy: 0.7372 - val_loss: 1.6624 - val_accuracy: 0.5514- loss: 0.8744 - accuracy: 0. - ETA: 41s - loss: 0.8734 - accur - ETA: 40s - loss: 0.8762 - accuracy:  - ETA: 39s - loss: 0.8748 - accuracy - ETA: 39s - loss: 0.8722 -  - ETA: 2s - loss: 0.8697 - accura - ETA: 1s - loss: 0.8695 - accuracy:  - ETA: 1s - loss: 0.869 - ETA: 0s - loss: 0.868\n",
      "Epoch 15/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.8422 - accuracy: 0.7450 - val_loss: 1.6410 - val_accuracy: 0.5697s - loss: 0.8456 -  - ETA: 53s - los - ETA: 48s - loss: 0.8353 - accuracy: 0.7 - ETA: 48s - loss: 0.8321 - accuracy: 0. - ETA: 48 - ETA: 45s - loss: - ETA: 43s - loss: 0.83 - ETA: 41s - loss: 0.836 - ETA - ETA: 25s - ETA: 22s - loss: 0.8453 - accuracy: 0.745 - ETA: 22s - loss: 0.8452 - accuracy:  - ETA: 18s - loss: 0.8459 - accuracy: 0 - ET - ETA: 1s - loss: 0.8430 - ac - ETA: 0s - loss: 0.8429 - accu - ETA: 0s - loss: 0.8425 - accuracy: \n",
      "Epoch 16/100\n",
      "1432/1432 [==============================] - 64s 45ms/step - loss: 0.8172 - accuracy: 0.7521 - val_loss: 1.8707 - val_accuracy: 0.541646 - accuracy: - ETA: 4s - loss: 0.814 - ETA: \n",
      "Epoch 17/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.7981 - accuracy: 0.7569 - val_loss: 1.6440 - val_accuracy: 0.5600s - - ETA: 21s - loss: 0.7929 - a - ETA: 20s - ETA: 17s - loss: 0.7919 - accuracy: 0.759 -  - ETA: 14s - l\n",
      "Epoch 18/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.7819 - accuracy: 0.7621 - val_loss: 1.4735 - val_accuracy: 0.5859 - loss: 0.7914 - ac - ETA: 19s - loss: 0.7919 - accuracy: - ETA: 18s - loss: 0.7912 - accuracy: 0. - ETA: 18s - loss: 0.7901 - a - ETA: 16s - loss: 0.7900 - accuracy:  - ETA: 2s - loss: 0.7839 - accura - ETA: 2s - - ETA: 0s - loss: 0.7833 - accuracy: 0. - ETA: 0s - loss: 0.7826 - ac\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432/1432 [==============================] - 65s 46ms/step - loss: 0.7587 - accuracy: 0.7694 - val_loss: 2.0400 - val_accuracy: 0.5276TA: 1:00 - loss: 0 - ETA: 1:00  - ETA: 57s - loss: 0.7715 -  - ETA: 55s - lo - ETA: 53s - loss:  - ETA: 47s - loss: 0.7785 - accuracy: - ETA: 46s - loss: 0.7821 - ac - ETA: 45s - loss: 0.7768 - acc  - ETA: 4 - ETA: 34s - - ETA: 28s - loss: 0.7697 - accuracy: 0.766 - ETA: 28s - loss: 0.7697   - ETA: 22s - loss: 0.7709 - accuracy:  - ETA: 22s - los - ETA: 20s - loss: 0.7729 - accuracy: 0.764 - ETA: - ETA: 16s - loss: 0.7696 - a - ETA: 15s - loss: 0.7681 - accuracy - ETA: 1s - loss: 0.760 - ETA: 0s - loss: 0.7588 - \n",
      "Epoch 20/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.7418 - accuracy: 0.7747 - val_loss: 1.4440 - val_accuracy: 0.580554 - accuracy: 0. - ETA: 44s - loss: 0.7392 - accuracy: 0 - ETA: 44s - loss: 0.7377 - accuracy: 0. - ETA: 43s - loss: 0.7363 - accuracy:  - ETA: 43s - loss - ETA: 41s - loss - ETA: 39s  - ETA: 21s - loss: 0.7429 - accuracy: 0 - ETA: 21s - loss: 0.7438 - accuracy:  - E - ETA: 17 - ETA: 6s - loss: 0.7414 - accu - ETA: 6s - loss: 0.7416 - accu - ETA: 5s - loss: 0.7426 - accuracy - ETA: 5s - loss: 0.7427 - accuracy: 0. - ETA: 5s - l - ETA: 0s - loss: 0.7414 - \n",
      "Epoch 21/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.7301 - accuracy: 0.7783 - val_loss: 1.5019 - val_accuracy: 0.5632TA: 55s - loss: 0.7200 - accuracy:  - ETA: 54s - loss: 0.7228 - accuracy:  - ETA: 54s - loss: 0.7267 - accura - ETA: 53s - ETA: 50s - loss: - ETA: 48s - loss: 0.7297 - accura - ETA: 48s - loss - ETA: 45s - loss: 0.7383 - accuracy: 0 - ETA: 45s - loss: 0.7387 - accur - ETA: 44s - loss: 0.7343 - accuracy: - ETA: 43s - loss: 0.7320 - a - ETA: 35s - loss: 0.7276 - accu - ETA: 34s - loss: 0. - ETA: 32s - loss: 0.7220 - accuracy: 0.783 - ETA: 32s - loss: 0.7219 - - ETA: 31s - loss: 0.7215 - accuracy: 0 - ETA: 30s - loss: 0.7230 - accu - ETA: 29s - loss: 0.7238 - accur - ETA: 28s - l - ETA: 26s - loss: 0.7255 - accuracy:  - ETA: 25s - loss: 0.7259 - accuracy:  - ETA: 25s - loss: 0.7273 - accu - ET - ETA: 2s - loss: 0.7311 \n",
      "Epoch 22/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.7144 - accuracy: 0.7841 - val_loss: 1.8028 - val_accuracy: 0.5578:  - ETA: 53s - loss: 0.6883 - accur - ETA: 52s - lo - ETA: 50s - loss: 0.7077 - accuracy: 0.78 - ETA: 50s - loss: 0.7065 - accurac - ETA: 49s - loss: 0.7078 - a - ETA: 48s - loss: 0.7079 - accuracy:  - ETA: 47s - l - ET - ETA: 41s - loss: - ETA: 39s - loss: - ETA: 37s - loss: 0.7121 - accuracy - ETA: 36s - loss: 0.7134 - a - ETA: 35s - loss: 0.7145 - accuracy:  - ETA: 3 - ETA: 6s - loss: 0\n",
      "Epoch 23/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.6983 - accuracy: 0.7889 - val_loss: 1.5565 - val_accuracy: 0.57951:00 - loss: 0.6273 - accurac - ET - ETA: 52s - loss: 0.6933 - accura - ETA: 51s - loss: 0.6973 - accuracy: 0. - ETA: 51s - loss: 0.6990 -  - ETA: 49s - loss: 0.6947 - accurac - ETA: 49s - loss: 0.6942 - accuracy - ETA: 48s - loss: 0.6893 - accuracy: 0 - ETA: 44s - loss: 0.68 - ETA: 42s - ETA: 39s  - ETA: 36s - loss: 0.6977 - accuracy - ETA: 36s - loss: 0.6972 - accuracy: - ETA:  - ETA: 14s - loss: 0.6981 - accu - ETA: 13s - loss: 0.6961  - \n",
      "Epoch 24/100\n",
      "1432/1432 [==============================] - 65s 46ms/step - loss: 0.6904 - accuracy: 0.7916 - val_loss: 1.7524 - val_accuracy: 0.5568: 54s - l - ETA: 51s - loss: 0.6786 - ETA: 50s - loss: 0.6818 - accuracy: 0. - ETA: 49s - loss: 0.6819 - ETA: 25s - loss: 0.6978 - accur - ETA: - ETA: 21s - ETA: - ETA: 15s - loss: 0.6955 - acc - ETA: 14s - loss: 0. - ETA: 12s - loss: 0.6934 - accurac - E - ETA: 2s - loss: 0.6906 - accura - ETA:  - ETA: 0s - loss: 0.6910 - accuracy: 0.\n",
      "Epoch 25/100\n",
      "1432/1432 [==============================] - 65s 46ms/step - loss: 0.6779 - accuracy: 0.7931 - val_loss: 1.7161 - val_accuracy: 0.5665  - ETA: 52s - loss: 0.6976 - accuracy: 0. - ETA: 51s - loss: 0. - ETA: 50s - loss: 0.6980 - accuracy:  - ETA: 49s - loss: 0.6966 - accuracy: 0.787 - ETA: 49s - loss: 0.6958 - accu - ETA: 41s - loss: 0.6816 - accuracy: 0.79 - ETA: 4 - E - - ETA: 27s - loss: 0.6774 - accura - ETA: 26s  - ETA: 20s - loss - ETA: 18s - los - ETA: 5s - loss: 0.679 - ETA: 1s - los\n",
      "Epoch 26/100\n",
      "1432/1432 [==============================] - 65s 46ms/step - loss: 0.6676 - accuracy: 0.7956 - val_loss: 1.7544 - val_accuracy: 0.5654TA: 1:00 - l - ETA: 57s - loss: 0.6794 - accura - ETA: 56s - loss: 0.6703 - accura - ETA: 33s - ETA: 31s - loss: 0.6642 - accuracy: 0.795 - ETA: 30s - loss: 0.6640 - accu - ETA: 26s - loss: 0.6689 - accu - ETA: 25s - loss: 0.6682 - accur - ETA: 24s - loss: 0 - ETA: 22s -  - ETA: 20s - loss: 0 - ETA: 17s - loss: 0.6656 - accuracy - ETA: 8s - loss: 0.6 - ETA: 3s - loss: 0 - ETA: 0s - loss: 0.6665 - accuracy: 0.79 - ETA: 0s - loss: 0.6663 - ac\n",
      "Epoch 27/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.6569 - accuracy: 0.7998 - val_loss: 1.5408 - val_accuracy: 0.56866282 - accuracy: 0.813 - ETA: 59s - loss: 0.6297 - a - ETA: 58s - - ETA: 55s - lo - ETA: 5 - ETA: 50s - loss: 0.6 - ETA: 48s - loss: 0.6446 - accuracy: 0.803 - ETA: 48s - loss: 0.64 - ETA: 39s -  - ETA: 36s - loss - ETA: 34s - loss: 0.6514  - ETA: 32s - loss: 0.6528 - accurac - ETA: 32s - loss: 0.6532 - accuracy: 0.801 - ETA: 32s - loss: 0.6 - ETA: 30s - loss: 0.6527 - accuracy: 0. - ETA: 29s - - ETA: - ETA: 20s - loss: 0.6498 - accuracy: - ETA: 19s - ETA: 7s - l - ETA: 3s -\n",
      "Epoch 28/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.6487 - accuracy: 0.8020 - val_loss: 1.6805 - val_accuracy: 0.583851s - loss: 0.6455 - accura - ETA: 5 - ETA: 47s - -  - ETA: - ETA: 27s - loss: 0.6601 - accur - ETA: 26s - loss: 0.6597 - accuracy: 0. - ETA: 26s - loss: 0.6 - ETA: 21s - loss: 0. -\n",
      "Epoch 29/100\n",
      "1432/1432 [==============================] - 65s 46ms/step - loss: 0.6349 - accuracy: 0.8049 - val_loss: 1.8821 - val_accuracy: 0.5697s - loss: 0.6297 - accuracy: 0. - ETA: 36s - loss: 0.6289 - accuracy: 0.806 - ETA: 35s - ETA: 1s - loss: 0.6364 - accura - ETA: 0s - loss: 0.6358 \n",
      "Epoch 30/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.6282 - accuracy: 0.8079 - val_loss: 1.9411 - val_accuracy: 0.5719 0.6362 - accur - ETA: 58s - loss: 0.6422 - accur - ETA: 57s - loss: 0.6367 - accur - ETA: 56s - loss: 0.6434 - accurac - ETA: 55s - - ETA: 41s - loss: 0.6296 - accuracy - ETA: 40s - loss: 0.6313 - accuracy:  - ETA: 40s - l - ETA: 37s - loss: 0.6274 - a - ETA: 36s - loss: 0.6303 - acc - ETA: 3 - ETA: 32s - loss: 0.6285 - - ETA: 31s - loss: 0.6250 - accur - ETA: 30s - loss: 0.6235 - accuracy: - ETA: 29s - lo - ETA: - ETA: 20 - ETA: 17s - loss: 0.6249 - a - ETA: 16s - loss: 0. - ETA: 10s - loss: 0.6266 - accur - ETA - ETA: 1s - loss: 0.6282 - accuracy: 0. - ETA: 0s - loss: 0\n",
      "Epoch 31/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.6215 - accuracy: 0.8103 - val_loss: 1.6471 - val_accuracy: 0.5892 - loss: 0 - ETA: 1:00 - loss - ETA: 57s - loss: 0.5828 - accuracy: 0. - ETA: 57s - loss - ETA: 55s - ETA: 52s - los - ETA: 50s -   - ETA: 4 - ETA: 34s - loss: 0.6182 - - ETA: 32s - loss: 0.6164 - accuracy: 0. -   - ETA: 17s - - ETA: 15s - loss: 0.6194 - accur - ETA: 14s - los - ETA: 12s - loss: 0.6211 - accu - ETA\n",
      "Epoch 32/100\n",
      "1432/1432 [==============================] - 65s 46ms/step - loss: 0.6078 - accuracy: 0.8135 - val_loss: 1.7575 - val_accuracy: 0.5827TA: 1:01 - - ETA: 52s - loss: 0.6131 - acc - ETA: 51s - l - ETA: 45s - loss: 0.6135 - accuracy:  - ETA: 44s - loss: 0.6105 - accurac - ETA: 43s - loss: 0.6127 - - ETA: 42s - loss: 0.6108 - accura - ETA: 41s - loss: 0.6094 - ETA: 36s - loss: \n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.6025 - accuracy: 0.8161 - val_loss: 1.9243 - val_accuracy: 0.5773ETA: 52s - loss: 0.5945 - accuracy: - ETA: 51s - loss: 0.5928 - accuracy: 0. - ETA: 51s - loss: 0.5920 - - ETA: 50s - loss: 0.5910 - accuracy:  - ETA: 49s - loss: 0.5926 - accurac - ETA: 48s - loss: 0.5883 - ac - ETA: 47 - ETA: 44s - - ETA: 38s - loss: 0.5914 - accuracy: 0 - ETA: 38s - lo - ETA: 35s - loss: 0.5892 - a - ETA: 34s - loss: 0.5870 - accuracy:  - ETA: 34s - loss: 0.5881 - accu - ETA: 33s - loss: 0.5886 - accur - ETA: 32s - loss: 0.5882 - a - ETA: 31s - loss: 0.5916 - accuracy: 0.8 - ETA: 30s - loss: 0.5923 - accurac - ETA: 30s - loss: 0.5936 - accur - ETA: 29s - loss: 0.5971 - - ETA: 27s - loss: 0.5990 - accuracy - ETA: 23s - los - ETA: 21s - loss: 0.6021 - accuracy: 0.816 - ETA: 21s - loss: 0.6018 - accurac - ETA: 20s - loss: 0.601 - ETA: 18s - loss: 0.6011 - accuracy:  - ETA: 18s - loss: 0.6026 - accuracy: 0. - ETA: 17s - loss:  - ETA: 7s - loss: 0.5997  - ETA: 6s - loss: 0.5995 - accuracy - ETA: 6s - loss: 0.6003 - ac - ETA: 5s - loss: 0.6012 - accuracy: 0.81 - ETA: 5s - ETA: 4s - loss: 0.600\n",
      "Epoch 34/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.5983 - accuracy: 0.8158 - val_loss: 1.8081 - val_accuracy: 0.5697 ETA: 55s - loss - ETA: 53s - loss: 0.5918 - accur - ETA: 52 - ETA: 49s - ETA: 46s - loss - ETA: 44s - loss: 0.599 - ETA: 42s - loss: 0.5992 - accuracy: 0.81 - ETA: 42s - loss: - ETA: 40s - loss: 0.6046 - accuracy - ETA: 39s - loss: 0.6031 - accuracy: 0 - ETA: 39s - loss: 0.6034 -  - ETA: 38s - loss: 0.6008 - a - ETA: 36s - loss: 0.6011 - - ETA: 35s - loss: 0.5972 - - ETA: 34s - loss: 0.5963 - accuracy: 0. - ETA: 33s - loss: 0. - ETA: 31s - loss: 0 - ETA: 29s - loss: 0.5964 - accuracy - ETA: 29s - loss: 0.5971 - accuracy: 0 - ETA: 28s - loss: 0.5964 - accuracy - ETA: 28s - loss: 0.5986 - accu - ETA: 27 - ETA: 4s - loss: 0.5975 -  - ETA: 3s - loss: 0.5969 - accuracy: 0.81 - E - ETA: 0s - loss: 0.5984 - accuracy: 0.\n",
      "Epoch 35/100\n",
      "1432/1432 [==============================] - 65s 45ms/step - loss: 0.5920 - accuracy: 0.8191 - val_loss: 1.6822 - val_accuracy: 0.5978TA: 1:02 - loss: 0.5111  - ETA: 1:01 - loss: 0.5285  - ETA: 1:00 - loss: 0.5354  - ETA: 59s - loss: - ETA: 35s - loss: 0.5898 - accuracy: 0.820 - ETA: 35s - loss: 0.5903 - accurac - ETA: 34s - loss: 0.5883 - accu - ETA: 3 - ETA: 30s - loss: 0.5910 - accuracy - ETA: 30s - loss: 0.5934 - accuracy: - ETA: 29s - loss: 0.5944 - accuracy: - ETA: 29s - loss: 0.5940 - accuracy: 0.818 - ETA - ETA: 1s - loss: 0.5929 -  - ETA: 0s - loss: 0.5930 - accuracy: 0.81 - ETA: 0s - loss: 0.5930 \n",
      "Evaluating model...\n",
      "ROC: 0.94\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.65\n",
      "F-Score: 0.65\n",
      "\n",
      "*** Train on {1, 2, 3, 4, 7, 8, 9} Validate on 5 Test on 6 ***\n",
      "val shape:  (936, 128, 128, 1)\n",
      "test shape:  (823, 128, 128, 1)\n",
      "train shape:  (146433, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1465 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "1465/1465 [==============================] - 73s 50ms/step - loss: 2.1165 - accuracy: 0.2752 - val_loss: 1.9018 - val_accuracy: 0.3645ETA: 54s - loss: 2 - ETA: 52s  - ETA: 48s - l - ETA: 37 - ETA: 33s - loss: 2.2584 - accuracy: 0.2 - ETA: 33s - loss: 2.2 - ETA: 31s - loss: 2.2471 - accuracy: 0.2 - ETA: 31s - loss: 2.2455 - accur - ETA: 30s - loss: 2.241 - ETA: 28s - loss: 2.2316 - accuracy:  - ETA: 28s - loss: 2.229 - ETA: 18s - loss: 2.1895 - accura - ETA: 17s - loss: 2.1885 - accura - ETA: 16s - loss: 2.1864 - accuracy: 0.2 - ETA: 16s - loss: 2.1843 - accuracy: 0.2 - ETA: 15s - loss: 2.1823 - accuracy:  - ETA: 15s  - ETA: 12s - loss: 2.1631 - accuracy: 0.25 - ETA: 12s - loss: 2.1618 - accurac - ETA: 11s - ETA: 7s - - ETA: 5s - loss: 2.1378 - accuracy:  - ETA: 5s - l - ETA: 2s - loss: 2.1268 - ac\n",
      "Epoch 2/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 1.7137 - accuracy: 0.4321 - val_loss: 1.5714 - val_accuracy: 0.46050.3 - ETA: 51s - loss: 1.7925 - accuracy: - ETA: 51s - loss: 1.7854 -  - ETA: 20s - los - ETA: 2s - loss: 1.7158 - accuracy - ETA: 2s - loss: 1.7150 - ac - ETA: 2s - loss: 1.7157 - accuracy\n",
      "Epoch 3/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 1.5095 - accuracy: 0.5118 - val_loss: 1.7017 - val_accuracy: 0.4411ss: 1.5457 - a - ETA: 49s - loss: 1.5384 - accurac - ETA: 48s - loss: 1.5439 - accuracy:  - ETA: 47s - loss - ETA: 42s - loss: 1.5409 - accurac - ETA: 41s - loss: 1.5413 - accuracy:  - ETA: 40s - loss: - ETA: 24s - l - ETA: 21s - loss: 1.5340 - accuracy: 0 - ETA:  - ETA - ETA: 15s - loss: 1.5306 - accurac - ETA: 14s - loss: 1.5304 - accuracy:  - ETA: 14s - loss: 1.5282 - accurac - ETA: 13s - loss: 1. - ETA: 1 - ETA: 9s - loss: 1.5249 - accura - ETA - ETA: 3s - ETA: 2s - loss: 1.5113  -\n",
      "Epoch 4/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 1.3708 - accuracy: 0.5630 - val_loss: 1.5632 - val_accuracy: 0.5140cura - ETA: 1:02 - loss: 1.3934 - accuracy: 0.55 - ETA: 1:02 - loss: 1.3938 - accura - E - ETA: 59s - ETA: 57s - loss: 1.3752 - accuracy: 0 - ETA: 56s - loss: 1.3710 -  - ETA: 47s - - ETA: 45s - loss: 1.396 - ETA: 43s - loss: 1. - ETA: 41s  -  - ETA: 28s - loss: 1.3920 - accurac - ETA: 27s - loss: 1.3928 \n",
      "Epoch 5/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 1.2658 - accuracy: 0.6010 - val_loss: 1.6413 - val_accuracy: 0.4751TA: 52s - loss: 1.30 - ETA: 51s - loss: 1.3090 - accur - ETA: 50s - loss: 1.3078  - ETA: 48s - loss: 1.3090 - accur - ETA: 47s - loss: - ETA: 45s - loss: 1.3068 - accura - ETA: 45s - lo - ETA: 42s - loss: 1.2952 - accur - ETA: 41s - loss: 1.2 - ETA: 39s - loss: 1.2965 - accur - ETA: 35s - loss: 1.2927 - a - ETA: 30s - loss: 1.2777 - accura - ETA: 29s - loss - ETA: 23s - loss: 1.2800 - accura - ETA: 22s - loss: 1.2806 - accuracy: 0. - ETA: 22s - loss: 1.2791 - accu - ETA: 21s - loss: 1.27 - ETA: 19s - loss - ETA: 17s - loss: 1.2729 - accuracy: 0.59 - ETA: 17s - loss: 1.2731 - accurac - ETA: 16s - loss: 1.2701  - ETA: 15s - los - ETA: 0s - loss: 1.2663 \n",
      "Epoch 6/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 1.1902 - accuracy: 0.6263 - val_loss: 1.4453 - val_accuracy: 0.5419loss: 1.2199  - ETA: 33s - loss: 1.2072 - ETA: 2s - l\n",
      "Epoch 7/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 1.1231 - accuracy: 0.6498 - val_loss: 1.7271 - val_accuracy: 0.5261TA: 1:05 - los - ETA: 1:03 - loss: 1.1887 -  - - ETA: 54s - loss:  - ETA: 44s - loss: 1. - ETA: 2s - loss: 1.1220 - ac - ETA: 2s - loss: 1.1232  - ETA\n",
      "Epoch 8/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 1.0766 - accuracy: 0.6695 - val_loss: 1.6191 - val_accuracy: 0.5407oss: 1.10 - ETA: 44s - loss: 1.1136 - - ETA: 43s - loss: 1.1151 - accuracy: 0. - ETA: 43s - loss: 1.117 - ETA: 37s - loss: 1.101 - ETA: 18s - loss: 1.0827 - accuracy:  - ETA: 17s - loss: 1.0825 - a - ETA: 16s - loss:  - ETA: 1s - los - ETA: 0s - loss: 1.0765 - accuracy: 0.66\n",
      "Epoch 9/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 1.0272 - accuracy: 0.6821 - val_loss: 1.3734 - val_accuracy: 0.5662\n",
      "Epoch 10/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.9812 - accuracy: 0.6981 - val_loss: 1.5342 - val_accuracy: 0.5541- loss: 0.9893 - accuracy: 0 - ETA: 33s - - ETA: 30s - loss: 0.992 - ETA: 25s - \n",
      "Epoch 11/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.9476 - accuracy: 0.7078 - val_loss: 1.3870 - val_accuracy: 0.5954.9799 - accuracy: 0.689 - ETA: 55s - loss: 0.9765 - ETA: 54s -  - ETA: 44s - loss: 0.9676 - - ETA: 43 - ETA: 40s - loss: 0.9712 - accuracy: - ETA: 39s - loss: 0.9727 - accuracy: 0 - ETA: 39s - loss: 0.9763 - accuracy: 0. - ETA: 39s - loss: 0.9759 - accurac - ETA: 38s -  - ETA: 14s - - ETA: 0s - loss: 0.9473 - accuracy: \n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.9201 - accuracy: 0.7188 - val_loss: 1.5346 - val_accuracy: 0.55777 - ETA: 56s - loss: 0.888 - ETA: 54s - loss: 0.8 - ETA: 41s - loss: 0.8973 - accuracy:  - ETA: 40s - loss: 0.8977 - ac - ETA: 39s\n",
      "Epoch 13/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.8900 - accuracy: 0.7287 - val_loss: 1.7078 - val_accuracy: 0.5553racy: - ETA: 53s - loss: 0.8901 - ac - ETA: 52s - loss: 0.8932 - accuracy:  - ETA: 52s - loss: 0.8881 - accur - - ETA: 48s - loss: 0.8801 - ac - ETA: 47s - loss: 0.8843 - accuracy: - ETA: 46s - loss: 0.88 - ETA: 15s - loss: 0.8964 - accura - ETA:\n",
      "Epoch 14/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.8711 - accuracy: 0.7339 - val_loss: 1.4883 - val_accuracy: 0.5601ss: 0.8671 -  - ETA: 43s - lo - ETA: 41s - loss: 0.8715 - accuracy: 0.734 - ETA: 41s - loss: 0.8 - ETA: 39s - loss: 0.8733 - ac - ETA: 38s - loss: 0.86 - ETA: 36s - loss: 0.8707  - ETA: 35s - los - ETA: 3 - ETA: 29s - loss: 0.8779 - accuracy: 0.73 - ET - ETA: 26s - loss: 0.8806 - a - ETA: 25s - loss: 0.882 - ETA: 19s  - ETA: 17s - loss: 0.8867 - accuracy -  - ETA: 13s - loss: 0.8826 - accuracy: - ETA: 0s - loss: 0.8711 - accura\n",
      "Epoch 15/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.8446 - accuracy: 0.7419 - val_loss: 1.6377 - val_accuracy: 0.5456 loss: 0 - ETA: 1:03 - los - ETA: 51 - ETA: 48s - loss: 0.84 - ETA: 13s - loss: 0 - ETA: 1s - loss: 0 - ETA: 0s - loss: 0\n",
      "Epoch 16/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.8201 - accuracy: 0.7490 - val_loss: 1.6484 - val_accuracy: 0.56626s - loss: 0.8 - ETA: 0s - loss: 0.8199 - accuracy: 0.74\n",
      "Epoch 17/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.8038 - accuracy: 0.7534 - val_loss: 1.6561 - val_accuracy: 0.5674 loss: 0.8103 - - ETA: 43s - los - ETA: 41s - loss: 0 - ET - ETA: 10s - loss: 0.8017 - accuracy: 0.754 - ETA: 10s - loss: 0. - E - ETA: 7s - loss: 0.8030 - accuracy:  - ETA: 7s - loss: 0.8018 - accu - E\n",
      "Epoch 18/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.7820 - accuracy: 0.7617 - val_loss: 1.5129 - val_accuracy: 0.5723 27s - loss: 0.7809 - accuracy:  - ETA: 27s - loss: 0.7804 - accuracy: 0. - ETA: 26s - loss: 0.7806 - - ETA: 25s - loss: 0.7801 - accuracy: 0.7 - ETA: 25s - loss: 0.7806 - accuracy: 0.7 - ETA: 24s - loss:\n",
      "Epoch 19/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.7653 - accuracy: 0.7671 - val_loss: 1.5699 - val_accuracy: 0.5589acy: - ETA: 5 - ETA: 51s - loss: 0.7743 - accuracy: 0. - ETA: 51s - loss: 0.7730 - - ETA: 50s - loss: 0.7756 - ac - ETA: 49s - loss: 0.7738 -  - ETA: 47s - - ETA: 0s - loss: 0.7649 - accuracy: 0.\n",
      "Epoch 20/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.7498 - accuracy: 0.7716 - val_loss: 1.7474 - val_accuracy: 0.5687 ETA: 50s - loss: 0.7515 - accuracy:  - ETA: 49s - loss: 0.75 - ETA: 47s - loss: 0.7481 - accu - ETA: 46s - loss: 0.74 - ETA: 45s - loss: 0.7472 - accu - ETA: 44s - loss: 0.7434 - accuracy: 0 - E - ETA: 40s - - ETA: 37s - loss: 0.74 - ETA: 24s - loss: 0.7506 - accura - ETA: 24s - loss: - ETA: 8s - loss: 0.7512 - accura - ETA: 8s - los - ETA: 5s - los - ETA: 4s - loss: 0.7 - E\n",
      "Epoch 21/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.7342 - accuracy: 0.7762 - val_loss: 1.5847 - val_accuracy: 0.5711s - loss: 0.7220 - accuracy - ETA: 43s - loss: 0.7204 - accuracy: 0.784 - ETA: 43s - loss: 0.7204 - accuracy: 0.78 - ETA: 43s - loss: 0\n",
      "Epoch 22/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.7221 - accuracy: 0.7799 - val_loss: 1.5882 - val_accuracy: 0.55770 -  - ETA: 53s - loss: 0 - ETA: 51s - loss: 0.7208 - accuracy - ETA: 50s - loss: 0.7176 - acc - ETA: 49s - loss: 0.7170 - accu - ETA: 48s - loss: 0.7128 - accuracy - ETA: 48s - loss: 0.7197 - a - ETA: 46s - loss: 0.7202 - accuracy: 0.7 - ETA: 46s - loss: 0.7199 - accuracy - ETA: - - ETA: 39s - loss: 0.7155 - accuracy:   - ETA: 31s - loss: 0.7259 - a - ETA: 30s  - ETA: 27s - loss: 0.7269 - accu - ETA: 26s - loss: 0.7286 - ac - ETA: 25s - loss: 0.7281 - accuracy: - E - ETA: 21s -  - ETA: 19s -  - ETA: 8s - l - ETA: 6s - loss: 0.719 - ETA: 5s - loss: 0.7205 - accura - ETA: 5s - loss: 0 - ETA: 1s - loss: 0.7229 - accu - ETA: 0s - loss: 0.7228 - ac\n",
      "Epoch 23/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.7100 - accuracy: 0.7832 - val_loss: 1.5678 - val_accuracy: 0.56268s - loss: 0.7302 - accuracy: 0.77 - ETA: 58s - loss: 0.7283 - acc - E - ETA: 31s - loss: 0.7237 - accu - ETA: 30s - loss: 0.7227 - ETA: 29s - los - ETA: 26s - loss: 0.7200 - accurac - ETA: 26s - loss: 0 - ETA: 16s - loss: 0.7\n",
      "Epoch 24/100\n",
      "1465/1465 [==============================] - 66s 45ms/step - loss: 0.6930 - accuracy: 0.7885 - val_loss: 1.5008 - val_accuracy: 0.5699ss:  - ETA: 39s - loss: 0.6934 - accurac - ETA: 38s - loss - ETA: 1s - l\n",
      "Evaluating model...\n",
      "ROC: 0.955\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.68\n",
      "F-Score: 0.68\n",
      "\n",
      "*** Train on {1, 2, 3, 4, 5, 8, 9} Validate on 6 Test on 7 ***\n",
      "val shape:  (823, 128, 128, 1)\n",
      "test shape:  (838, 128, 128, 1)\n",
      "train shape:  (148491, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1485 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "1485/1485 [==============================] - 74s 50ms/step - loss: 2.1264 - accuracy: 0.2690 - val_loss: 1.9982 - val_accuracy: 0.2733 - loss: 2.3375 - accuracy: 0.180 - ETA: 50s - loss: 2.3370 - accuracy: 0. - ETA: 49s - loss: 2.3358 - accuracy: 0.180 - ETA: 49s - loss: 2.3354 - accuracy:  - ETA: 49s - loss: 2.3325 - accurac - ETA: 48s - loss: 2.3315 - accuracy - ETA: 47s - loss: 2.3293 - accuracy: 0.1 - ETA: 47s  - ETA: 43s - loss: 2.315 - ETA: 38s - loss: 2.2880 - accuracy: 0.20 - ETA: 37s - loss: 2.2 - ET - ETA: 32s - loss: 2.2577 - accuracy: 0.21 - ETA: 32s - loss: 2.2581 - accuracy: 0. - ETA: 31s - loss: 2.2567 - accuracy:  - ETA: 31s - loss: 2.2545 - accuracy: 0.2 - ETA: 31s - loss: 2.2531 - accuracy: 0.217 - ETA - ETA: 27s - loss: 2.2383 - accuracy:  - ETA: 26s - loss: 2.2363 - accuracy: 0.2 - ETA: 26s - loss: 2.2337 - accuracy: 0.22 - ETA: 26s - loss: 2.2331 - acc - ETA: 25s - loss: 2.2279 - accu - ETA: 24s - loss: 2.2238 - accuracy: 0.228 - ETA: 24s - loss: 2.2226 - accuracy: 0.22 - ETA: 23s -  - ETA: 17s - loss: 2.1931 - accura - ETA: 16s - loss: 2 - ETA: 10s - loss: 2.1627 - accuracy: 0.2 - ETA: 10s - loss: - ETA: 8s - loss: 2 - ETA: 7s - loss: 2.1517 - accu - ETA: 7s - loss: 2.1 - ETA: 6s - loss: 2.1 - ETA: 1s - loss: 2.1322 - accuracy - ETA: 1s - los\n",
      "Epoch 2/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.7631 - accuracy: 0.4171 - val_loss: 1.6789 - val_accuracy: 0.4045accura - ETA: 52s - loss: 1.8377 -  - ETA: 51s - loss: 1.8473 - accuracy: - ETA: - ETA: 47s - loss: 1 - ETA: 45s - loss: 1.8437 - accuracy:  - ETA: 44s - loss: 1.8400 - accura - ETA: 44s - loss: 1.8362 - - ETA: 42s - loss: 1.8348  - ETA:  - ETA: 38s - loss: 1.8302 - acc\n",
      "Epoch 3/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.5678 - accuracy: 0.4936 - val_loss: 1.4735 - val_accuracy: 0.4893 ETA - ETA: 1:01 - loss: 1.6508 - accura - ETA: 1:00 - loss: 1.6385 - accura - ETA: 56s - loss: 1.6473 - acc - ETA: 55s - loss: 1.6425 - accur - ETA: 54s - loss: 1.6485 - ac - ETA: 53s - loss: 1.6452 - accu - ETA: 48s - loss: 1.6301 - accuracy: 0.471 - - ETA: 45s - loss: 1.6288 - accuracy:  - ETA: 45s - loss: 1 - ETA: 43s - loss: 1.6223 - - ETA: 41s - loss - ETA: 39s - loss: 1.6178 - accuracy: 0. - ETA: 39s - loss: 1.6168 - accur - - ETA: 34s - loss: 1.6111 - accuracy: 0 - ETA: 34s - loss: 1.6107 - accuracy: 0 - ETA: 22s - loss: 1.5859 - accuracy: 0. - ETA: 22s - loss: 1.5855 - accuracy: 0 - ETA: 22s - loss: 1.5 - ETA: 20s - loss: 1.5821 - accur - ETA: 19 - ETA: 0s - loss: 1.568\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.4285 - accuracy: 0.5432 - val_loss: 1.4078 - val_accuracy: 0.5274\n",
      "Epoch 5/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.3236 - accuracy: 0.5804 - val_loss: 1.4887 - val_accuracy: 0.5334 1.3800 - accuracy: 0.567 - ETA: 52s - loss: 1.3776 - accurac - ETA: 51s - loss - ETA: 49s - loss: 1.3631 - accurac - ETA: 48s - loss: 1.3682 - a - ETA: 47s - - ETA: 44s - loss: 1.3575 - - ETA: 43s - loss: 1.3568 - accuracy: 0.569 - ETA: 42s - loss: 1.3567 - ETA: 41s - loss: 1 - ETA: 39s - loss: 1. - ETA: 33s - loss: - ETA: 31s - loss:\n",
      "Epoch 6/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.2445 - accuracy: 0.6066 - val_loss: 1.4463 - val_accuracy: 0.5274 - accurac - ETA: 53s - loss: 1.3013 - accuracy:  - ETA: 52s - loss: 1.2970 - a - ETA: 51s - loss: 1.2985 - accuracy: 0. - ETA: 51s - loss: 1.2974 - accuracy: 0.588 - ETA: 5 - ETA: 48s - loss: 1.2923 - accuracy: - ETA:\n",
      "Epoch 7/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.1782 - accuracy: 0.6308 - val_loss: 1.3575 - val_accuracy: 0.5597 - accura - ETA: 33s - loss: 1.200 - ETA: 32s - loss: 1.2017 - accuracy - ETA: 27s - loss: 1.2032 - accuracy - - ETA: 23s - loss:  - ETA: 21s - loss: 1.1940 - accu - E - ETA: 13s - loss\n",
      "Epoch 8/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.1196 - accuracy: 0.6492 - val_loss: 1.1896 - val_accuracy: 0.62651258 - accuracy: 0.64 - ETA: 34s - loss: 1.1248 - a - ETA: 33s - loss: 1.1264 - accurac - ETA: 32s - loss: 1.1258 - accuracy: - ETA: 28s - ETA: 3s - - ETA: 0s - loss: 1.1199 - accuracy: 0.64\n",
      "Epoch 9/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.0761 - accuracy: 0.6637 - val_loss: 1.2632 - val_accuracy: 0.6026s - loss: - ETA: 33s - loss: 1.082 - ETA: 32s - loss: 1.0840 - ac - ETA: 31s - loss - ETA: 25s -\n",
      "Epoch 10/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.0301 - accuracy: 0.6793 - val_loss: 1.3472 - val_accuracy: 0.6217 - loss: 1.0197 - accu - ETA: 1:01 - loss: 1.0315 - accura - ETA: - ETA: 59 - ET - ETA: 46s -  - ETA: 43s - loss: 1.0482 - ETA: 42s - loss: 1.048 - ETA: 22s - loss - ETA: 16s - loss: 1.0254 - accuracy:  - ET - ETA: 0s - loss: 1.0316 - ac\n",
      "Epoch 11/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.9860 - accuracy: 0.6941 - val_loss: 1.5204 - val_accuracy: 0.55497s - loss: 0.9916 - accu - ETA: 26s - loss: 0.9900 - accur - ETA: 2 - ETA: 22s - loss: 0.9911 - accura - ETA: 21s  - ETA: 0s - loss: 0.9852 - accuracy: 0.69\n",
      "Epoch 12/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.9517 - accuracy: 0.7056 - val_loss: 1.1481 - val_accuracy: 0.63965 - accuracy: 0.\n",
      "Epoch 13/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.9244 - accuracy: 0.7161 - val_loss: 1.1182 - val_accuracy: 0.6742cy:  - ETA: 1:02 - loss: 0.9799 - accura - ETA: 1:01 - - ETA: 1:0 - ETA: 57s - loss: 0.98 - ETA: 55s - loss: 0.9709 - accuracy: 0 - ETA: 55s - loss: 0.9630 -  - ETA: 54s - l - ETA: 51s - loss: - ETA: 49s - loss: 0.966 - ETA: 22s - loss: 0.9 - ETA: 2s - loss: 0.9 - ETA: 1s - loss: 0.9258  - ETA: 1s - loss:\n",
      "Epoch 14/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.8909 - accuracy: 0.7253 - val_loss: 1.2648 - val_accuracy: 0.6098\n",
      "Epoch 15/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.8716 - accuracy: 0.7335 - val_loss: 1.3538 - val_accuracy: 0.5835TA: \n",
      "Epoch 16/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.8440 - accuracy: 0.7410 - val_loss: 1.2748 - val_accuracy: 0.6205: 0.8585  - ETA: 56s - loss: 0.8554 - accuracy: 0.73 - ETA: 56s - loss: 0.8571 - accuracy: 0. - ETA:  - ETA: 53s - loss: 0.8615 -  - ETA: 52s - loss: 0.8562 - a - ETA: 50s - loss: 0.8529 - accuracy: - ETA: 50s - loss: 0.8587 - - ETA: 48s - loss: 0.8532 - accuracy: 0.737 - ETA: 48s - loss: 0.853 - ETA: 47s - loss: 0.851 - ETA: 45s - loss: - ETA - ETA\n",
      "Epoch 17/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.8222 - accuracy: 0.7483 - val_loss: 1.2287 - val_accuracy: 0.6277\n",
      "Epoch 18/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.8048 - accuracy: 0.7536 - val_loss: 1.7253 - val_accuracy: 0.5191\n",
      "Epoch 19/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7853 - accuracy: 0.7606 - val_loss: 1.2325 - val_accuracy: 0.63968s - loss: 0.7665 - accuracy: - ETA: 44s - loss: 0.7765 -  - ETA: 42s - loss: 0.7745 - accuracy:  - ETA: 42s - loss: 0.7734 - accurac - ETA:  - ETA: 38s - loss: 0.7758 - accuracy:  - ETA: 38s - loss: 0.7745 - accuracy - E - ETA: 30s - loss: 0.7743 - accu - - ETA: 26s  - ETA - ETA: 0s - loss: 0.7845 \n",
      "Epoch 20/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7675 - accuracy: 0.7654 - val_loss: 1.1839 - val_accuracy: 0.67300.7495 - ac - ETA: 39s - \n",
      "Epoch 21/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7539 - accuracy: 0.7692 - val_loss: 1.2501 - val_accuracy: 0.6587curacy: 0 -  - ETA: 26s - loss: 0.7596 - accuracy:  - ETA: 26s - loss: 0.75 - ETA: 24s - loss: 0.7602 - accuracy: 0. - ETA: 24s - loss: 0.7588 - accuracy: 0.767 - ETA: 24s - loss: 0.7588 - ac - ETA: 22 - ETA: 20 - ETA: 2s - ETA: 1s -\n",
      "Epoch 22/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7317 - accuracy: 0.7778 - val_loss: 1.2407 - val_accuracy: 0.64327429 - accuracy: 0 - ETA: 32s - loss: 0.7396 - accuracy: - ETA: 31s - ETA: 28s - loss: 0.7375 - accuracy: 0 - ETA: 28s - loss: 0.736 - ETA: 26s - loss: 0.7348 - accuracy: - ETA: 26s - loss: 0 - ETA: 16s - loss: 0.7277 - accuracy:  - ETA: 5s - loss: 0.7330 - accuracy - - ETA: 3s - l - ETA: 2s - loss: -\n",
      "Epoch 23/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7244 - accuracy: 0.7803 - val_loss: 1.2257 - val_accuracy: 0.6492.7059 - accurac - ETA: 39s - ETA: 1\n",
      "Epoch 24/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7138 - accuracy: 0.7828 - val_loss: 1.1629 - val_accuracy: 0.6742ss: 0.7284 - - ETA: 36s - l - ETA: 34s - loss: 0.7220 - accuracy:  - ETA: 3 - ETA:  - ETA: 24s - loss: 0.724\n",
      "Epoch 25/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6971 - accuracy: 0.7889 - val_loss: 1.2244 - val_accuracy: 0.6706\n",
      "Epoch 26/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6865 - accuracy: 0.7913 - val_loss: 1.1483 - val_accuracy: 0.6695\n",
      "Epoch 27/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6780 - accuracy: 0.7946 - val_loss: 1.2428 - val_accuracy: 0.6384 - a - ETA: 17s - loss: 0.6698 - accurac - ETA: 13s - ETA - ETA: 6s - loss: 0.6767 - accura - ETA: 6s - loss: 0.6775 - accu - ETA: 6s - loss: 0.678 -\n",
      "Epoch 28/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6678 - accuracy: 0.7959 - val_loss: 1.1702 - val_accuracy: 0.6527\n",
      "Evaluating model...\n",
      "ROC: 0.933\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.60\n",
      "F-Score: 0.6\n",
      "\n",
      "*** Train on {1, 2, 3, 4, 5, 8, 9} Validate on 7 Test on 6 ***\n",
      "val shape:  (838, 128, 128, 1)\n",
      "test shape:  (823, 128, 128, 1)\n",
      "train shape:  (148491, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1485 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "1485/1485 [==============================] - 76s 51ms/step - loss: 2.0818 - accuracy: 0.2854 - val_loss: 2.0047 - val_accuracy: 0.3560: 41s - loss:  - ETA: 18s - loss: 2.1 - ETA: 16s - loss: 2.14 - ETA: 14s - loss: 2.137 - ETA: 13s - loss: 2.1302 - accuracy: 0.266 - ETA: 12s - loss: 2.1297 - accur - E - ETA: 9s - loss: 2 - ETA: 8s - loss: 2.1 - ETA: 7s\n",
      "Epoch 2/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.7061 - accuracy: 0.4385 - val_loss: 1.7583 - val_accuracy: 0.39610s - loss: 1.7074 - accuracy:  - ETA: 0s - loss: 1.7062 - accuracy: \n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.5193 - accuracy: 0.5072 - val_loss: 1.6712 - val_accuracy: 0.4168 loss: 1.5931 - accuracy: 0.479 - ETA: 43 - ETA: 40s - \n",
      "Epoch 4/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.3841 - accuracy: 0.5575 - val_loss: 1.6706 - val_accuracy: 0.4447: 55s - lo - ETA: 52s - loss: 1.4124 - accuracy: 0.55 - ETA: 48s - loss: 1.4082 - accura - ETA - E - ETA: 30s - loss: 1.3981 - - ETA: 29s - loss: 1.4026  - ETA: 27s - - ETA: 21s - loss: 1.3 - ETA: 1 - ETA: 16s - loss:  - ETA: 11s - loss: 1.3885 - accurac - ETA: 10s - loss: 1.3879 - accuracy: 0.556 - ETA: 10s - loss: 1.3875 -  - ETA: 9s - loss: 1.3879 - \n",
      "Epoch 5/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.2866 - accuracy: 0.5915 - val_loss: 1.5333 - val_accuracy: 0.5091 1.3153 - accuracy: 0 - ETA: 53s - loss: 1.3225 - accuracy: 0. - ETA: 53s - loss: 1.3195  - ETA: 51s - loss: 1.3239 - accuracy - ETA:  - ETA:\n",
      "Epoch 6/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.2035 - accuracy: 0.6206 - val_loss: 1.4100 - val_accuracy: 0.5917\n",
      "Epoch 7/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.1316 - accuracy: 0.6452 - val_loss: 1.3413 - val_accuracy: 0.5711 loss: 1.1 -  - ETA: 44s - loss: 1.1241 - accura - ETA: 43s - loss - ETA: 41s - loss: 1.1276 - accuracy: - ETA: 40s  - ETA: 37s - loss: 1.1293  - ETA: 32s - loss:  - ETA: 30s - loss: 1.1321 - a - ETA: 29s - loss: 1.1357 - accuracy: 0 - ETA: 28s - loss - ETA: 26s - loss: 1.1 - ETA: 24s - loss: 1.1303 - accur - ETA: 24s - loss: - ETA: 21s - loss:   - ETA: 0s - loss: 1.1312 - accu\n",
      "Epoch 8/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 1.0780 - accuracy: 0.6647 - val_loss: 1.4025 - val_accuracy: 0.58577 - acc - ETA: 58s - loss: 1 - ETA: 56s  - ETA: 53s - loss: 1.0714  - ETA: 52s - loss: 1.0671 - ETA: 1s - l - ETA: 0s - loss: 1.0781 - accuracy\n",
      "Epoch 9/100\n",
      "1485/1485 [==============================] - 66s 45ms/step - loss: 1.0280 - accuracy: 0.6814 - val_loss: 1.3267 - val_accuracy: 0.6160- loss: 1.0253 - acc - ETA: 21s - loss: 1.0261 - accuracy - ETA: 20s - loss: 1.0247  - ETA: 19s - loss: 1.02 - ETA: 17s - ETA: 1s - loss: 1.0288  - ETA: 0s - loss: 1.0283 - accura - ETA: 0s - loss: 1.0282 - accuracy - ETA: 0s - loss: 1.0280 - accuracy: 0.68\n",
      "Epoch 10/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.9882 - accuracy: 0.6966 - val_loss: 1.4748 - val_accuracy: 0.5747os  - ETA: 53s - loss: 0.9776 - accura - ETA: 53s - - ETA: 50s - loss: 0.9776 - accurac -  - ETA: 42s - ETA: 36s - loss: 0.9743 - accuracy:  - ETA: 35s - loss: 0.9775  - ETA: 34s - loss: 0.9750 - ETA: 1s - los - ETA: 0s - loss: 0.9879 - accuracy: \n",
      "Epoch 11/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.9430 - accuracy: 0.7098 - val_loss: 1.4714 - val_accuracy: 0.5930oss: 0 - ETA: 46s - loss: 0. - ETA: 44s - loss: 0.9426 - acc - ETA: 43s - loss - ETA: 41s - loss: 0.9395 - - ETA: 39s - loss: 0.9417 - accuracy: - ETA: 39s - loss: \n",
      "Epoch 12/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.9082 - accuracy: 0.7216 - val_loss: 1.5720 - val_accuracy: 0.5711s - lo - ETA: 50s - loss: 0.8971 - accurac - ETA: 49s - loss: 0.8998 - accur - ETA: 48s - loss: 0.9038 - accuracy - ETA: 48s - loss: 0.9027 - ac - ETA: 47s - los - ETA: 22s - l - ETA: 2s - loss: 0.906\n",
      "Epoch 13/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.8785 - accuracy: 0.7319 - val_loss: 1.5612 - val_accuracy: 0.5990 loss: 0.8728 - accura\n",
      "Epoch 14/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.8512 - accuracy: 0.7404 - val_loss: 1.2589 - val_accuracy: 0.6464\n",
      "Epoch 15/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.8309 - accuracy: 0.7459 - val_loss: 1.3921 - val_accuracy: 0.6136- ETA: 57s - loss: 0.7739 - accuracy: 0 - ETA: 57s - loss: 0.771 - ETA: 55s - loss: 0.7933 - accuracy: 0.755 - ETA: 55s - loss: 0. - E - ETA: 3s - loss: 0.8238 - accuracy: 0.74 - ETA: 2s - loss: 0.8239 - accura - ETA: 2s - loss: 0.823 - ETA: 1s - - ETA: 0s - loss: 0.8295 - accu\n",
      "Epoch 16/100\n",
      "1485/1485 [==============================] - 66s 45ms/step - loss: 0.8026 - accuracy: 0.7548 - val_loss: 1.1923 - val_accuracy: 0.6367TA: 35s - loss: 0.7878 - accurac - ETA: 34s - loss: 0.7899 - accuracy: 0. - ETA: 34s - loss:  - ETA: \n",
      "Epoch 17/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7884 - accuracy: 0.7601 - val_loss: 1.1372 - val_accuracy: 0.6744- - ETA: 37s - loss: 0.7919 - accuracy: 0. - ETA: 33s - loss: 0.789 - ETA: 32s - loss: 0.79 - ETA: 30s - los - ETA: 1s - l\n",
      "Epoch 18/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7675 - accuracy: 0.7669 - val_loss: 1.1678 - val_accuracy: 0.6646674 - accuracy\n",
      "Epoch 19/100\n",
      "1485/1485 [==============================] - 66s 45ms/step - loss: 0.7511 - accuracy: 0.7705 - val_loss: 1.1944 - val_accuracy: 0.6659\n",
      "Epoch 20/100\n",
      "1485/1485 [==============================] - 66s 45ms/step - loss: 0.7346 - accuracy: 0.7762 - val_loss: 1.0399 - val_accuracy: 0.6950\n",
      "Epoch 21/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7241 - accuracy: 0.7819 - val_loss: 1.0588 - val_accuracy: 0.6768\n",
      "Epoch 22/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.7088 - accuracy: 0.7845 - val_loss: 1.2406 - val_accuracy: 0.665900 - loss: 0.69 - ETA: 58s - loss: 0 - ETA: 56s - los - ETA: 54s - loss: 0.6961 - ETA: 5 - - ETA: 42s - loss: 0.7072 - a - ETA: - ETA: 38s - loss: 0.7065 - accuracy: 0 - ETA: 38s - loss: 0.7078 - accu - ETA: 37s - loss: 0.7081 - accuracy: 0. - ETA: 36s - loss: 0.7051 - accuracy:  - ETA: 36s - loss: 0 - ETA: 34s - loss: 0.7096  - ETA: 32s - loss: 0.7075 - acc - ETA: 28s - loss: 0.7110 - accurac - ETA: 27s - loss: 0.7115 - a - ETA: 26s - loss: 0.7133 -  - ETA: 25 - ETA - ETA: 12s - loss: 0.7127 - - ETA: 10s - loss: 0.7120 - accurac - ETA: 9s -  - ETA: 8s - loss: 0.7114 - ac - ETA: 0s - loss: 0\n",
      "Epoch 23/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6947 - accuracy: 0.7889 - val_loss: 1.2425 - val_accuracy: 0.6513\n",
      "Epoch 24/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6872 - accuracy: 0.7910 - val_loss: 1.1757 - val_accuracy: 0.6379\n",
      "Epoch 25/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6780 - accuracy: 0.7937 - val_loss: 1.2098 - val_accuracy: 0.6574oss: 0.6952 - accuracy:  - ETA: 1: - ETA: 1:00  -  - ETA: 44s - - ETA: 42s - loss: 0.6812 - a - ETA: 40 - ETA: 34s - loss: 0.6 - ETA: 32s - loss: 0.6785 - accuracy: 0.792 - ETA: 32s - lo\n",
      "Epoch 26/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6648 - accuracy: 0.7959 - val_loss: 1.1444 - val_accuracy: 0.6561\n",
      "Epoch 27/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6524 - accuracy: 0.8021 - val_loss: 1.1887 - val_accuracy: 0.6598 loss: 0.6164  - ETA: 55s - loss: 0.6144 - accuracy: - ETA: 55s -  - ETA: 52s - l - ETA: 50s - loss: 0.6228 - - ETA: 45s - loss: 0.6351  - ETA: 43s - - ETA: 41s - los - ETA: 38s - loss: 0.6409 - a - ET - ETA: 30s - loss: - ETA: 28s - loss: 0.6441 - ETA: 26s - loss: 0.6459 - accura - ETA: 26s - loss: 0.6458 - accuracy: 0 - ETA: 25s - loss: 0.6444  - ETA: 17s - loss: 0.64\n",
      "Epoch 28/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6445 - accuracy: 0.8039 - val_loss: 1.3042 - val_accuracy: 0.6598\n",
      "Epoch 29/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6361 - accuracy: 0.8075 - val_loss: 1.2460 - val_accuracy: 0.63551s  - ETA: 48s - loss: 0 - ETA: 28s - ETA: 26s - los - ETA: 23s - loss: 0.6 - ETA: 21s - loss: 0.6314  - E - ETA: 6s - loss: 0.6324 - accuracy - ETA: 0s - loss: 0.634\n",
      "Epoch 30/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6301 - accuracy: 0.8089 - val_loss: 1.2694 - val_accuracy: 0.6780 - loss: 0.6261 - ETA: 25s - loss: 0.6262 - ETA: 19s - loss: 0.63 - ETA: 18s - loss:  - ETA: 16s - loss - ETA: 1s - loss: 0.6296 - accura - ETA: 0s - loss: 0.6295  - ETA: 0s - loss: 0.6302 - accuracy: 0.80\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6212 - accuracy: 0.8110 - val_loss: 1.2552 - val_accuracy: 0.6549- loss: - ETA: 19s - loss: 0.61 - ETA: 17s - loss: 0.6203 - accuracy:  - ETA: 17s - lo\n",
      "Epoch 32/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6147 - accuracy: 0.8122 - val_loss: 1.1880 - val_accuracy: 0.6525\n",
      "Epoch 33/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.6052 - accuracy: 0.8144 - val_loss: 1.2605 - val_accuracy: 0.6549\n",
      "Epoch 34/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.5974 - accuracy: 0.8180 - val_loss: 1.2907 - val_accuracy: 0.6671los - ETA: 55s - loss: 0.5899  - ETA: 53s - loss: 0.5958 - accu - ETA: 52s - loss: 0.5978 - accura - ETA: 51s - loss: 0.5948 - accuracy: 0.820 - ETA: 51s - loss: 0.5952 - accura - ETA: 32s - loss:  - ETA: 30 - ETA: 12s - loss: 0.5957 - ac\n",
      "Epoch 35/100\n",
      "1485/1485 [==============================] - 67s 45ms/step - loss: 0.5949 - accuracy: 0.8186 - val_loss: 1.6550 - val_accuracy: 0.6209loss: 0.599 - ETA: 58s - loss: 0.58 - ETA: 56s  - ETA: 53s - loss: - ETA: 44s - loss: 0 - ETA - ETA: 39s - loss: 0.587 - ETA: 33s - lo - ETA: 31s - loss: 0.583 - ETA: - ETA: 23s - loss: 0.5873 - accuracy: 0. - ETA: 22s - loss: 0.5878 - accur - ETA: 22s - loss: 0.5882 - accuracy: 0.821 - ETA: 21s - loss: 0.5 - ETA: 20s - loss: 0.5884 - accur - ETA: 19s - loss: 0.5879 - accuracy: - ETA: 18s - loss: 0.5869 - a - ETA: 17s - loss: 0.5893 - accuracy: 0.82 - ETA: 17s - loss: 0.5894 - accuracy:  - ETA: 16s - loss: 0.5891 - accurac - ETA: 16s - loss: 0.5900 - ETA: 3s - loss: 0.593 - ETA: 2s - loss: 0.5935 - \n",
      "Evaluating model...\n",
      "ROC: 0.943\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.66\n",
      "F-Score: 0.66\n",
      "\n",
      "*** Train on {1, 2, 3, 4, 5, 6, 7} Validate on 8 Test on 9 ***\n",
      "val shape:  (806, 128, 128, 1)\n",
      "test shape:  (816, 128, 128, 1)\n",
      "train shape:  (149310, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1494 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "1494/1494 [==============================] - 74s 50ms/step - loss: 2.1808 - accuracy: 0.2396 - val_loss: 1.9584 - val_accuracy: 0.34313563 - accurac - E - ETA: 49s - loss: 2.3457 - accuracy: 0. - ETA: 48s - loss: 2.3446 - accuracy: 0.175 - ETA: 48s - loss: 2.3448 - - - ETA: 4 - ETA: 31s - loss: 2.2951 - acc - ETA: 30s - loss: 2.290 - ETA: 28s - loss: 2.2843 - accuracy: 0. - ETA: - ETA: 25s - loss: 2.2717 - accuracy: - ETA: 24s - los - ETA: 21s - loss: 2.2585 - accu - ETA: 20s - loss: 2.2553 - a - ETA: 15s - loss: 2.2365 - accur - ETA: 14s - loss: 2. - ETA: 12s - loss: 2.2265 - accuracy: 0.2 - ETA: 12s - loss: 2.2247 - accuracy: 0 - ETA: 5s - loss: 2.1990 - accuracy: 0.23 - - ETA: 3s - loss: 2.1 - ETA: 2s - loss: 2.1901  - ETA: 1s - loss: 2.1875 - accu - ETA: 0s - loss: 2.185\n",
      "Epoch 2/100\n",
      "1494/1494 [==============================] - 68s 45ms/step - loss: 1.7540 - accuracy: 0.4102 - val_loss: 1.6448 - val_accuracy: 0.49149s - loss: 1. - ETA: 57s - loss: 1.8981 - accuracy: 0.3 - ETA: 57s - loss: 1.8977 - accuracy: 0.3 - ETA: - ETA: 46s - lo - ETA: - ETA: 37s - loss: 1.8384 - accuracy: 0 - ETA: 37s - loss: 1.8402 - accuracy: 0. - ETA: 37s - loss: 1.8395 - accuracy:  - ETA: 36s - loss: 1.8372 - - ETA: 3 - ETA: 24s - lo - ETA: 5s - loss: 1.7630 -  - ETA: 0s - loss: 1.7\n",
      "Epoch 3/100\n",
      "1494/1494 [==============================] - 68s 45ms/step - loss: 1.5357 - accuracy: 0.4984 - val_loss: 1.5978 - val_accuracy: 0.5331 - ETA: 1:02 - loss: 1.6252 - accuracy: 0.46 - ETA: 1:02 - loss: 1.6231 - accuracy: 0.46 - E\n",
      "Epoch 4/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 1.3888 - accuracy: 0.5546 - val_loss: 1.4724 - val_accuracy: 0.5882loss:  - ETA: 44s - loss: 1.4284 - accuracy - ETA: 36s - loss: 1.4284 -  - E - ETA: 31s - loss: 1.4220 - accuracy:  - E - ETA: 23s - loss: 1.409 - ETA\n",
      "Epoch 5/100\n",
      "1494/1494 [==============================] - 68s 45ms/step - loss: 1.2749 - accuracy: 0.5923 - val_loss: 1.3512 - val_accuracy: 0.6164: 1.2856 - accuracy:  - ETA: 53s - loss: 1.2855 - accuracy: 0. - ETA: 53s - loss: 1.27 - ETA: 51s - loss: 1.2876 - accur - ETA: 50s - loss: 1.2833 - accuracy: 0.5 - ETA: 50s - loss: 1.2883 - accu - ETA: 49s - loss: 1.2876 - ETA: 32 -  - ET - ETA: 23s - los - ETA: 4s - loss: 1.2708 - accuracy:  - ETA: 4s - los - ETA: 3s - l - - ETA: 0s - loss: 1.2739 - accuracy: 0.\n",
      "Epoch 6/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 1.1825 - accuracy: 0.6270 - val_loss: 1.8501 - val_accuracy: 0.5699 - ETA: 55s - - ETA: 53s - loss: 1.2261 - accuracy: 0.6 - ETA: 52s - loss: 1.2227 - accuracy: 0.610 - ETA: 52s - l - ET - ETA: 36s - loss: 1. - ETA: 30s - loss: 1.1967 - accuracy:  - ETA: 30s - loss: 1.1969 - accurac - ETA: 29s - loss: 1. - ETA - ETA: 2s - loss: 1.1838 \n",
      "Epoch 7/100\n",
      "1494/1494 [==============================] - 68s 45ms/step - loss: 1.1208 - accuracy: 0.6500 - val_loss: 1.2858 - val_accuracy: 0.6336 loss: 1.1369 - accura - ETA: 16s - loss: 1.1382 - accuracy: 0. - ETA: 15s - ETA: 12s - loss: 1.1351 - acc - ETA: 7s - loss: 1.1293 - accura - ETA: 5s - loss: 1 - ETA:  - ETA: 0s - loss: 1.1\n",
      "Epoch 8/100\n",
      "1494/1494 [==============================] - 68s 45ms/step - loss: 1.0570 - accuracy: 0.6709 - val_loss: 1.4681 - val_accuracy: 0.6507 loss - ETA: 55s - loss: 1.0574 - accuracy: 0.668 - ETA: 55s - ETA: 53s - loss: 1.0503 - accurac - ETA: 52s - loss: 1.0579 - accuracy: 0.67 - ETA: 52s - loss: 1.0561 - accuracy: 0. - ETA: 51s - loss: 1.0548 - accur - ETA: 50s - loss: 1.0618 - accurac - ETA: 50s - loss: 1.0663 - ETA: 44s - loss: 1. - ETA: 39s - loss: 1.05 - ETA: 37s - loss: 1.0624 -  - ETA: 36s - lo - ETA: 33s - los - ETA: 27s - loss: 1.0700 - accurac - ETA: 27s - loss: 1.0707 - accuracy: 0.6 - ETA: 26s - loss: - ETA: 24s - loss: 1.0739 - - ETA: 23s - loss: 1.0717 - accuracy:  - ETA: 22s - loss: 1.0720 - accurac - ETA: 22s - loss: 1.0723 - accuracy: 0 - ETA: 21s - loss: 1.0703 - accuracy: 0.667 - ETA: 21s - loss: 1.0708  - ETA: 2 - ETA: 2s - loss: 1.057\n",
      "Epoch 9/100\n",
      "1494/1494 [==============================] - 68s 45ms/step - loss: 1.0117 - accuracy: 0.6880 - val_loss: 1.4554 - val_accuracy: 0.6556263 - accur - ETA: 53s - loss: 1.0266 - accura - \n",
      "Epoch 10/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.9675 - accuracy: 0.7017 - val_loss: 1.4666 - val_accuracy: 0.667921 - accuracy:  - ETA: 52s - loss: 0 - ETA: 46s -  - ETA: 22s - lo - ETA: 2s - loss: 0.9683 - accura - ETA:  - ETA: 0s - loss: 0.9677 - accuracy\n",
      "Epoch 11/100\n",
      "1494/1494 [==============================] - 68s 45ms/step - loss: 0.9315 - accuracy: 0.7145 - val_loss: 1.5156 - val_accuracy: 0.6801A: 59s - loss: 0.9399 - accurac - ETA: 58s - loss: - ETA: 56s - loss: 0.9250 - accuracy:  - ETA: 55s - loss: 0.9307 - accuracy:  - ETA: 55s - loss: 0 - ETA: 49s - loss: - ETA: 40s - loss: 0.94 - ETA: 23s - loss: 0.9376 - a -\n",
      "Epoch 12/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.8958 - accuracy: 0.7269 - val_loss: 1.3493 - val_accuracy: 0.6740s - loss: 0.8577 - acc - ETA: 39s - loss: 0.8943  - ETA: 37s - loss: 0. - ETA: 36s - l\n",
      "Epoch 13/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.8642 - accuracy: 0.7367 - val_loss: 1.3634 - val_accuracy: 0.6936TA:  - ETA: 54s - loss: 0.8 - ET - ETA: 45 - ETA: 31s -  - ETA: 28s - loss: 0.8614 - accu - ETA: 6s - l - E - E\n",
      "Epoch 14/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.8371 - accuracy: 0.7446 - val_loss: 1.5893 - val_accuracy: 0.6716\n",
      "Epoch 15/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.8078 - accuracy: 0.7550 - val_loss: 1.4990 - val_accuracy: 0.6875\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.7910 - accuracy: 0.7621 - val_loss: 1.5124 - val_accuracy: 0.70227930 - accu - ETA: 20s - loss: 0.7924 -\n",
      "Epoch 17/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.7698 - accuracy: 0.7674 - val_loss: 1.5106 - val_accuracy: 0.7132\n",
      "Epoch 18/100\n",
      "1494/1494 [==============================] - 68s 45ms/step - loss: 0.7446 - accuracy: 0.7750 - val_loss: 1.5920 - val_accuracy: 0.7047A: 58s  - ETA: 56s - loss: 0.7339 - ETA: 54s  - ETA: 51s - ETA: 34s - loss: 0.7408 - accuracy - ETA: 33s - loss: 0.739 - - ETA: 24s - loss: 0.7403 - accuracy: 0.776 - ETA: 24s  - ETA: 22s - loss: 0.7441 -  - ETA: 20s - l - ETA\n",
      "Epoch 19/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.7233 - accuracy: 0.7813 - val_loss: 1.3837 - val_accuracy: 0.7194uracy:  - ETA: 0s - loss: 0.7242 - \n",
      "Epoch 20/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.7145 - accuracy: 0.7846 - val_loss: 1.5631 - val_accuracy: 0.697329s - loss: 0.7334 - accuracy:  - ETA: 28s - loss: - ETA: 1s - loss: 0.7179 - ac - ETA: 1s - loss: 0.7168 - accuracy:  - ETA: 1s - l\n",
      "Epoch 21/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.7011 - accuracy: 0.7896 - val_loss: 1.3384 - val_accuracy: 0.7255\n",
      "Epoch 22/100\n",
      "1494/1494 [==============================] - 67s 45ms/step - loss: 0.6883 - accuracy: 0.7925 - val_loss: 1.6298 - val_accuracy: 0.7071\n",
      "Evaluating model...\n",
      "ROC: 0.92\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.56\n",
      "F-Score: 0.56\n",
      "\n",
      "*** Train on {1, 2, 3, 4, 5, 6, 8} Validate on 9 Test on 7 ***\n",
      "val shape:  (816, 128, 128, 1)\n",
      "test shape:  (838, 128, 128, 1)\n",
      "train shape:  (148638, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1487 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "1487/1487 [==============================] - 74s 50ms/step - loss: 2.1560 - accuracy: 0.2585 - val_loss: 1.8716 - val_accuracy: 0.3914oss: 2.3593 - ac - ETA: 49s - loss: 2.3570 - accuracy: 0.1 - ETA: 49s - loss: 2.3544 -  - ETA: 47s - loss: 2.3450 - a - ETA: 46s - loss: 2.3421 - accurac - ETA: 45s - loss: 2.3402 - accuracy: 0 - ETA: 44s - - ETA: 41s - loss: 2.3270 - - ETA: 11s - loss: 2.2004 - - ETA: 8s - loss: 2.1 - ETA - ETA: 5s - loss: 2.1766  - ETA: 2s - loss: 2.1649 - accuracy:  - ETA: 2s - loss: 2\n",
      "Epoch 2/100\n",
      "1487/1487 [==============================] - 68s 46ms/step - loss: 1.7463 - accuracy: 0.4243 - val_loss: 1.5211 - val_accuracy: 0.5072rac - ETA: 54s - loss: 1.8490 - acc - ETA: 52s - los - ETA: 50s - loss: 1.8432 - acc - ETA: 49s - loss: 1.8416 - accuracy:  - ETA: 48s - loss:  - ETA: 46s - loss: 1.8453 - ac - ETA: 45s - loss: 1  - ETA: 36s - ETA: 33s - loss: 1.8169 - accura - ETA: 32s - loss: 1.81 - ETA: 31s - loss: 1.8088 - accurac - ETA: 26s - loss: 1.8009 - accuracy: 0 - ETA: 26s - loss: 1.7999 - accuracy: 0.405 - ETA: 26s - loss: 1.7991 - accur - ETA: 25s - loss: 1.7964 - accuracy: 0.4 - ETA: 24 - ETA: 21s  - ETA: 19s - loss: 1.7859 - accuracy - ETA: 18s - ETA: 15s - loss: 1.7850 - accuracy: 0.410 - ETA: 15s - loss: 1.7853 - accuracy: 0.4 - ETA: 15s - loss: 1.7849 - accu - ETA: 14s - loss:  - ETA:  - ETA: 9s - loss: 1.7760 - ac\n",
      "Epoch 3/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 1.5210 - accuracy: 0.5086 - val_loss: 1.7662 - val_accuracy: 0.415303 - loss: - ETA: 1:02 - ETA: 1:01 - los - ET - ETA: 23s - loss: 1.5406 - accur - ETA: 22s - loss: 1.5380 - accuracy: - ETA: 21s - lo - ETA: 19s - loss: - ETA - ETA: 1s - l\n",
      "Epoch 4/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 1.3704 - accuracy: 0.5632 - val_loss: 1.4522 - val_accuracy: 0.5191TA: 38s - loss: 1.4230 - accuracy: 0.54 - ETA: 38s - loss: 1.4223  - ETA: 36s - loss - ETA: 34s  - ETA: 31s - loss: 1.4047 -  - ETA: 30s - loss: 1.4040 - accuracy: 0 - ETA: - ETA: 2s - loss: 1.3701  - ETA: 1s - loss: 1.3 - ETA: 0s - loss: 1.3704 - accura\n",
      "Epoch 5/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 1.2683 - accuracy: 0.6016 - val_loss: 1.2854 - val_accuracy: 0.5788: 47s - loss: 1.2707 - accuracy: - ETA: 47s -  - ETA: 33s - loss: 1.2772 - ac - ETA: 32s - loss: 1.2787 -  - ETA: 31s - loss: 1.27 - ETA: 29s - loss: 1.2783 - accuracy: 0 - ETA: 29s - loss: 1. - ETA: 27s - loss: 1.2833 - accuracy: 0.59 - E - ETA: 19s - loss: - E - ETA: 5s\n",
      "Epoch 6/100\n",
      "1487/1487 [==============================] - 68s 45ms/step - loss: 1.1862 - accuracy: 0.6310 - val_loss: 1.2753 - val_accuracy: 0.58471.2339 - accuracy: 0.618 - ETA: 57s - loss: 1.2343 - accuracy: - ETA: 57s - loss: 1.2248 - accuracy: 0. - ETA: 56s - loss: 1.2236 - accura  - ETA: 52s - loss: 1.2242 - ETA: 47s - loss: 1.2243 - accuracy: 0.  - ETA: 43s - loss: 1.2129 - accuracy: 0.62 - ETA: 43s - loss: 1.2135 - accu - ETA: 42s - loss: 1.2156 - accuracy: 0.6 - ETA: 41s - loss: 1.2124 - a - ETA: 40s - loss: 1.2200 - - ETA: 39s - loss: 1.2167 -  - ETA: 37s - loss: - ETA: 35s - loss: 1.2184 - accuracy:  - ETA: 35s - loss: 1.2159 - accuracy:  - ETA: 34s - loss: 1. - ETA: 32s - lo - ETA: - ETA: 27s - loss: 1.2058 - accu - ETA: 26s - loss: 1.2013 - accuracy - ETA - ETA: 1s - loss: 1.1879 - accuracy: 0.63 - ETA: 1s -\n",
      "Epoch 7/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 1.1230 - accuracy: 0.6546 - val_loss: 1.2149 - val_accuracy: 0.6038oss: 1.1185 - accuracy: 0 - ETA: 51s - loss: 1.1192 - accu - ETA: - ETA: 44s - loss: - ETA: 41s - loss: 1.1130 - ETA: 40s - lo - ETA: 30s - loss: 1.1156 - accuracy: 0.659 - ETA: 30s - loss: 1.1150 - accuracy:  - ETA: 30s - loss: 1 - ETA: 28s - loss: 1.1171 - accuracy: 0. - ETA: 27s - loss: 1.1177 -  - ETA: 26s - loss: 1.1188 -  - ETA: 21s - lo - ETA: 15s - loss: 1.1274 - accuracy:  - ETA: 11s - loss: 1.1242 - acc - ETA: 10s - loss: - ETA: 9s - ETA: 7s - los - ETA: 6s - loss: 1 - ETA: 5s - loss: 1 - E - ETA: 1s - l\n",
      "Epoch 8/100\n",
      "1487/1487 [==============================] - 68s 45ms/step - loss: 1.0651 - accuracy: 0.6720 - val_loss: 1.3627 - val_accuracy: 0.56215 - ETA: 30s - loss: 1.07 - ETA: 28s - loss:  - ETA: 26s - loss: 1.0673 - accuracy:  - ETA: 26s - loss: 1.0652 - accuracy: 0.671 - ETA: 26s - loss: 1.0647 -  - ETA: 24s - loss: 1.0630 - accuracy: 0. - E - - ETA: 17s - loss: 1.0647   - ETA: 0s - loss: 1.0655 - accuracy: 0.\n",
      "Epoch 9/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 1.0204 - accuracy: 0.6898 - val_loss: 1.1766 - val_accuracy: 0.6420cy:  - ETA:  - ETA: 52s - loss: 1.0419 - accuracy: 0.6 - ETA: 51s - loss: 1.0434 - accuracy: 0. - ETA: 51s - loss: 1.0420 - accuracy: - ETA: 50s - loss: 1.0381 - ETA: 49s - loss: 1.0455 - - ETA: 36s - loss: 1.0389 - accuracy: 0 - ETA: 36s - loss: 1.04 - ETA: 3 - ETA: 31s - loss: 1.0328 - accuracy: 0 - ETA: 31s - loss: 1.0323 - accur - ETA: 30s - loss: 1.0313 -  - ETA: 29s -\n",
      "Epoch 10/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.9770 - accuracy: 0.7030 - val_loss: 1.1736 - val_accuracy: 0.6169: 1:03 - loss: 0.9877 - accuracy: 0.70 - ETA: 1:02  - ETA: 59s - loss: 0.9890 - accur - ETA: 58s - los -  - ETA: 49s -  - ETA: 46s - loss: 0 - ETA: 44s - loss: 0.9918 - ac - ETA: 43s - loss: 0.9887 - accuracy: 0.700 - ETA: 43s -  - ETA: 41s - loss: 0.9820 - accuracy: 0. - ETA: 40s - loss: 0.9869 - - ETA: 39s - loss: 0. - ETA: 37s - loss: 0.9820 - a - ETA - ETA: 18s - loss: 0.9796 - accurac  - ETA: 1s - los\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1487/1487 [==============================] - 68s 45ms/step - loss: 0.9405 - accuracy: 0.7147 - val_loss: 1.2086 - val_accuracy: 0.615806 - loss: 0.9711 - accuracy: 0. - ETA: 1:06 - los - ETA: 1:02 - loss: 0.9437 - accuracy:  - ETA -  - ETA: 46s - loss: 0.9551 - accuracy: 0 - ETA: 45s - - ETA: 39s - loss: 0.9517 - accu - ETA: 38s - loss: 0.947 - ETA: 36s - loss: 0.9443 - accuracy:  - ETA:  - ETA: 33s - l - ETA - ETA: 27s - loss: 0.9480 - accuracy - ETA: 26s - loss: 0.9460 - accuracy:  - ETA: 26s - loss: 0.9477 - accuracy: 0 - ETA: 25s - loss: 0.9462 - accura - ETA: 21s - loss: 0.9423 - a - ETA: 16s - loss: 0.9392 - - ETA: 11s - loss: 0.9387 - acc - ETA: 2s - loss:\n",
      "Epoch 12/100\n",
      "1487/1487 [==============================] - 68s 45ms/step - loss: 0.9075 - accuracy: 0.7255 - val_loss: 1.1982 - val_accuracy: 0.637257s -  - ETA: - ETA: 51s - loss: 0.9189 - a - ETA: 50s - loss: 0.9155 -  - ETA: 49s  - ETA: 46s - loss: 0.9071 \n",
      "Epoch 13/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.8782 - accuracy: 0.7340 - val_loss: 1.1987 - val_accuracy: 0.6396 ETA: 54s - loss: 0.87 - ETA: 52s - loss: 0.8811 - accur -  - ETA: 48s - loss: 0.8870 - accuracy: - ETA: 44s - loss: 0.8940 - accuracy - ETA: 43s - - ETA: 37s - loss: 0.882 - ETA: 35s - loss: 0.8842 - accuracy - ETA: 34s - - ETA: 32s -  - ETA: 29s - loss: 0.8847 - ac  - ETA: 21s - loss: 0.8770 -  - ETA: 20s - loss: 0.8795 - accuracy: - ETA: 19s -  - ETA: 16s - loss: 0.8787 - accurac - E - ETA: 4s - ETA: 0s - loss: 0\n",
      "Epoch 14/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.8514 - accuracy: 0.7443 - val_loss: 1.2595 - val_accuracy: 0.6265- accurac - ET - ETA: 11s - loss: 0.8554 - ETA: 9s -  - ETA: 8s - - ETA: 7s - loss: 0.8508 - accuracy - ETA: 6s - loss: 0.8510 - accuracy: 0.74 - ETA: 1s - loss: 0.8503 - accuracy:  - ETA: 1s - l\n",
      "Epoch 15/100\n",
      "1487/1487 [==============================] - 68s 45ms/step - loss: 0.8273 - accuracy: 0.7513 - val_loss: 1.1819 - val_accuracy: 0.6539 59s - - ETA: 56s - l - ETA: 53s - loss: 0.8137 - - ETA: 41s - lo - ETA: 35s - loss: 0.8361 - accuracy: 0 - ETA: 35s - loss: 0.834 - ETA: 33s - loss: 0.8338 - accurac - ETA: 32s - loss: 0.8358 - accura - ETA: 31s - loss: 0.8344 - accuracy: 0 - ETA: 31s - loss: 0.8350 - accuracy: 0. - ETA: 31s - loss: 0.8357 - E - ETA: 1s - loss: - ETA: 0s - loss: 0.8275 - accura - ETA: 0s - loss: 0.8271 - accuracy: 0.75 - ETA: 0s - loss: 0.8274 - accuracy: 0.75\n",
      "Epoch 16/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.8058 - accuracy: 0.7569 - val_loss: 1.2403 - val_accuracy: 0.6169 54s - loss: 0.8099 - accuracy: 0.7 -  - ETA: 50s - loss: 0.8 - ETA: 48s - loss: 0.8098 - accuracy:  - ETA: 48s - loss: 0.8104 - - ETA: 47s - loss: 0.8094 - a - ETA: 45s - - ETA: 6s - l - ETA\n",
      "Epoch 17/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.7878 - accuracy: 0.7632 - val_loss: 1.4009 - val_accuracy: 0.5561accuracy: 0.77 - E - ETA: 32s - loss: 0.7738 - accuracy:  - ETA: 32s - loss: 0.7741  - ETA: 30s - loss: 0.7736 - a - ETA: 29s - loss: 0.7763 - accuracy: 0 - ETA: 29s - loss: 0.7746 - ET - - ETA: 17s - loss: 0.7864 - accurac - ETA: 16s - loss: 0.7872 - accuracy: - ETA: 16s - l - ETA: 13s - loss: 0.7877 - accuracy: 0.7 - ETA: 13s - loss: 0 - ETA: 11 - E - ETA: 2s - loss: 0.7893 - accuracy: 0.76 - ETA: 2s - los - ETA: 0s - loss: 0.7\n",
      "Epoch 18/100\n",
      "1487/1487 [==============================] - 68s 45ms/step - loss: 0.7642 - accuracy: 0.7704 - val_loss: 1.1885 - val_accuracy: 0.63370.7509 - accuracy - ETA: 49s - loss: 0.7499 - accuracy: - ETA: 48s - loss: 0.7483 - accuracy:  - ETA: 4 - ETA: 45s - loss: 0.7 - ETA: 43s - loss: 0.7482 - accuracy:  - ETA: 42s - - ETA: 40s - loss: 0.7504 - - ETA: 38s - loss: 0.7529 - accuracy: 0. - ETA: 38s - loss: 0.7506 - accuracy:  - ETA: 38s - loss: 0.7499 - accurac - ETA: 37s - lo  - ETA: 31s - loss: 0.7570 - - ETA: 29s - loss: 0.7 - ETA: 28s - loss: 0.7685 -  - ETA: 26s - loss: 0.7677 - accuracy: 0.7 - ETA: 26s - loss: 0.768 - ETA: 21s - loss: 0.7710 - accuracy - ETA: 20s - loss: 0.7695 - accuracy: 0 - - ETA: 12s - loss: 0.7696 - accuracy: 0.7 - ETA: 12s - loss: 0.7689 - accuracy:  - ETA: 12s - loss: 0.769 - ETA: 10s - l\n",
      "Epoch 19/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.7448 - accuracy: 0.7766 - val_loss: 1.1424 - val_accuracy: 0.6492 - ETA: 1:00 - loss: 0.7201 - accu - - ETA: 48s - loss: 0.7391 - accuracy: - E - ETA: 44s - loss: 0.7389 - accu - ETA: 43s - loss: 0.7393 - accuracy -  - ETA: 36s - loss: 0.7412 - accuracy: 0.7 - ETA: 35s - loss: 0.7425 - ac - ETA: 34s - loss: 0.7408 - accuracy:  - E - ETA: 30s - loss: 0.7410 -  - ETA: 29s - loss: 0.7374 - a - ETA: 28s - loss: 0.7390 - - ETA: 23s - loss - ETA: 21s - loss: 0.7376 - ac - ETA: 19s - loss: 0 - ETA: 18s - loss: 0.7364 - accuracy: 0 - ETA: 17s - loss: 0.7374 - accura - ETA: 16s - loss: 0.7365 - accuracy: 0.77 - ETA: - ETA: 13s - loss: 0.7341 - accuracy: 0.7 - ETA: 0s - loss: 0.7\n",
      "Epoch 20/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.7391 - accuracy: 0.7770 - val_loss: 1.1958 - val_accuracy: 0.6539 - ETA: 1:03 - l - ETA: 55s - loss: 0.7329 - accuracy: 0.77 - ETA: 55s -  - ETA: 53s - loss: 0.7441 - a - ETA: 51s - loss: 0.7482 - accuracy: 0 - ETA: 51s - loss: 0.7465 - accuracy: - ETA: 47s -  - - ETA: 0s - loss: 0.7392 - accuracy: \n",
      "Epoch 21/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.7197 - accuracy: 0.7825 - val_loss: 1.1742 - val_accuracy: 0.6551\n",
      "Epoch 22/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.7032 - accuracy: 0.7880 - val_loss: 1.1897 - val_accuracy: 0.6575.7060 - accur - ETA: 33s - loss: 0.7027 - a - ETA: 32s - loss: 0.7032 - accuracy: 0 - ETA: 31s - loss: 0.7021 - accuracy: 0.787 - ETA: 31s - loss:  - - ETA: 18s - loss: 0.70 - ETA: 4s - loss: 0.7\n",
      "Epoch 23/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6909 - accuracy: 0.7910 - val_loss: 1.2274 - val_accuracy: 0.6372: 54s - loss: 0.6922 - accuracy: 0.783 - ETA: 54s - loss: 0. - ETA: 49s - loss: 0.7008 - accur - ETA: 4  - ETA: 26s - loss: 0.6880 - accuracy: - ETA: 26s - loss - ETA: 24s - ETA: 21s - loss: 0.6936 - ETA: 16s - E - ETA: 2s - loss:\n",
      "Epoch 24/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6824 - accuracy: 0.7942 - val_loss: 1.1681 - val_accuracy: 0.6611 52s - loss: 0.6507 - accu - ETA: 51s - loss: 0 - ETA: 45s - los - ETA: 43s - loss: 0.6546 - ac - ETA: 42s - loss: 0.6555 - a - ETA: 41s -  - ETA:  - ETA: 13s - loss: 0.6700 - accur - ETA: 12s - loss:  - ETA: 5s - loss: 0.6785 - accura - ETA: 1s - loss:\n",
      "Epoch 25/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6737 - accuracy: 0.7965 - val_loss: 1.1973 - val_accuracy: 0.667122s - loss: 0.6739 - a - ETA: 21s - loss: 0.67 - ETA: 19s - loss: 0.6720 - a - ETA: 18s - loss: 0.6726 - acc - ETA: 2s - loss: 0.6 - ETA: 1s - loss: 0.6733 - accuracy: 0.79 -\n",
      "Epoch 26/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6569 - accuracy: 0.8005 - val_loss: 1.2263 - val_accuracy: 0.6277 0.6186 - accuracy:  - ETA: 57s  - ETA: 55s - loss: 0.6279  - ETA: 53s  - ETA: 51s - loss: 0.6416 - accuracy:  - ETA: 50s - loss: 0.6442 - accuracy:  - ETA: 50s - loss: 0.6434 - a - ETA: 49s - loss: 0.644 - ETA: 47s - loss: 0.6458 -  - - ETA: 42 - ETA: 39s - loss: 0.6525 - accuracy: 0.802 -  - ETA: 36s - loss: 0.6507 - accu - ETA: 35s - loss: 0.6549 - a - ETA: 34s - loss: 0.6573 - accura - ETA: 33s - los - ETA: 16s - loss: 0.6606  - ETA: 15s - loss: 0.6610 - accuracy: 0. - ETA: \n",
      "Epoch 27/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6506 - accuracy: 0.8041 - val_loss: 1.1271 - val_accuracy: 0.643200 - a - ETA: 23s - loss: 0.6493 - accura - ETA: 22s - loss: 0.6496 - accura - ETA: 22s - loss: 0.6493  - ETA: 16s - loss: 0.6522 - accuracy: 0.80 - ETA: 16s - loss: 0.6530  \n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6435 - accuracy: 0.8054 - val_loss: 1.2442 - val_accuracy: 0.6193 los - ETA: 47s - loss: 0.6397 - accuracy: - ETA: 46s - loss: 0.6371 - accuracy: 0.80  - ETA: 39s - loss:  - ET - ETA: 26s - loss: 0.6462 - accura - ETA: 25s - l - ETA: 22s - loss: 0.6432 - accuracy: 0. - ETA: 22s - loss: 0.6425 - accuracy: 0 - ETA: \n",
      "Epoch 29/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6319 - accuracy: 0.8089 - val_loss: 1.1798 - val_accuracy: 0.6504: 0.6167 - accuracy: - ETA: 50s - loss: 0.6150 - accuracy: - ETA: 50s - loss: 0.6166 - accu - ETA: 45s - loss: 0.6173 - accu - ETA: 44s - loss: 0.6178 - accuracy: 0. - ETA: 44s - loss: 0.6167 - ETA: 35s - loss: 0.6147 - accuracy:  - ETA: 34s - loss: 0.6156 - a - ETA: 33s - loss: 0.6162 - accuracy: 0.81 - ETA: 33s - loss: 0.6165 - accurac - ETA: 32s - loss: 0.6169  - ETA: 31s - loss: 0.618 - ETA: 22s - loss: 0.6222 - accuracy: 0.811 - ETA: 22s - loss: 0.6223  - ETA: 17s - loss: 0.6284 - accurac - ETA: 9s - - ETA: 4s - loss: 0.6304 - accuracy: 0.80 - ETA: 4s - loss: 0.6307 - accuracy - ETA: 4s - loss: - ETA: 1s - l\n",
      "Epoch 30/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6253 - accuracy: 0.8101 - val_loss: 1.2198 - val_accuracy: 0.64926s - loss: 0.6 - ETA: 25s - loss: 0.6258 - accuracy: 0.8 - ETA: 24s - loss: 0.6258 - accu - ETA: 23s - loss: 0.6256 - a\n",
      "Epoch 31/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6145 - accuracy: 0.8136 - val_loss: 1.2357 - val_accuracy: 0.6909\n",
      "Epoch 32/100\n",
      "1487/1487 [==============================] - 68s 45ms/step - loss: 0.6139 - accuracy: 0.8127 - val_loss: 1.2859 - val_accuracy: 0.6432.6169 - - ETA: 45s - loss: 0.6240 - accuracy:  - ETA: 44s - loss: 0.6241 - accuracy - ETA: 44s -  - ET - ETA: 34s - loss: 0.6197 - accuracy - ETA: 30s - loss - ETA: 17s - loss: 0.6188 - accuracy: 0.8 - ETA: 16s - loss: 0 - ETA: 14s - loss: 0.6166 - ETA: 7s - l - ETA: 6s - l\n",
      "Epoch 33/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.6048 - accuracy: 0.8160 - val_loss: 1.1743 - val_accuracy: 0.6730loss: 0.59 - ETA: 48s - loss: 0.5949 - accuracy: 0. - ETA: 48s - loss: 0.5965 - accur - ETA: 47s - loss: 0.5936 - accuracy: 0 - ETA: 46 - ETA: 40s  - ETA: 37s - loss - ETA: 35s - - ETA: 32s - loss: 0.5972 - accuracy: 0 - ETA: 32s - loss: 0.5967 - accuracy: 0 - ETA: 32s - loss: 0.5994 - accura - ETA: 31s - loss: 0 - ETA: 29s - loss: 0.5994 - accuracy: 0.8 - ETA: 29s - - ETA: 26s - loss: 0.6024 - accuracy: 0.815 - ETA: 26s - loss: 0.60 - ETA: 0s - loss: 0.604\n",
      "Epoch 34/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.5950 - accuracy: 0.8181 - val_loss: 1.1970 - val_accuracy: 0.6611 E - - ETA: 33s - loss: 0.5905 - - ETA: 32s - loss: 0.58 -  - ETA: 3s - loss: - ETA: 1s - loss:\n",
      "Epoch 35/100\n",
      "1487/1487 [==============================] - 68s 45ms/step - loss: 0.5928 - accuracy: 0.8190 - val_loss: 1.1998 - val_accuracy: 0.639659s - loss: 0.55 - ETA: 57s - loss: 0.560 - ETA: 56 - ETA: 38s - loss: 0.5880 - accurac - ET - - ETA: 2s - ETA: 0s - loss: 0.5932 \n",
      "Epoch 36/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.5827 - accuracy: 0.8229 - val_loss: 1.2451 - val_accuracy: 0.6516  - ETA: 39s - loss: 0.5733 - accuracy: 0 - ETA: 39s - loss: 0.5723 - accuracy:  - ETA: 38s - l - ETA: 21s - loss: 0.5808 - accuracy: 0.822 - ETA: 21s - loss: 0.5819 - accuracy: 0.822 - ETA: 21s - loss: 0.5818 - accurac - ETA: 20 - ETA: 17s - loss: 0.5 - ETA:  - ETA: 4s - loss: 0.5832 -  - E\n",
      "Epoch 37/100\n",
      "1487/1487 [==============================] - 68s 46ms/step - loss: 0.5790 - accuracy: 0.8231 - val_loss: 1.3501 - val_accuracy: 0.6635 0.5783 - ac - ETA: 1:00 -  - ETA: 54s - loss:  - ETA: 52s - lo - ETA: 50s - loss: 0.5882 - accurac - ETA: 49 - ETA: 46s - loss: 0.5908 - accu - ETA: 45s - loss: 0.5876 - accuracy: 0. - ETA: 44s - loss: 0.5886 - ac - ETA: 35s - loss: 0.5792 - accuracy: 0 - ETA: 35s - loss: 0.5783 - accuracy:  - ETA: 34s - loss: 0.5791 - accu - ETA: 22s - loss: 0.5774 - accuracy: 0.823 - ETA: 22s - loss: 0.5772 - accuracy: 0 - ETA: 21s - loss: 0.5769 - accuracy:  - ETA: 21s - loss: 0.57 - ETA: 19s - loss: 0.5762 - accur - ETA: 18s - l - ETA: 16s - loss: 0.5755 - acc - ETA: 15s - loss: 0.5748 - accuracy - ETA: 14s - \n",
      "Epoch 38/100\n",
      "1487/1487 [==============================] - 68s 46ms/step - loss: 0.5730 - accuracy: 0.8260 - val_loss: 1.3063 - val_accuracy: 0.6348ss: 0.5679 - accuracy: 0.826 - ETA: 45s - loss: 0.5680 - accura - ETA: 44s - l - - ETA: 38s - loss: 0.5646 - - ETA: 37s - loss: - ETA: 35s - loss: 0.5649 -  - ETA: 34s - loss: 0.5664 - accu - ETA: 33s - loss: 0.5666 - ETA: 31s - loss: 0.5680 - accuracy: 0. - ETA: 31s - loss: 0.5703 - acc - ETA: 30s - loss: 0.5695 - - ETA: 28s - loss: 0.5698 - accuracy: 0.826 - ETA: 28s - loss: 0. - ETA: 26s - loss: 0.5 - ETA: 24s  - ETA: 22s - loss: 0.5746 - accur - ETA: 21s - l - ETA: 15s  - ETA: 12s - - ETA: 9s - loss: 0.574\n",
      "Epoch 39/100\n",
      "1487/1487 [==============================] - 67s 45ms/step - loss: 0.5685 - accuracy: 0.8261 - val_loss: 1.2436 - val_accuracy: 0.6862 - accura - ETA: 53s - loss: 0.5 - ETA: 33s - loss: 0.5562 - accuracy: 0.830 - ETA: 33s - loss: 0.5559 - accuracy: 0 - ETA: 33s - loss: 0.55 - ETA: 31s - loss: 0.5605 - accuracy: - ETA: 30s - - ETA: 28s - loss: 0.5601 - accur - ETA: 27s - loss: 0.5624 -  - ETA: 25s\n",
      "Epoch 40/100\n",
      "1487/1487 [==============================] - 70s 47ms/step - loss: 0.5652 - accuracy: 0.8282 - val_loss: 1.2593 - val_accuracy: 0.6086cu - - ETA: 37s - loss: 0.5642 - - ETA: 35s - loss: 0.56 - ETA: 33s - loss: 0.5602 - accurac - ETA\n",
      "Epoch 41/100\n",
      "1487/1487 [==============================] - 71s 48ms/step - loss: 0.5565 - accuracy: 0.8307 - val_loss: 1.2787 - val_accuracy: 0.61585 - acc - ETA: 46s  - ETA: 43s - loss: 0.5423 - accurac - ETA: 42s - loss: 0.5444 - accuracy:  - ETA: 41s - loss: 0.545 - ETA: 39s - loss -  - ETA: 33s -  - ETA: 30s - loss: 0.5513 - accuracy: 0.8 - ETA: 30s - los - ETA: 27 - ETA: 24s - loss: 0.5546 - accu - ETA: 19s - loss: 0.5562 - accuracy: 0.83 - ETA: 19s - loss: - ETA: 13s - loss: 0.5513 - accuracy: 0.831 - ETA: 13s - loss: 0.5 - ETA:  - - ETA: 1s -\n",
      "Epoch 42/100\n",
      "1487/1487 [==============================] - 69s 47ms/step - loss: 0.5539 - accuracy: 0.8310 - val_loss: 1.2795 - val_accuracy: 0.6313\n",
      "Evaluating model...\n",
      "ROC: 0.959\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.71\n",
      "F-Score: 0.71\n",
      "\n",
      "*** Train on {1, 2, 3, 4, 5, 6, 7, 9} Validate on 10 Test on 8 ***\n",
      "val shape:  (837, 128, 128, 1)\n",
      "test shape:  (806, 128, 128, 1)\n",
      "train shape:  (148869, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1489 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "1489/1489 [==============================] - 74s 50ms/step - loss: 2.1959 - accuracy: 0.2429 - val_loss: 1.8072 - val_accuracy: 0.5124ETA: 41s - loss: 2.3365 - acc - ETA: 40s - loss: 2.3339 - accurac - ETA: 39s - los - ETA: 36s - loss: 2.3233 - accurac - ETA: 27s - l - ETA: 24s - loss: 2.2813 - accu - ETA: 19s - loss: 2.2661 - accu - ETA: 18s - loss: 2. - ETA: 16s - loss: 2.2568 - accu - ETA: 15s - loss: 2.2533 - accuracy: 0 - ETA: 15s - loss: 2.2523 - accuracy: 0.219 - ETA: 15s - loss:  - ETA: 12s - loss: 2.2445 - accu - ETA: 11s - loss: 2.2403 - ETA: 8s - loss: 2.2 - - ETA\n",
      "Epoch 2/100\n",
      "1489/1489 [==============================] - 68s 45ms/step - loss: 1.7898 - accuracy: 0.4038 - val_loss: 1.6349 - val_accuracy: 0.5099 0. - ETA: 45s - los - ETA: 42s - l - ETA: 40s - loss: 1.866 - ETA: 38s - loss - ETA: 3 - ETA: 33s - loss: 1.8442 - accur - ETA: 32s - loss: 1.840\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1489/1489 [==============================] - 67s 45ms/step - loss: 1.5664 - accuracy: 0.4919 - val_loss: 1.3588 - val_accuracy: 0.5943A: 39s - loss: 1.6133 - accuracy: 0. - ETA: 39s - loss: 1.6133 - acc - ETA: 37s - loss: 1.61 - ETA: 36s - loss: 1.610 - ETA: 34s - loss: 1.6074 - accuracy: 0.477 - ETA: 34s - loss: 1.6073 - accurac - ETA: 33s - loss: 1.6068 - accu - ETA: 32s - loss: 1.6099 - ac - - ETA: 28s - loss: 1.6023 - accuracy: 0.479 - ETA: 27s - loss: 1.6035 - accuracy - ETA: 27 - ETA: 24s - loss: 1.5962 - accuracy:  - ETA: 23s - loss: 1.5945 - accuracy: 0.482 - ETA: 23s - l - ETA: 21s - loss: 1.5948 - - ETA: 19s - loss: 1.5893 - ETA: 18s - loss: - ETA: 12s - loss: 1.5817 -  - ET\n",
      "Epoch 4/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 1.4058 - accuracy: 0.5476 - val_loss: 1.3859 - val_accuracy: 0.5298\n",
      "Epoch 5/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 1.2880 - accuracy: 0.5901 - val_loss: 1.3088 - val_accuracy: 0.6166\n",
      "Epoch 6/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 1.2052 - accuracy: 0.6180 - val_loss: 1.4879 - val_accuracy: 0.60675 - ETA: 46s - loss: 1.2308 - accuracy:  - E - ETA: 42s -  - ETA: 36s -  - ETA: 34s - loss: 1.2040 - accuracy - ETA: 33s - loss: 1.20 - ETA: 31s - loss: 1.20 - ETA: 30s - loss: 1.2037 - accuracy: 0. - ETA: 29s - loss: 1.2042 - ETA: 28s - loss:  - ETA: 26s - loss:  - ETA: 24s - loss: 1.2092 - ETA:  - ETA:  - ETA: 0s - loss: 1.2050 - accura\n",
      "Epoch 7/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 1.1399 - accuracy: 0.6427 - val_loss: 1.2721 - val_accuracy: 0.6179.1 - ETA: 31s -  - ETA: 25s  - ETA: 22s - loss: 1.1254 - - ETA: 17s  -  -\n",
      "Epoch 8/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 1.0816 - accuracy: 0.6640 - val_loss: 1.2590 - val_accuracy: 0.6328\n",
      "Epoch 9/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 1.0394 - accuracy: 0.6765 - val_loss: 1.3244 - val_accuracy: 0.6427\n",
      "Epoch 10/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 1.0002 - accuracy: 0.6907 - val_loss: 1.2272 - val_accuracy: 0.6663\n",
      "Epoch 11/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.9648 - accuracy: 0.7029 - val_loss: 1.3037 - val_accuracy: 0.6166\n",
      "Epoch 12/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.9297 - accuracy: 0.7150 - val_loss: 1.2726 - val_accuracy: 0.6390\n",
      "Epoch 13/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.8933 - accuracy: 0.7251 - val_loss: 1.4630 - val_accuracy: 0.6526loss: 0.9 - ETA: 22s - loss: - ETA: 20s - loss:\n",
      "Epoch 14/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.8766 - accuracy: 0.7322 - val_loss: 1.2517 - val_accuracy: 0.6340\n",
      "Epoch 15/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.8444 - accuracy: 0.7403 - val_loss: 1.2709 - val_accuracy: 0.640276 - accuracy: 0 - ETA: 55s - loss: 0.8437 - accuracy: 0 - E - ETA: 5s - loss: 0.8426 - accuracy: 0.74 - ETA: 5s - loss: 0.8425 - accuracy:  - ETA: 1s - loss: 0.8423 - accuracy - ETA: 1s - los\n",
      "Epoch 16/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.8262 - accuracy: 0.7477 - val_loss: 1.2933 - val_accuracy: 0.6625ETA: 51s - loss: 0.8346 - accuracy: 0. - ETA: 51s - loss: 0.8344 - accuracy - - E - ETA: 44s - loss: 0.8297 - accuracy: 0.7 - ETA: 43s - loss: 0.8304 - accuracy: 0.743 - ETA: 43s - loss: 0 - ETA: 41s - - ETA: 39s - loss: 0.8345 - accuracy: - ETA -  - ETA: 1s - los\n",
      "Epoch 17/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.8045 - accuracy: 0.7557 - val_loss: 1.2860 - val_accuracy: 0.6725- accu\n",
      "Epoch 18/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.7878 - accuracy: 0.7596 - val_loss: 1.3149 - val_accuracy: 0.6514 loss: 0. - ETA: 53s - loss: 0.7677 - accuracy: 0.7 - ETA: 53s - l - ETA: 43s - loss: - ETA: 41s - loss: 0.7994 - acc - ETA: 40s - loss: 0.796 - ETA: 35s - loss: 0.7915 - acc - ETA: 2s - l - ETA: 0s - loss: 0.7\n",
      "Epoch 19/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.7668 - accuracy: 0.7674 - val_loss: 1.2922 - val_accuracy: 0.642746s - loss: 0.7742 - ac -  - ETA: 38s - loss: 0.7563 - accur - ETA: 37s - loss: 0.7542 - accuracy: 0.7 - ETA: 37s - loss: 0.7531 -  - ETA: 35s - loss: 0. - ETA: 34s - loss: 0.7576 - accurac - ETA: 33s - loss: 0.7560  - ETA: 31s - loss: - ETA: 29s - loss: 0.7603 - accuracy: 0 - ETA: 6s - loss: - ETA: 5s - loss: 0.7667 - ac\n",
      "Epoch 20/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.7509 - accuracy: 0.7701 - val_loss: 1.4098 - val_accuracy: 0.6129\n",
      "Epoch 21/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.7360 - accuracy: 0.7766 - val_loss: 1.3295 - val_accuracy: 0.6452 38s - loss: - ETA - ETA: 33s - loss: 0.7499 - accuracy: 0 - ETA: 32s - loss: 0.750 - ETA: 23s - loss: 0.7423 - ETA: 22s - ETA: 19s - loss: 0.739 - ETA: 14s - -\n",
      "Epoch 22/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.7232 - accuracy: 0.7793 - val_loss: 1.2195 - val_accuracy: 0.6377\n",
      "Epoch 23/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.7091 - accuracy: 0.7842 - val_loss: 1.3102 - val_accuracy: 0.6278\n",
      "Epoch 24/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6940 - accuracy: 0.7891 - val_loss: 1.3640 - val_accuracy: 0.6464uracy: 0.7 - ETA: 37s - loss: 0.6882 - accuracy: - ETA: 37s - - ETA: 27s - loss: 0. - ETA: 25s - loss: 0.6910 - - ETA: 20s - loss: 0.6908 - accurac - ETA: 19s - loss: - ETA: 17s - los\n",
      "Epoch 25/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6862 - accuracy: 0.7903 - val_loss: 1.2062 - val_accuracy: 0.6725\n",
      "Epoch 26/100\n",
      "1489/1489 [==============================] - 68s 45ms/step - loss: 0.6764 - accuracy: 0.7930 - val_loss: 1.4377 - val_accuracy: 0.6551\n",
      "Epoch 27/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6650 - accuracy: 0.7964 - val_loss: 1.2296 - val_accuracy: 0.6873\n",
      "Epoch 28/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6551 - accuracy: 0.7999 - val_loss: 1.3128 - val_accuracy: 0.6663\n",
      "Epoch 29/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6461 - accuracy: 0.8033 - val_loss: 1.3547 - val_accuracy: 0.6476\n",
      "Epoch 30/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6356 - accuracy: 0.8055 - val_loss: 1.3903 - val_accuracy: 0.66638s - loss: 0.6381  - ETA: 1s - l - ETA: 0s - loss: 0.6364 \n",
      "Epoch 31/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6289 - accuracy: 0.8075 - val_loss: 1.3406 - val_accuracy: 0.670058s \n",
      "Epoch 32/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6195 - accuracy: 0.8101 - val_loss: 1.4918 - val_accuracy: 0.6390\n",
      "Epoch 33/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6112 - accuracy: 0.8132 - val_loss: 1.5320 - val_accuracy: 0.6625oss: 0.6127 - ac\n",
      "Epoch 34/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6071 - accuracy: 0.8148 - val_loss: 1.4139 - val_accuracy: 0.6588\n",
      "Epoch 35/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.6001 - accuracy: 0.8165 - val_loss: 1.2437 - val_accuracy: 0.6650\n",
      "Epoch 36/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.5929 - accuracy: 0.8190 - val_loss: 1.4619 - val_accuracy: 0.6675 ETA: 42s - loss: 0.5925 - - ETA: 33s - loss: 0.5876 - accuracy: 0.82 - ETA: 33s  - ETA: 20s - loss: 0.5875  \n",
      "Epoch 37/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.5837 - accuracy: 0.8207 - val_loss: 1.3310 - val_accuracy: 0.6861864 - accuracy: 0. - ETA: 51s - loss: 0.5857 - - ETA: 50s - l - ETA: 44s - loss: 0.577 - ETA: 0s - loss: 0.5839 - ac - ETA: 0s - loss: 0.5834 - accuracy: \n",
      "Epoch 38/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.5814 - accuracy: 0.8222 - val_loss: 1.4110 - val_accuracy: 0.6799 0.5841 - accu - ETA: 1s - loss: 0.5 - ETA: 0s - loss: 0.5832 \n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.5758 - accuracy: 0.8233 - val_loss: 1.5218 - val_accuracy: 0.6154 - ETA: 2s - loss:\n",
      "Epoch 40/100\n",
      "1489/1489 [==============================] - 67s 45ms/step - loss: 0.5705 - accuracy: 0.8245 - val_loss: 1.2078 - val_accuracy: 0.6873ss: 0.5606 - accuracy: 0.8 - ETA: 59s - loss: 0.5574 - accur - ETA: 58s - loss: 0.5626 - ac - ETA: 57s  - ETA: 47s - loss: 0.5732 - accuracy - ETA: 46s - loss: 0.5749 - accuracy: 0.8 -  - ETA: 42s - loss: 0.5751 - accuracy: 0 - ETA: 42s - loss: 0.57\n",
      "Evaluating model...\n",
      "ROC: 0.968\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "\n",
      "Accuracy = 0.77\n",
      "F-Score: 0.77\n",
      "\n",
      "Average R.O.C: 0.9436346429971447\n",
      "Average Accuracy: 0.6574656188488006\n"
     ]
    }
   ],
   "source": [
    "acc = np.zeros(10)\n",
    "roc = np.zeros(10)\n",
    "\n",
    "CM = 0\n",
    "\n",
    "for f in range(1,10+1):\n",
    "\n",
    "    roc[f-1], acc[f-1], cm = train_fold(f)\n",
    "    clear_session() # clear tensorflow variables\n",
    "    gc.collect() #collect garbage\n",
    "    CM += cm\n",
    "\n",
    "    \n",
    "print ('\\nAverage R.O.C:', np.mean(roc))\n",
    "print ('Average Accuracy:', np.mean(acc))\n",
    "\n",
    "# using all folds: best ROC = 0.91, f-score = 0.592 (50 epochs)\n",
    "# using 2 folds: average ROC = 0.792, average f-score = 0.335\n",
    "\n",
    "# if you want to save the model, uncomment this...\n",
    "#filepath = \"models/salamon-cnn-model.h5\"\n",
    "#model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TlA2tsI5CFF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x291dc61d3c8>,\n",
       "  <matplotlib.lines.Line2D at 0x291e97f9c48>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x291e9d35808>,\n",
       "  <matplotlib.lines.Line2D at 0x29227009288>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x291dc61da08>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x29227009f88>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x291e97e16c8>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UgKVz2_a5Cnn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x291cc7934c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ['air_conditioner',\n",
    "           \n",
    "'car_horn',\n",
    "'children_playing',\n",
    "'dog_bark',\n",
    "'drilling',\n",
    "'engine_idling',\n",
    "'gun_shot',\n",
    "'jackhammer',\n",
    "'siren',\n",
    "'street_music']\n",
    "df_cm = pd.DataFrame(CM, index = classes,\n",
    "                  columns = classes)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,  fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"acc_augmented_wav.npy\", acc)\n",
    "np.save(\"cm_agumented_wav.npy\", CM)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "us8k-cnn-salamon.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
