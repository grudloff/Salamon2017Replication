{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7x6wKsIGKLK"
   },
   "source": [
    "**Reproduction of:**\n",
    "\n",
    "**Deep Convolutional Neural Networks and Data Augmentation for Environmental  Sound Classification** \n",
    "\n",
    "Justin Salamon and Juan Pablo Bello\n",
    "\n",
    "Some code taken from https://github.com/jaron/deep-listening/blob/master/4-us8k-cnn-salamon.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNGuDtV8G3v9"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#for dir in [load_dir, augmented_load_dir]:\n",
    "#    for k in range(1,10+1):\n",
    "#        filename = \"fold\"+str(k)+\"_x.npy\"\n",
    "#        file_path = os.path.join(dir,filename)\n",
    "#        file= np.load(file_path, allow_pickle = True)\n",
    "#        file = file.astype('float32') \n",
    "#        np.save(file_path, file, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/grudloff/Salomon2017Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kj7xR5hfzYAW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monic\\miniconda3\\envs\\deepsound\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\monic\\miniconda3\\envs\\deepsound\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "#gc.set_debug(gc.DEBUG_STATS)\n",
    "\n",
    "from preprocessing_augmented import load_folds\n",
    "from model import build_model\n",
    "from evaluation import evaluate\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pywt import dwt2\n",
    "\n",
    "load_dir = \"CNN-Sound/data/us8k\"\n",
    "augmented_load_dir = \"CNN-Sound/data/us8k-augmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet = 'bior1.5'\n",
    "frames = 68\n",
    "bands=68\n",
    "channels = 4\n",
    "\n",
    "def wavedec(batch_x):\n",
    "    new_batch_x = np.empty(shape = (batch_x.shape[0], frames, bands, channels),dtype = 'float32')\n",
    "    for i, img in enumerate(batch_x):\n",
    "        img = np.squeeze(img)\n",
    "        img = (img - np.mean(img))/np.std(img)\n",
    "    \n",
    "        # 2D Discrete Wavelet Transform\n",
    "        LL, (LH, HL, HH) = dwt2(img, wavelet)\n",
    "        new_batch_x[i] = np.stack([LL,LH,HL,HH],axis=-1)# shape: [frames, bands, 4]\n",
    "    \n",
    "    return new_batch_x\n",
    "\n",
    "class waveletGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size, shuffle):\n",
    "        self.x, self.y = x_set, np.array(y_set)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(self.x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(self.x.shape[0] / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_x = wavedec(self.x[indexes])\n",
    "        batch_y = self.y[indexes]\n",
    "\n",
    "        return batch_x , batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLYCNfTzwWBt"
   },
   "source": [
    "10-Fold Crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(f):\n",
    "    # load data\n",
    "    train_x, test_x, val_x, train_y, test_y, val_y = load_folds(load_dir,augmented_load_dir, f)\n",
    "    #train_gen, test_x, val_x, test_y, val_y = load_folds_pescador(load_dir,augmented_load_dir, f)\n",
    "\n",
    "    train_gen = waveletGenerator(train_x, train_y, shuffle=True, batch_size=100)\n",
    "    test_gen = waveletGenerator(test_x, test_y, shuffle=False, batch_size=100)\n",
    "    val_gen = waveletGenerator(val_x, val_y, shuffle=False, batch_size=100)\n",
    "    \n",
    "    print(\"Building model...\")\n",
    "    model = build_model(f_size=3, frames=frames, bands=bands, channels=channels)\n",
    "\n",
    "    # now fit the model to the training data, evaluating loss against the validation data\n",
    "    print(\"Training model...\")\n",
    "    model.fit(train_gen, validation_data=test_gen, \n",
    "              callbacks=[EarlyStopping(restore_best_weights=True, patience=15)],\n",
    "              epochs=100, workers=0)\n",
    "    \n",
    "    # now evaluate the trained model against the unseen test data\n",
    "    print(\"Evaluating model...\")\n",
    "    return evaluate(model, val_gen, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "WQyEXvd9wWBt",
    "outputId": "78f34333-1791-4de4-9206-1d2cf9591893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Train on {2, 3, 4, 5, 6, 7, 9} Validate on 1 Test on 8 ***\n",
      "val shape:  (873, 128, 128, 1)\n",
      "test shape:  (806, 128, 128, 1)\n",
      "train shape:  (148113, 128, 128, 1)\n",
      "Building model...\n",
      "Training model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1482 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "1482/1482 [==============================] - 75s 51ms/step - loss: 2.1361 - accuracy: 0.2670 - val_loss: 1.7958 - val_accuracy: 0.5385 loss: 2.3394 - accuracy: - ETA: 51s - loss: 2.3377 - accuracy:  - ETA: 50s - loss: 2.3357 - accuracy: 0 - ETA: 50s - loss: 2.333 - ETA: 48s - loss: 2. - ETA: 45s - ETA: 37s  - ETA: 34s   - ETA: 27s - loss: 2.2\n",
      "Epoch 2/100\n",
      "1482/1482 [==============================] - 67s 46ms/step - loss: 1.7480 - accuracy: 0.4226 - val_loss: 1.6063 - val_accuracy: 0.5087\n",
      "Epoch 3/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 1.5337 - accuracy: 0.5049 - val_loss: 1.4538 - val_accuracy: 0.5906\n",
      "Epoch 4/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 1.3948 - accuracy: 0.5545 - val_loss: 1.6504 - val_accuracy: 0.5335 1.3950 - accuracy: \n",
      "Epoch 5/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 1.2938 - accuracy: 0.5905 - val_loss: 1.2625 - val_accuracy: 0.6414\n",
      "Epoch 6/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 1.2076 - accuracy: 0.6199 - val_loss: 1.3416 - val_accuracy: 0.6104TA: 25s - E\n",
      "Epoch 7/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 1.1482 - accuracy: 0.6416 - val_loss: 1.2669 - val_accuracy: 0.6390loss: 1.1688 - accuracy: 0. - ETA: 37s - loss: 1.1677 - accura - ETA: 36s - loss: 1.1737  - ETA: 34s - loss: 1.1 - ETA: 11s - loss: 1.1499 - accuracy: 0 - ETA: 10s - loss: 1.1501 - accuracy: 0. - ETA: 10s - loss: 1.1522 - accuracy:  - ETA: 9s  - E\n",
      "Epoch 8/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 1.0900 - accuracy: 0.6587 - val_loss: 1.6208 - val_accuracy: 0.5608\n",
      "Epoch 9/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 1.0352 - accuracy: 0.6777 - val_loss: 1.2937 - val_accuracy: 0.6390\n",
      "Epoch 10/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 0.9961 - accuracy: 0.6923 - val_loss: 1.3684 - val_accuracy: 0.6390 - - ETA: 59s - loss: 0.9404 - ETA: 58s - loss: 0.9564 - accuracy: - ET\n",
      "Epoch 11/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.9622 - accuracy: 0.7044 - val_loss: 1.2220 - val_accuracy: 0.6464- accura - ETA: 2s - loss: 0.9608  - ETA: 2s - loss: 0.9609 -  - ETA\n",
      "Epoch 12/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.9283 - accuracy: 0.7136 - val_loss: 1.2020 - val_accuracy: 0.6787 48s - loss: 0.9 - ETA: 43s - ETA: 3s - loss: 0.926 - ETA: 2s - los - ETA: 1s -\n",
      "Epoch 13/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.8953 - accuracy: 0.7266 - val_loss: 1.2654 - val_accuracy: 0.6613s - loss: 0.8776 - accura - ETA: 50s - loss: 0.8851 - accu - ETA: 42s - loss: 0.8944 -  - ETA: 3 - ETA: 34s - loss: 0.8862 - accuracy: 0.728 - ETA: 34s - l - ETA: 31s - loss: 0.8850 - accuracy:  - ETA: 31s - loss: 0.8825 - accuracy: 0.7 - ETA: 31s - lo - ETA: 28s -  - ETA: 26s - loss: 0.8848 - a - ETA: 13s - los\n",
      "Epoch 14/100\n",
      "1482/1482 [==============================] - 67s 45ms/step - loss: 0.8658 - accuracy: 0.7349 - val_loss: 1.2982 - val_accuracy: 0.6638TA: 53s - loss: 0.8748 - ac\n",
      "Epoch 15/100\n",
      "1482/1482 [==============================] - 66s 45ms/step - loss: 0.8497 - accuracy: 0.7395 - val_loss: 1.3228 - val_accuracy: 0.6687\n",
      "Epoch 16/100\n",
      "1336/1482 [==========================>...] - ETA: 6s - loss: 0.8192 - accuracy: 0.7503 - ETA: 57s - los - ETA: 55s - loss: 0.8118 - accuracy - - ETA: 51s - loss: 0.81 - ETA: 49s - loss: 0.8205  - ETA: 4 - ETA - ETA: 34s - loss: 0.8296   - ETA: 8s - loss: 0.8209 - accuracy: 0.75 - E - ETA: 7s - loss: 0.8196 - accuracy:  - ETA: 6s - loss: 0.8197 - accuracy: "
     ]
    }
   ],
   "source": [
    "acc = np.zeros(10)\n",
    "roc = np.zeros(10)\n",
    "\n",
    "CM = 0\n",
    "\n",
    "for f in range(1,10+1):\n",
    "\n",
    "    roc[f-1], acc[f-1], cm = train_fold(f)\n",
    "    clear_session() # clear tensorflow variables\n",
    "    gc.collect() #collect garbage\n",
    "    CM += cm\n",
    "\n",
    "    \n",
    "print ('\\nAverage R.O.C:', np.mean(roc))\n",
    "print ('Average Accuracy:', np.mean(acc))\n",
    "\n",
    "# using all folds: best ROC = 0.91, f-score = 0.592 (50 epochs)\n",
    "# using 2 folds: average ROC = 0.792, average f-score = 0.335\n",
    "\n",
    "# if you want to save the model, uncomment this...\n",
    "#filepath = \"models/salamon-cnn-model.h5\"\n",
    "#model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TlA2tsI5CFF"
   },
   "outputs": [],
   "source": [
    "plt.boxplot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UgKVz2_a5Cnn"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ['air_conditioner',\n",
    "           \n",
    "'car_horn',\n",
    "'children_playing',\n",
    "'dog_bark',\n",
    "'drilling',\n",
    "'engine_idling',\n",
    "'gun_shot',\n",
    "'jackhammer',\n",
    "'siren',\n",
    "'street_music']\n",
    "df_cm = pd.DataFrame(CM, index = classes,\n",
    "                  columns = classes)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,  fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"acc_augmented_wav.npy\", acc)\n",
    "np.save(\"cm_agumented_wav.npy\", CM)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "us8k-cnn-salamon.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
